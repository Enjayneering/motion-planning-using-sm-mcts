Searching game tree in timestep 0...
Max timehorizon: 8
Actions to choose Agent 0: dict_values([{'num_count': 124, 'sum_payoffs': 35.22154920391987, 'action': [1.0, 1.5707963267948966]}, {'num_count': 128, 'sum_payoffs': 37.00319449018661, 'action': [1.0, -1.5707963267948966]}, {'num_count': 128, 'sum_payoffs': 37.02865858847075, 'action': [2.0, -1.5707963267948966]}, {'num_count': 114, 'sum_payoffs': 30.583687952907674, 'action': [0.0, 0.0]}, {'num_count': 122, 'sum_payoffs': 34.34880233099721, 'action': [0.0, -1.5707963267948966]}, {'num_count': 119, 'sum_payoffs': 32.82375329440585, 'action': [1.0, 0.0]}, {'num_count': 116, 'sum_payoffs': 31.65154583411923, 'action': [0.0, 1.5707963267948966]}, {'num_count': 124, 'sum_payoffs': 35.22468915680215, 'action': [2.0, 1.5707963267948966]}, {'num_count': 125, 'sum_payoffs': 35.68081586743855, 'action': [2.0, 0.0]}])
Weights num count: [0.11262488646684832, 0.11625794732061762, 0.11625794732061762, 0.10354223433242507, 0.11080835603996367, 0.1080835603996367, 0.10535876475930972, 0.11262488646684832, 0.11353315168029064]
Actions to choose Agent 1: dict_values([{'num_count': 196, 'sum_payoffs': 54.56703126175972, 'action': [1.0, 0.0]}, {'num_count': 192, 'sum_payoffs': 52.77840073136639, 'action': [1.0, -1.5707963267948966]}, {'num_count': 171, 'sum_payoffs': 44.37127119108736, 'action': [0.0, 0.0]}, {'num_count': 175, 'sum_payoffs': 45.88132634924123, 'action': [0.0, 1.5707963267948966]}, {'num_count': 190, 'sum_payoffs': 52.064589574991736, 'action': [1.0, 1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 46.37262528631258, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.17801998183469572, 0.17438692098092642, 0.1553133514986376, 0.1589464123524069, 0.17257039055404177, 0.15985467756584923]
Selected final action: [1.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.22222222219629628, 0.2777777777453703]
Runtime: 16.146106719970703 s
