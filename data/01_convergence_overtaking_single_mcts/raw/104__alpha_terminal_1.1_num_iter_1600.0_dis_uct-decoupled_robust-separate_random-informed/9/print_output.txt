Searching game tree in timestep 0...
Max timehorizon: 8
Actions to choose Agent 0: dict_values([{'num_count': 176, 'sum_payoffs': 49.528174373379464, 'action': [1.0, 1.5707963267948966]}, {'num_count': 174, 'sum_payoffs': 48.656115188570574, 'action': [1.0, 0.0]}, {'num_count': 182, 'sum_payoffs': 52.14375223719403, 'action': [1.0, -1.5707963267948966]}, {'num_count': 171, 'sum_payoffs': 47.53827673606199, 'action': [0.0, -1.5707963267948966]}, {'num_count': 189, 'sum_payoffs': 55.227884833638164, 'action': [2.0, 0.0]}, {'num_count': 175, 'sum_payoffs': 49.13970728610393, 'action': [0.0, 1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 50.43501759774449, 'action': [2.0, -1.5707963267948966]}, {'num_count': 182, 'sum_payoffs': 52.007984202982016, 'action': [2.0, 1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 48.323796934639155, 'action': [0.0, 0.0]}])
Weights num count: [0.1099312929419113, 0.10868207370393504, 0.1136789506558401, 0.10680824484697064, 0.11805121798875702, 0.10930668332292318, 0.11118051217988757, 0.1136789506558401, 0.1080574640849469]
Actions to choose Agent 1: dict_values([{'num_count': 288, 'sum_payoffs': 79.73695888837791, 'action': [1.0, 0.0]}, {'num_count': 254, 'sum_payoffs': 66.54518397202264, 'action': [0.0, 0.0]}, {'num_count': 251, 'sum_payoffs': 65.41863213813109, 'action': [0.0, -1.5707963267948966]}, {'num_count': 271, 'sum_payoffs': 73.05586803404988, 'action': [1.0, 1.5707963267948966]}, {'num_count': 255, 'sum_payoffs': 67.0003160015937, 'action': [0.0, 1.5707963267948966]}, {'num_count': 281, 'sum_payoffs': 77.05360981168747, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.17988757026858213, 0.15865084322298564, 0.15677701436602123, 0.16926920674578388, 0.15927545284197375, 0.1755153029356652]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 25.543909311294556 s
