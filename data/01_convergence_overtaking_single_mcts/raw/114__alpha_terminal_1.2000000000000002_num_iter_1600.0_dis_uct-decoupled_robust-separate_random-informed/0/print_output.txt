Searching game tree in timestep 0...
Max timehorizon: 8
Actions to choose Agent 0: dict_values([{'num_count': 177, 'sum_payoffs': 49.82539554789125, 'action': [0.0, 0.0]}, {'num_count': 182, 'sum_payoffs': 52.05613729642728, 'action': [2.0, 0.0]}, {'num_count': 182, 'sum_payoffs': 51.96836526510966, 'action': [1.0, -1.5707963267948966]}, {'num_count': 174, 'sum_payoffs': 48.52423857835178, 'action': [0.0, 1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 48.10041885260474, 'action': [0.0, -1.5707963267948966]}, {'num_count': 175, 'sum_payoffs': 49.065510707019364, 'action': [1.0, 1.5707963267948966]}, {'num_count': 181, 'sum_payoffs': 51.507482405720495, 'action': [2.0, -1.5707963267948966]}, {'num_count': 179, 'sum_payoffs': 50.750382906180725, 'action': [2.0, 1.5707963267948966]}, {'num_count': 177, 'sum_payoffs': 49.93808086569956, 'action': [1.0, 0.0]}])
Weights num count: [0.11055590256089944, 0.1136789506558401, 0.1136789506558401, 0.10868207370393504, 0.1080574640849469, 0.10930668332292318, 0.11305434103685197, 0.11180512179887571, 0.11055590256089944]
Actions to choose Agent 1: dict_values([{'num_count': 251, 'sum_payoffs': 65.69905797061189, 'action': [0.0, -1.5707963267948966]}, {'num_count': 243, 'sum_payoffs': 62.61484516469205, 'action': [0.0, 1.5707963267948966]}, {'num_count': 280, 'sum_payoffs': 76.85393025731004, 'action': [1.0, -1.5707963267948966]}, {'num_count': 268, 'sum_payoffs': 72.25160132607732, 'action': [0.0, 0.0]}, {'num_count': 271, 'sum_payoffs': 73.3083923654144, 'action': [1.0, 1.5707963267948966]}, {'num_count': 287, 'sum_payoffs': 79.55303583793294, 'action': [1.0, 0.0]}])
Weights num count: [0.15677701436602123, 0.15178013741411617, 0.1748906933166771, 0.16739537788881947, 0.16926920674578388, 0.17926296064959402]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 27.886712789535522 s
