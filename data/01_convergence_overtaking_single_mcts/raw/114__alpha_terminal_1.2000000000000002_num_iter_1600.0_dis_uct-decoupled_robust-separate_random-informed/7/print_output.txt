Searching game tree in timestep 0...
Max timehorizon: 8
Actions to choose Agent 0: dict_values([{'num_count': 184, 'sum_payoffs': 52.572231336093786, 'action': [1.0, -1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 49.99715638486167, 'action': [0.0, 0.0]}, {'num_count': 186, 'sum_payoffs': 53.45834595130184, 'action': [2.0, 0.0]}, {'num_count': 173, 'sum_payoffs': 47.85400595651496, 'action': [1.0, 0.0]}, {'num_count': 181, 'sum_payoffs': 51.36597995887203, 'action': [2.0, 1.5707963267948966]}, {'num_count': 187, 'sum_payoffs': 53.93261557108526, 'action': [2.0, -1.5707963267948966]}, {'num_count': 168, 'sum_payoffs': 45.83036475516909, 'action': [0.0, 1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 49.141200082093484, 'action': [1.0, 1.5707963267948966]}, {'num_count': 167, 'sum_payoffs': 45.345969209217586, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.11492816989381636, 0.11118051217988757, 0.11617738913179262, 0.1080574640849469, 0.11305434103685197, 0.11680199875078076, 0.10493441599000625, 0.1099312929419113, 0.10430980637101811]
Actions to choose Agent 1: dict_values([{'num_count': 260, 'sum_payoffs': 69.62771189020104, 'action': [0.0, 0.0]}, {'num_count': 270, 'sum_payoffs': 73.44188993635292, 'action': [1.0, 1.5707963267948966]}, {'num_count': 292, 'sum_payoffs': 82.11373041442155, 'action': [1.0, 0.0]}, {'num_count': 255, 'sum_payoffs': 67.755346030865, 'action': [0.0, 1.5707963267948966]}, {'num_count': 271, 'sum_payoffs': 73.9272144496168, 'action': [1.0, -1.5707963267948966]}, {'num_count': 252, 'sum_payoffs': 66.51301670141903, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.16239850093691444, 0.16864459712679575, 0.18238600874453467, 0.15927545284197375, 0.16926920674578388, 0.15740162398500937]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 25.32771587371826 s
