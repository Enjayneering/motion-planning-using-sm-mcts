Searching game tree in timestep 0...
Max timehorizon: 8
Actions to choose Agent 0: dict_values([{'num_count': 220, 'sum_payoffs': 60.145362995099404, 'action': [0.0, 0.0]}, {'num_count': 240, 'sum_payoffs': 68.20267103883083, 'action': [1.0, -1.5707963267948966]}, {'num_count': 232, 'sum_payoffs': 65.00342194644679, 'action': [1.0, 1.5707963267948966]}, {'num_count': 242, 'sum_payoffs': 69.03058301948799, 'action': [2.0, 1.5707963267948966]}, {'num_count': 226, 'sum_payoffs': 62.56019941430719, 'action': [0.0, -1.5707963267948966]}, {'num_count': 221, 'sum_payoffs': 60.571657190646064, 'action': [0.0, 1.5707963267948966]}, {'num_count': 241, 'sum_payoffs': 68.55396017110226, 'action': [2.0, -1.5707963267948966]}, {'num_count': 242, 'sum_payoffs': 69.13388422561574, 'action': [2.0, 0.0]}, {'num_count': 236, 'sum_payoffs': 66.6332309394039, 'action': [1.0, 0.0]}])
Weights num count: [0.10471204188481675, 0.1142313184198001, 0.11042360780580676, 0.11518324607329843, 0.10756782484531176, 0.10518800571156592, 0.11470728224654926, 0.11518324607329843, 0.11232746311280342]
Actions to choose Agent 1: dict_values([{'num_count': 353, 'sum_payoffs': 96.01100003366483, 'action': [1.0, 1.5707963267948966]}, {'num_count': 367, 'sum_payoffs': 101.22549600775868, 'action': [1.0, -1.5707963267948966]}, {'num_count': 331, 'sum_payoffs': 87.75032438280473, 'action': [0.0, 1.5707963267948966]}, {'num_count': 337, 'sum_payoffs': 90.00894007477382, 'action': [0.0, -1.5707963267948966]}, {'num_count': 366, 'sum_payoffs': 100.92237994709772, 'action': [1.0, 0.0]}, {'num_count': 346, 'sum_payoffs': 93.39317312817244, 'action': [0.0, 0.0]}])
Weights num count: [0.16801523084245598, 0.17467872441694432, 0.1575440266539743, 0.1603998096144693, 0.17420276059019515, 0.1646834840552118]
Selected final action: [2.0, 1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 34.32029390335083 s
