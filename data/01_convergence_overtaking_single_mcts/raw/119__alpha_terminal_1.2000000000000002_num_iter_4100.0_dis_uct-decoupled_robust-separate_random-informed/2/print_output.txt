Searching game tree in timestep 0...
Max timehorizon: 8
Actions to choose Agent 0: dict_values([{'num_count': 493, 'sum_payoffs': 139.2688322920898, 'action': [2.0, 0.0]}, {'num_count': 428, 'sum_payoffs': 115.1428738493077, 'action': [0.0, -1.5707963267948966]}, {'num_count': 454, 'sum_payoffs': 124.67937988951164, 'action': [1.0, -1.5707963267948966]}, {'num_count': 453, 'sum_payoffs': 124.33855583383655, 'action': [1.0, 1.5707963267948966]}, {'num_count': 465, 'sum_payoffs': 128.78166668817576, 'action': [2.0, 1.5707963267948966]}, {'num_count': 471, 'sum_payoffs': 130.98591114452879, 'action': [2.0, -1.5707963267948966]}, {'num_count': 433, 'sum_payoffs': 116.9692213868614, 'action': [0.0, 1.5707963267948966]}, {'num_count': 461, 'sum_payoffs': 127.24238187821561, 'action': [1.0, 0.0]}, {'num_count': 442, 'sum_payoffs': 120.26667504505693, 'action': [0.0, 0.0]}])
Weights num count: [0.1202145818093148, 0.10436478907583516, 0.11070470616922702, 0.11046086320409657, 0.11338697878566203, 0.11485003657644477, 0.10558400390148744, 0.11241160692514021, 0.10777859058766155]
Actions to choose Agent 1: dict_values([{'num_count': 705, 'sum_payoffs': 188.17021505804107, 'action': [1.0, 1.5707963267948966]}, {'num_count': 666, 'sum_payoffs': 174.7154344028135, 'action': [0.0, 0.0]}, {'num_count': 658, 'sum_payoffs': 172.08797792094975, 'action': [0.0, -1.5707963267948966]}, {'num_count': 626, 'sum_payoffs': 161.17680364439573, 'action': [0.0, 1.5707963267948966]}, {'num_count': 706, 'sum_payoffs': 188.47344556083374, 'action': [1.0, -1.5707963267948966]}, {'num_count': 739, 'sum_payoffs': 199.82158826148728, 'action': [1.0, 0.0]}])
Weights num count: [0.17190929041697148, 0.1623994147768837, 0.16044867105584004, 0.15264569617166546, 0.17215313338210192, 0.18019995123140697]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 65.59826946258545 s
