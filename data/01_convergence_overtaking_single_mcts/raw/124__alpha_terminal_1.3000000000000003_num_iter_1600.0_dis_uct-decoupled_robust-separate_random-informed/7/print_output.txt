Searching game tree in timestep 0...
Max timehorizon: 9
Actions to choose Agent 0: dict_values([{'num_count': 170, 'sum_payoffs': 44.53726850757098, 'action': [0.0, 1.5707963267948966]}, {'num_count': 184, 'sum_payoffs': 50.3827539127055, 'action': [2.0, -1.5707963267948966]}, {'num_count': 175, 'sum_payoffs': 46.6199457339884, 'action': [1.0, 1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 47.85153047857972, 'action': [2.0, 1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 45.783578847913496, 'action': [0.0, -1.5707963267948966]}, {'num_count': 179, 'sum_payoffs': 48.240227639165155, 'action': [0.0, 0.0]}, {'num_count': 171, 'sum_payoffs': 44.98067894280825, 'action': [1.0, 0.0]}, {'num_count': 186, 'sum_payoffs': 51.214050862321535, 'action': [2.0, 0.0]}, {'num_count': 184, 'sum_payoffs': 50.41489076548382, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.1061836352279825, 0.11492816989381636, 0.10930668332292318, 0.11118051217988757, 0.1080574640849469, 0.11180512179887571, 0.10680824484697064, 0.11617738913179262, 0.11492816989381636]
Actions to choose Agent 1: dict_values([{'num_count': 257, 'sum_payoffs': 64.08802755288905, 'action': [0.0, 0.0]}, {'num_count': 289, 'sum_payoffs': 76.00042719169501, 'action': [1.0, 0.0]}, {'num_count': 254, 'sum_payoffs': 62.88754493689457, 'action': [0.0, 1.5707963267948966]}, {'num_count': 267, 'sum_payoffs': 67.78570445047089, 'action': [1.0, -1.5707963267948966]}, {'num_count': 284, 'sum_payoffs': 74.12191521460765, 'action': [1.0, 1.5707963267948966]}, {'num_count': 249, 'sum_payoffs': 61.14385874008648, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.16052467207995003, 0.18051217988757026, 0.15865084322298564, 0.16677076826983137, 0.1773891317926296, 0.15552779512804496]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 26.801881313323975 s
