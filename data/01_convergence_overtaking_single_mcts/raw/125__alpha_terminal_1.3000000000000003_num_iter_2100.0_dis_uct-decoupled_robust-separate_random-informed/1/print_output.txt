Searching game tree in timestep 0...
Max timehorizon: 9
Actions to choose Agent 0: dict_values([{'num_count': 220, 'sum_payoffs': 57.76034785293298, 'action': [0.0, 0.0]}, {'num_count': 235, 'sum_payoffs': 63.737428386759525, 'action': [0.0, -1.5707963267948966]}, {'num_count': 240, 'sum_payoffs': 65.70340898906734, 'action': [2.0, 0.0]}, {'num_count': 245, 'sum_payoffs': 67.7672172106742, 'action': [2.0, 1.5707963267948966]}, {'num_count': 251, 'sum_payoffs': 70.14098626283315, 'action': [2.0, -1.5707963267948966]}, {'num_count': 220, 'sum_payoffs': 57.79977526834669, 'action': [1.0, 0.0]}, {'num_count': 233, 'sum_payoffs': 62.91327763966365, 'action': [1.0, -1.5707963267948966]}, {'num_count': 223, 'sum_payoffs': 58.820416589588035, 'action': [0.0, 1.5707963267948966]}, {'num_count': 233, 'sum_payoffs': 62.90851127079847, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.10471204188481675, 0.11185149928605426, 0.1142313184198001, 0.11661113755354593, 0.11946692051404094, 0.10471204188481675, 0.11089957163255593, 0.10613993336506425, 0.11089957163255593]
Actions to choose Agent 1: dict_values([{'num_count': 340, 'sum_payoffs': 84.979458520034, 'action': [0.0, 0.0]}, {'num_count': 325, 'sum_payoffs': 79.5991066453802, 'action': [0.0, 1.5707963267948966]}, {'num_count': 370, 'sum_payoffs': 95.615153419567, 'action': [1.0, 1.5707963267948966]}, {'num_count': 340, 'sum_payoffs': 85.01356213848645, 'action': [0.0, -1.5707963267948966]}, {'num_count': 354, 'sum_payoffs': 89.98170360408491, 'action': [1.0, 0.0]}, {'num_count': 371, 'sum_payoffs': 96.05849729794507, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.1618277010947168, 0.1546882436934793, 0.17610661589719181, 0.1618277010947168, 0.16849119466920515, 0.17658257972394098]
Selected final action: [2.0, -1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 35.26095461845398 s
