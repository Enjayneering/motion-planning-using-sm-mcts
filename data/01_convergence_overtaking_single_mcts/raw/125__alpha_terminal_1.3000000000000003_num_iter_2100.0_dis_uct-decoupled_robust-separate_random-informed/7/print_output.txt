Searching game tree in timestep 0...
Max timehorizon: 9
Actions to choose Agent 0: dict_values([{'num_count': 233, 'sum_payoffs': 62.755935182077245, 'action': [2.0, 0.0]}, {'num_count': 228, 'sum_payoffs': 60.83659717757384, 'action': [0.0, -1.5707963267948966]}, {'num_count': 233, 'sum_payoffs': 62.76060657156463, 'action': [0.0, 0.0]}, {'num_count': 245, 'sum_payoffs': 67.5628795051477, 'action': [2.0, -1.5707963267948966]}, {'num_count': 241, 'sum_payoffs': 65.89366386237427, 'action': [1.0, -1.5707963267948966]}, {'num_count': 234, 'sum_payoffs': 63.23412082505611, 'action': [2.0, 1.5707963267948966]}, {'num_count': 231, 'sum_payoffs': 61.86205098598802, 'action': [1.0, 1.5707963267948966]}, {'num_count': 223, 'sum_payoffs': 58.836119207509604, 'action': [0.0, 1.5707963267948966]}, {'num_count': 232, 'sum_payoffs': 62.38371975130017, 'action': [1.0, 0.0]}])
Weights num count: [0.11089957163255593, 0.10851975249881009, 0.11089957163255593, 0.11661113755354593, 0.11470728224654926, 0.11137553545930509, 0.1099476439790576, 0.10613993336506425, 0.11042360780580676]
Actions to choose Agent 1: dict_values([{'num_count': 343, 'sum_payoffs': 86.52282845501276, 'action': [0.0, 0.0]}, {'num_count': 336, 'sum_payoffs': 84.03355183566671, 'action': [0.0, 1.5707963267948966]}, {'num_count': 369, 'sum_payoffs': 95.79838184265543, 'action': [1.0, 0.0]}, {'num_count': 367, 'sum_payoffs': 95.12034263637715, 'action': [1.0, 1.5707963267948966]}, {'num_count': 347, 'sum_payoffs': 87.89736285851515, 'action': [1.0, -1.5707963267948966]}, {'num_count': 338, 'sum_payoffs': 84.63390524347734, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.1632555925749643, 0.15992384578772012, 0.17563065207044265, 0.17467872441694432, 0.16515944788196096, 0.16087577344121848]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 35.345189332962036 s
