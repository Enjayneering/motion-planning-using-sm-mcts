Searching game tree in timestep 0...
Max timehorizon: 9
Actions to choose Agent 0: dict_values([{'num_count': 224, 'sum_payoffs': 59.55958211156087, 'action': [0.0, 1.5707963267948966]}, {'num_count': 244, 'sum_payoffs': 67.63668389311036, 'action': [2.0, 1.5707963267948966]}, {'num_count': 232, 'sum_payoffs': 62.80640271203085, 'action': [1.0, 0.0]}, {'num_count': 228, 'sum_payoffs': 61.20594483743578, 'action': [0.0, 0.0]}, {'num_count': 235, 'sum_payoffs': 63.82305842312405, 'action': [1.0, -1.5707963267948966]}, {'num_count': 228, 'sum_payoffs': 61.17353689117807, 'action': [0.0, -1.5707963267948966]}, {'num_count': 231, 'sum_payoffs': 62.3733282489014, 'action': [1.0, 1.5707963267948966]}, {'num_count': 235, 'sum_payoffs': 63.98919851405275, 'action': [2.0, -1.5707963267948966]}, {'num_count': 243, 'sum_payoffs': 67.11757730185963, 'action': [2.0, 0.0]}])
Weights num count: [0.10661589719181343, 0.11613517372679677, 0.11042360780580676, 0.10851975249881009, 0.11185149928605426, 0.10851975249881009, 0.1099476439790576, 0.11185149928605426, 0.11565920990004759]
Actions to choose Agent 1: dict_values([{'num_count': 345, 'sum_payoffs': 86.58833320585094, 'action': [0.0, 0.0]}, {'num_count': 332, 'sum_payoffs': 82.02468502451056, 'action': [0.0, 1.5707963267948966]}, {'num_count': 337, 'sum_payoffs': 83.76631428713428, 'action': [0.0, -1.5707963267948966]}, {'num_count': 360, 'sum_payoffs': 91.91520918825627, 'action': [1.0, -1.5707963267948966]}, {'num_count': 365, 'sum_payoffs': 93.81295003275129, 'action': [1.0, 1.5707963267948966]}, {'num_count': 361, 'sum_payoffs': 92.34480079796705, 'action': [1.0, 0.0]}])
Weights num count: [0.16420752022846263, 0.15801999048072346, 0.1603998096144693, 0.17134697762970014, 0.173726796763446, 0.1718229414564493]
Selected final action: [2.0, 1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 35.245595932006836 s
