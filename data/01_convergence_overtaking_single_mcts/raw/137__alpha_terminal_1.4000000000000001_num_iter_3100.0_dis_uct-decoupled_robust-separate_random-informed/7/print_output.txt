Searching game tree in timestep 0...
Max timehorizon: 10
Actions to choose Agent 0: dict_values([{'num_count': 328, 'sum_payoffs': 82.0668849052176, 'action': [0.0, 1.5707963267948966]}, {'num_count': 349, 'sum_payoffs': 89.65658317553067, 'action': [2.0, 1.5707963267948966]}, {'num_count': 365, 'sum_payoffs': 95.52267910809329, 'action': [2.0, 0.0]}, {'num_count': 332, 'sum_payoffs': 83.44832405193799, 'action': [0.0, 0.0]}, {'num_count': 349, 'sum_payoffs': 89.51464600605311, 'action': [1.0, -1.5707963267948966]}, {'num_count': 350, 'sum_payoffs': 90.01593098686617, 'action': [1.0, 1.5707963267948966]}, {'num_count': 343, 'sum_payoffs': 87.47053839607744, 'action': [1.0, 0.0]}, {'num_count': 350, 'sum_payoffs': 90.03833310854107, 'action': [2.0, -1.5707963267948966]}, {'num_count': 334, 'sum_payoffs': 84.15617990224953, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.10577233150596582, 0.11254434053531119, 0.11770396646243148, 0.10706223798774589, 0.11254434053531119, 0.11286681715575621, 0.11060948081264109, 0.11286681715575621, 0.10770719122863592]
Actions to choose Agent 1: dict_values([{'num_count': 551, 'sum_payoffs': 135.0937304265782, 'action': [1.0, 0.0]}, {'num_count': 498, 'sum_payoffs': 117.70850461028559, 'action': [0.0, 0.0]}, {'num_count': 497, 'sum_payoffs': 117.30426451795476, 'action': [0.0, 1.5707963267948966]}, {'num_count': 537, 'sum_payoffs': 130.42248019793422, 'action': [1.0, -1.5707963267948966]}, {'num_count': 484, 'sum_payoffs': 113.05034745794404, 'action': [0.0, -1.5707963267948966]}, {'num_count': 533, 'sum_payoffs': 129.1531516281795, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.17768461786520479, 0.16059335698161883, 0.16027088036117382, 0.17316994517897452, 0.1560786842953886, 0.17188003869719445]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 57.856173038482666 s
