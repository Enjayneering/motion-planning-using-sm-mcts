Searching game tree in timestep 0...
Max timehorizon: 10
Actions to choose Agent 0: dict_values([{'num_count': 389, 'sum_payoffs': 97.74341804130076, 'action': [1.0, 0.0]}, {'num_count': 380, 'sum_payoffs': 94.62876714333072, 'action': [0.0, 1.5707963267948966]}, {'num_count': 396, 'sum_payoffs': 100.3721537960281, 'action': [1.0, 1.5707963267948966]}, {'num_count': 410, 'sum_payoffs': 105.26569956545949, 'action': [2.0, -1.5707963267948966]}, {'num_count': 383, 'sum_payoffs': 95.79233200437187, 'action': [0.0, -1.5707963267948966]}, {'num_count': 390, 'sum_payoffs': 98.23758794808484, 'action': [0.0, 0.0]}, {'num_count': 412, 'sum_payoffs': 106.02745211065094, 'action': [2.0, 1.5707963267948966]}, {'num_count': 404, 'sum_payoffs': 103.14784229236352, 'action': [1.0, -1.5707963267948966]}, {'num_count': 436, 'sum_payoffs': 114.67425534165875, 'action': [2.0, 0.0]}])
Weights num count: [0.10802554845876146, 0.10552624271035824, 0.10996945292974174, 0.11385726187170231, 0.10635934462649264, 0.10830324909747292, 0.11441266314912524, 0.1121910580394335, 0.1210774784782005]
Actions to choose Agent 1: dict_values([{'num_count': 585, 'sum_payoffs': 137.82407381765412, 'action': [0.0, 0.0]}, {'num_count': 630, 'sum_payoffs': 152.2299068034279, 'action': [1.0, 1.5707963267948966]}, {'num_count': 570, 'sum_payoffs': 133.0375257485186, 'action': [0.0, 1.5707963267948966]}, {'num_count': 576, 'sum_payoffs': 134.93409285807354, 'action': [0.0, -1.5707963267948966]}, {'num_count': 617, 'sum_payoffs': 148.09928608040588, 'action': [1.0, -1.5707963267948966]}, {'num_count': 622, 'sum_payoffs': 149.49490037733696, 'action': [1.0, 0.0]}])
Weights num count: [0.1624548736462094, 0.17495140238822549, 0.15828936406553734, 0.15995556789780616, 0.1713412940849764, 0.17272979727853374]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 66.10570240020752 s
