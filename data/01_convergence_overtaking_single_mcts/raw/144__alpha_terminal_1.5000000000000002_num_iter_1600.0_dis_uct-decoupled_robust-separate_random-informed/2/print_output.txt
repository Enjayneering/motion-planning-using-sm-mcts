Searching game tree in timestep 0...
Max timehorizon: 10
Actions to choose Agent 0: dict_values([{'num_count': 174, 'sum_payoffs': 44.847101813641174, 'action': [1.0, 0.0]}, {'num_count': 170, 'sum_payoffs': 43.117295888448325, 'action': [0.0, 0.0]}, {'num_count': 191, 'sum_payoffs': 51.73312118015708, 'action': [2.0, 0.0]}, {'num_count': 172, 'sum_payoffs': 43.940710580676985, 'action': [0.0, 1.5707963267948966]}, {'num_count': 180, 'sum_payoffs': 47.16720179408866, 'action': [1.0, -1.5707963267948966]}, {'num_count': 179, 'sum_payoffs': 46.81227394341207, 'action': [2.0, 1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 44.3200195825666, 'action': [0.0, -1.5707963267948966]}, {'num_count': 172, 'sum_payoffs': 44.081152906805784, 'action': [1.0, 1.5707963267948966]}, {'num_count': 189, 'sum_payoffs': 50.83662685407494, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.10868207370393504, 0.1061836352279825, 0.1193004372267333, 0.10743285446595878, 0.11242973141786383, 0.11180512179887571, 0.1080574640849469, 0.10743285446595878, 0.11805121798875702]
Actions to choose Agent 1: dict_values([{'num_count': 286, 'sum_payoffs': 71.24163047821392, 'action': [1.0, 0.0]}, {'num_count': 263, 'sum_payoffs': 63.018220295504314, 'action': [0.0, 0.0]}, {'num_count': 272, 'sum_payoffs': 66.2154644395609, 'action': [1.0, -1.5707963267948966]}, {'num_count': 251, 'sum_payoffs': 58.71880203641844, 'action': [0.0, 1.5707963267948966]}, {'num_count': 271, 'sum_payoffs': 65.8542071043351, 'action': [1.0, 1.5707963267948966]}, {'num_count': 257, 'sum_payoffs': 60.849083587470666, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.17863835103060588, 0.16427232979387882, 0.16989381636477202, 0.15677701436602123, 0.16926920674578388, 0.16052467207995003]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 30.37348771095276 s
