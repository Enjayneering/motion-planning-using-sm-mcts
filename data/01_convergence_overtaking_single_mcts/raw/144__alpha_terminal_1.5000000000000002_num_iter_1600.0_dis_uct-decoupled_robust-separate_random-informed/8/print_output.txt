Searching game tree in timestep 0...
Max timehorizon: 10
Actions to choose Agent 0: dict_values([{'num_count': 180, 'sum_payoffs': 46.99887209359818, 'action': [2.0, -1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 45.45065948590695, 'action': [1.0, 1.5707963267948966]}, {'num_count': 174, 'sum_payoffs': 44.63668125652799, 'action': [0.0, -1.5707963267948966]}, {'num_count': 183, 'sum_payoffs': 48.25815456247883, 'action': [2.0, 1.5707963267948966]}, {'num_count': 182, 'sum_payoffs': 47.74062335451007, 'action': [1.0, 0.0]}, {'num_count': 174, 'sum_payoffs': 44.61067018789407, 'action': [0.0, 0.0]}, {'num_count': 179, 'sum_payoffs': 46.65837270662301, 'action': [2.0, 0.0]}, {'num_count': 182, 'sum_payoffs': 47.80223127217431, 'action': [1.0, -1.5707963267948966]}, {'num_count': 170, 'sum_payoffs': 43.008622635611786, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.11242973141786383, 0.1099312929419113, 0.10868207370393504, 0.11430356027482823, 0.1136789506558401, 0.10868207370393504, 0.11180512179887571, 0.1136789506558401, 0.1061836352279825]
Actions to choose Agent 1: dict_values([{'num_count': 273, 'sum_payoffs': 66.1452034334564, 'action': [1.0, -1.5707963267948966]}, {'num_count': 273, 'sum_payoffs': 66.16988323542792, 'action': [1.0, 1.5707963267948966]}, {'num_count': 255, 'sum_payoffs': 59.732992559004465, 'action': [0.0, -1.5707963267948966]}, {'num_count': 257, 'sum_payoffs': 60.47037416890946, 'action': [0.0, 1.5707963267948966]}, {'num_count': 284, 'sum_payoffs': 70.05984523085111, 'action': [1.0, 0.0]}, {'num_count': 258, 'sum_payoffs': 60.76995114530486, 'action': [0.0, 0.0]}])
Weights num count: [0.17051842598376016, 0.17051842598376016, 0.15927545284197375, 0.16052467207995003, 0.1773891317926296, 0.16114928169893816]
Selected final action: [2.0, 1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 30.236788272857666 s
