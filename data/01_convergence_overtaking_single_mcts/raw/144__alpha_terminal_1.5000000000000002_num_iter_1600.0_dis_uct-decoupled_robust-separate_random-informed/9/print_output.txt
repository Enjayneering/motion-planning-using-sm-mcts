Searching game tree in timestep 0...
Max timehorizon: 10
Actions to choose Agent 0: dict_values([{'num_count': 176, 'sum_payoffs': 44.922250055427526, 'action': [0.0, -1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 44.841107022643214, 'action': [1.0, 0.0]}, {'num_count': 179, 'sum_payoffs': 46.20723812719646, 'action': [2.0, 1.5707963267948966]}, {'num_count': 180, 'sum_payoffs': 46.59382680231337, 'action': [2.0, 0.0]}, {'num_count': 182, 'sum_payoffs': 47.33124064524969, 'action': [1.0, 1.5707963267948966]}, {'num_count': 187, 'sum_payoffs': 49.36087759318696, 'action': [2.0, -1.5707963267948966]}, {'num_count': 171, 'sum_payoffs': 42.92365188116108, 'action': [0.0, 0.0]}, {'num_count': 171, 'sum_payoffs': 42.89762015625163, 'action': [0.0, 1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 45.79997131412122, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.1099312929419113, 0.1099312929419113, 0.11180512179887571, 0.11242973141786383, 0.1136789506558401, 0.11680199875078076, 0.10680824484697064, 0.10680824484697064, 0.11118051217988757]
Actions to choose Agent 1: dict_values([{'num_count': 257, 'sum_payoffs': 60.99194324879436, 'action': [0.0, 1.5707963267948966]}, {'num_count': 280, 'sum_payoffs': 69.37487245073793, 'action': [1.0, -1.5707963267948966]}, {'num_count': 255, 'sum_payoffs': 60.261133949714406, 'action': [0.0, -1.5707963267948966]}, {'num_count': 260, 'sum_payoffs': 62.10374775148384, 'action': [0.0, 0.0]}, {'num_count': 279, 'sum_payoffs': 68.96232396749929, 'action': [1.0, 1.5707963267948966]}, {'num_count': 269, 'sum_payoffs': 65.38819236619476, 'action': [1.0, 0.0]}])
Weights num count: [0.16052467207995003, 0.1748906933166771, 0.15927545284197375, 0.16239850093691444, 0.17426608369768895, 0.1680199875078076]
Selected final action: [2.0, -1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 30.37704086303711 s
