Searching game tree in timestep 0...
Max timehorizon: 10
Actions to choose Agent 0: dict_values([{'num_count': 302, 'sum_payoffs': 79.50266809298189, 'action': [2.0, 0.0]}, {'num_count': 291, 'sum_payoffs': 75.37423501968823, 'action': [2.0, 1.5707963267948966]}, {'num_count': 280, 'sum_payoffs': 71.2816375984915, 'action': [0.0, 1.5707963267948966]}, {'num_count': 280, 'sum_payoffs': 71.31775816269513, 'action': [0.0, -1.5707963267948966]}, {'num_count': 282, 'sum_payoffs': 72.00257313929917, 'action': [1.0, 0.0]}, {'num_count': 289, 'sum_payoffs': 74.66733587169091, 'action': [1.0, 1.5707963267948966]}, {'num_count': 294, 'sum_payoffs': 76.46439134470442, 'action': [1.0, -1.5707963267948966]}, {'num_count': 278, 'sum_payoffs': 70.57292885544267, 'action': [0.0, 0.0]}, {'num_count': 304, 'sum_payoffs': 80.3349270000006, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.11610918877354863, 0.1118800461361015, 0.10765090349865436, 0.10765090349865436, 0.10841983852364476, 0.1111111111111111, 0.11303344867358708, 0.10688196847366398, 0.11687812379853903]
Actions to choose Agent 1: dict_values([{'num_count': 400, 'sum_payoffs': 93.14352221581056, 'action': [0.0, 1.5707963267948966]}, {'num_count': 440, 'sum_payoffs': 106.41793212545655, 'action': [1.0, 1.5707963267948966]}, {'num_count': 463, 'sum_payoffs': 114.1787908563012, 'action': [1.0, 0.0]}, {'num_count': 423, 'sum_payoffs': 100.77282623770115, 'action': [0.0, 0.0]}, {'num_count': 452, 'sum_payoffs': 110.4423481663745, 'action': [1.0, -1.5707963267948966]}, {'num_count': 422, 'sum_payoffs': 100.46634809429017, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.15378700499807765, 0.16916570549788543, 0.1780084582852749, 0.16262975778546712, 0.17377931564782775, 0.16224529027297194]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 49.49851679801941 s
