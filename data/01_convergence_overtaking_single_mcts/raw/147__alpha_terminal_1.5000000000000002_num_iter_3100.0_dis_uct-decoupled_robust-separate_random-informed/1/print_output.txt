Searching game tree in timestep 0...
Max timehorizon: 10
Actions to choose Agent 0: dict_values([{'num_count': 331, 'sum_payoffs': 83.79504849710534, 'action': [0.0, 0.0]}, {'num_count': 344, 'sum_payoffs': 88.50623668983529, 'action': [2.0, 1.5707963267948966]}, {'num_count': 359, 'sum_payoffs': 94.09808948184035, 'action': [2.0, -1.5707963267948966]}, {'num_count': 358, 'sum_payoffs': 93.64605480685856, 'action': [1.0, -1.5707963267948966]}, {'num_count': 334, 'sum_payoffs': 84.85166187052369, 'action': [0.0, -1.5707963267948966]}, {'num_count': 356, 'sum_payoffs': 93.0443717268005, 'action': [1.0, 1.5707963267948966]}, {'num_count': 334, 'sum_payoffs': 84.97974449443002, 'action': [1.0, 0.0]}, {'num_count': 353, 'sum_payoffs': 91.9370288440549, 'action': [2.0, 0.0]}, {'num_count': 331, 'sum_payoffs': 83.8471615030482, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.10673976136730087, 0.1109319574330861, 0.11576910673976137, 0.11544663011931634, 0.10770719122863592, 0.11480167687842631, 0.10770719122863592, 0.11383424701709126, 0.10673976136730087]
Actions to choose Agent 1: dict_values([{'num_count': 536, 'sum_payoffs': 129.6641550324125, 'action': [1.0, 0.0]}, {'num_count': 503, 'sum_payoffs': 119.00686202753764, 'action': [0.0, -1.5707963267948966]}, {'num_count': 540, 'sum_payoffs': 130.99422843008082, 'action': [1.0, -1.5707963267948966]}, {'num_count': 497, 'sum_payoffs': 116.93160789094979, 'action': [0.0, 0.0]}, {'num_count': 488, 'sum_payoffs': 114.13772997640143, 'action': [0.0, 1.5707963267948966]}, {'num_count': 536, 'sum_payoffs': 129.81513017226, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.1728474685585295, 0.16220574008384392, 0.17413737504030957, 0.16027088036117382, 0.15736859077716867, 0.1728474685585295]
Selected final action: [2.0, -1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 58.52970790863037 s
