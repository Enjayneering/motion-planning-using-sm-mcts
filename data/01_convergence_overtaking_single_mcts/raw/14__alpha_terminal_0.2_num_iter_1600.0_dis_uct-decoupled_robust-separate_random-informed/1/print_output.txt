Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 216, 'sum_payoffs': 56.496860256150306, 'action': [2.0, 0.0]}, {'num_count': 169, 'sum_payoffs': 38.40731807373257, 'action': [1.0, 1.5707963267948966]}, {'num_count': 169, 'sum_payoffs': 38.35517023461735, 'action': [1.0, -1.5707963267948966]}, {'num_count': 188, 'sum_payoffs': 45.56591268826054, 'action': [2.0, 1.5707963267948966]}, {'num_count': 171, 'sum_payoffs': 39.1500264295842, 'action': [0.0, 0.0]}, {'num_count': 188, 'sum_payoffs': 45.54266344331441, 'action': [2.0, -1.5707963267948966]}, {'num_count': 194, 'sum_payoffs': 47.947547957207235, 'action': [1.0, 0.0]}, {'num_count': 152, 'sum_payoffs': 32.088738234271226, 'action': [0.0, -1.5707963267948966]}, {'num_count': 153, 'sum_payoffs': 32.36403536827428, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.13491567770143661, 0.10555902560899438, 0.10555902560899438, 0.1174266083697689, 0.10680824484697064, 0.1174266083697689, 0.12117426608369769, 0.09494066208619613, 0.09556527170518427]
Actions to choose Agent 1: dict_values([{'num_count': 262, 'sum_payoffs': 72.66989692357046, 'action': [0.0, 0.0]}, {'num_count': 283, 'sum_payoffs': 80.98928795129508, 'action': [1.0, -1.5707963267948966]}, {'num_count': 235, 'sum_payoffs': 62.02735587697568, 'action': [0.0, -1.5707963267948966]}, {'num_count': 236, 'sum_payoffs': 62.42433130224761, 'action': [0.0, 1.5707963267948966]}, {'num_count': 277, 'sum_payoffs': 78.59613670121773, 'action': [1.0, 1.5707963267948966]}, {'num_count': 307, 'sum_payoffs': 90.65242739448877, 'action': [1.0, 0.0]}])
Weights num count: [0.16364772017489068, 0.17676452217364147, 0.14678326046221113, 0.14740787008119924, 0.17301686445971268, 0.19175515302935664]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 2.6960036754608154 s
