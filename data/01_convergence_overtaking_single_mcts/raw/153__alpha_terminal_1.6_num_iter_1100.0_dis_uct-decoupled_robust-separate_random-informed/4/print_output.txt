Searching game tree in timestep 0...
Max timehorizon: 11
Actions to choose Agent 0: dict_values([{'num_count': 119, 'sum_payoffs': 29.225579286820576, 'action': [0.0, 1.5707963267948966]}, {'num_count': 127, 'sum_payoffs': 32.577922513925216, 'action': [2.0, 1.5707963267948966]}, {'num_count': 123, 'sum_payoffs': 30.882088524613525, 'action': [1.0, 1.5707963267948966]}, {'num_count': 127, 'sum_payoffs': 32.696834317273755, 'action': [1.0, -1.5707963267948966]}, {'num_count': 123, 'sum_payoffs': 30.953961360486765, 'action': [0.0, 0.0]}, {'num_count': 117, 'sum_payoffs': 28.387247598978504, 'action': [1.0, 0.0]}, {'num_count': 123, 'sum_payoffs': 30.980340532217255, 'action': [2.0, -1.5707963267948966]}, {'num_count': 122, 'sum_payoffs': 30.575149504374263, 'action': [2.0, 0.0]}, {'num_count': 119, 'sum_payoffs': 29.331482150852864, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.1080835603996367, 0.11534968210717529, 0.11171662125340599, 0.11534968210717529, 0.11171662125340599, 0.10626702997275204, 0.11171662125340599, 0.11080835603996367, 0.1080835603996367]
Actions to choose Agent 1: dict_values([{'num_count': 190, 'sum_payoffs': 44.49159332541402, 'action': [1.0, 0.0]}, {'num_count': 175, 'sum_payoffs': 38.963231123363535, 'action': [0.0, -1.5707963267948966]}, {'num_count': 190, 'sum_payoffs': 44.45697170511296, 'action': [1.0, 1.5707963267948966]}, {'num_count': 179, 'sum_payoffs': 40.45887148990258, 'action': [0.0, 0.0]}, {'num_count': 184, 'sum_payoffs': 42.268236399927794, 'action': [1.0, -1.5707963267948966]}, {'num_count': 182, 'sum_payoffs': 41.635784818164474, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.17257039055404177, 0.1589464123524069, 0.17257039055404177, 0.16257947320617622, 0.16712079927338783, 0.16530426884650318]
Selected final action: [2.0, 1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 27.574933290481567 s
