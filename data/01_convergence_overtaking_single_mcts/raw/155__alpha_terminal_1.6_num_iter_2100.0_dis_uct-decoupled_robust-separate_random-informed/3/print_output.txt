Searching game tree in timestep 0...
Max timehorizon: 11
Actions to choose Agent 0: dict_values([{'num_count': 240, 'sum_payoffs': 60.60911398149401, 'action': [2.0, 1.5707963267948966]}, {'num_count': 233, 'sum_payoffs': 58.00809624850646, 'action': [1.0, 1.5707963267948966]}, {'num_count': 230, 'sum_payoffs': 56.77797671427788, 'action': [0.0, 0.0]}, {'num_count': 220, 'sum_payoffs': 53.08407184871094, 'action': [0.0, 1.5707963267948966]}, {'num_count': 232, 'sum_payoffs': 57.51067923141587, 'action': [1.0, -1.5707963267948966]}, {'num_count': 227, 'sum_payoffs': 55.723366436862385, 'action': [0.0, -1.5707963267948966]}, {'num_count': 229, 'sum_payoffs': 56.43829464249243, 'action': [1.0, 0.0]}, {'num_count': 240, 'sum_payoffs': 60.593961258219316, 'action': [2.0, -1.5707963267948966]}, {'num_count': 249, 'sum_payoffs': 64.01390967525862, 'action': [2.0, 0.0]}])
Weights num count: [0.1142313184198001, 0.11089957163255593, 0.10947168015230842, 0.10471204188481675, 0.11042360780580676, 0.10804378867206092, 0.10899571632555925, 0.1142313184198001, 0.1185149928605426]
Actions to choose Agent 1: dict_values([{'num_count': 360, 'sum_payoffs': 84.00638092421589, 'action': [1.0, 0.0]}, {'num_count': 360, 'sum_payoffs': 83.98226276021799, 'action': [1.0, 1.5707963267948966]}, {'num_count': 346, 'sum_payoffs': 79.3466514163408, 'action': [0.0, -1.5707963267948966]}, {'num_count': 341, 'sum_payoffs': 77.54810639539636, 'action': [0.0, 0.0]}, {'num_count': 355, 'sum_payoffs': 82.29855865973379, 'action': [1.0, -1.5707963267948966]}, {'num_count': 338, 'sum_payoffs': 76.58525009431656, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.17134697762970014, 0.17134697762970014, 0.1646834840552118, 0.16230366492146597, 0.1689671584959543, 0.16087577344121848]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 51.14578056335449 s
