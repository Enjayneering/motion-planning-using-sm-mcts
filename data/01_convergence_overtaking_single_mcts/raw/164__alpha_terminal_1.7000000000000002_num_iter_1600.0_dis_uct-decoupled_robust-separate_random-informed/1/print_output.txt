Searching game tree in timestep 0...
Max timehorizon: 12
Actions to choose Agent 0: dict_values([{'num_count': 181, 'sum_payoffs': 44.048282963996776, 'action': [1.0, -1.5707963267948966]}, {'num_count': 177, 'sum_payoffs': 42.493302755845804, 'action': [2.0, 1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 42.20565297591325, 'action': [1.0, 0.0]}, {'num_count': 178, 'sum_payoffs': 42.92616569699006, 'action': [0.0, -1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 40.97794689291371, 'action': [0.0, 1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 40.935842905157294, 'action': [0.0, 0.0]}, {'num_count': 178, 'sum_payoffs': 42.98601179953913, 'action': [2.0, -1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 42.860241342646525, 'action': [1.0, 1.5707963267948966]}, {'num_count': 186, 'sum_payoffs': 46.00705857904994, 'action': [2.0, 0.0]}])
Weights num count: [0.11305434103685197, 0.11055590256089944, 0.1099312929419113, 0.11118051217988757, 0.1080574640849469, 0.1080574640849469, 0.11118051217988757, 0.11118051217988757, 0.11617738913179262]
Actions to choose Agent 1: dict_values([{'num_count': 272, 'sum_payoffs': 60.55764838054992, 'action': [1.0, -1.5707963267948966]}, {'num_count': 284, 'sum_payoffs': 64.61055197178925, 'action': [1.0, 0.0]}, {'num_count': 262, 'sum_payoffs': 57.13958107406709, 'action': [0.0, -1.5707963267948966]}, {'num_count': 266, 'sum_payoffs': 58.36888726230972, 'action': [1.0, 1.5707963267948966]}, {'num_count': 258, 'sum_payoffs': 55.83253030621506, 'action': [0.0, 1.5707963267948966]}, {'num_count': 258, 'sum_payoffs': 55.70351317450062, 'action': [0.0, 0.0]}])
Weights num count: [0.16989381636477202, 0.1773891317926296, 0.16364772017489068, 0.16614615865084323, 0.16114928169893816, 0.16114928169893816]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 40.15804719924927 s
