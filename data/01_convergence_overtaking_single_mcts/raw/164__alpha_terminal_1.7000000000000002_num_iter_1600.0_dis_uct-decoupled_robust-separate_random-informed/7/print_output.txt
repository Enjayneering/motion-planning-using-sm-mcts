Searching game tree in timestep 0...
Max timehorizon: 12
Actions to choose Agent 0: dict_values([{'num_count': 176, 'sum_payoffs': 42.1282259864035, 'action': [0.0, 0.0]}, {'num_count': 184, 'sum_payoffs': 45.37218826504787, 'action': [2.0, -1.5707963267948966]}, {'num_count': 180, 'sum_payoffs': 43.83378906194727, 'action': [2.0, 1.5707963267948966]}, {'num_count': 172, 'sum_payoffs': 40.67859025629793, 'action': [0.0, -1.5707963267948966]}, {'num_count': 184, 'sum_payoffs': 45.27058514001328, 'action': [1.0, -1.5707963267948966]}, {'num_count': 172, 'sum_payoffs': 40.726301209208195, 'action': [1.0, 1.5707963267948966]}, {'num_count': 179, 'sum_payoffs': 43.314787628080225, 'action': [1.0, 0.0]}, {'num_count': 179, 'sum_payoffs': 43.297846253949956, 'action': [2.0, 0.0]}, {'num_count': 174, 'sum_payoffs': 41.42672300287226, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.1099312929419113, 0.11492816989381636, 0.11242973141786383, 0.10743285446595878, 0.11492816989381636, 0.10743285446595878, 0.11180512179887571, 0.11180512179887571, 0.10868207370393504]
Actions to choose Agent 1: dict_values([{'num_count': 279, 'sum_payoffs': 62.75515393950782, 'action': [1.0, 0.0]}, {'num_count': 257, 'sum_payoffs': 55.29555260942849, 'action': [0.0, -1.5707963267948966]}, {'num_count': 257, 'sum_payoffs': 55.389503303408986, 'action': [0.0, 1.5707963267948966]}, {'num_count': 271, 'sum_payoffs': 60.10497182588232, 'action': [1.0, 1.5707963267948966]}, {'num_count': 276, 'sum_payoffs': 61.709146849076774, 'action': [1.0, -1.5707963267948966]}, {'num_count': 260, 'sum_payoffs': 56.27655855805801, 'action': [0.0, 0.0]}])
Weights num count: [0.17426608369768895, 0.16052467207995003, 0.16052467207995003, 0.16926920674578388, 0.17239225484072454, 0.16239850093691444]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 40.68321871757507 s
