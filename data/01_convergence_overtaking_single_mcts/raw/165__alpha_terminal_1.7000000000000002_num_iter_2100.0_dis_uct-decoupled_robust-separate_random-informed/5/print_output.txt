Searching game tree in timestep 0...
Max timehorizon: 12
Actions to choose Agent 0: dict_values([{'num_count': 232, 'sum_payoffs': 55.5836538752859, 'action': [1.0, -1.5707963267948966]}, {'num_count': 238, 'sum_payoffs': 57.85363413398884, 'action': [2.0, 1.5707963267948966]}, {'num_count': 234, 'sum_payoffs': 56.433427084785514, 'action': [0.0, -1.5707963267948966]}, {'num_count': 244, 'sum_payoffs': 60.11285140815566, 'action': [2.0, -1.5707963267948966]}, {'num_count': 235, 'sum_payoffs': 56.762486264221245, 'action': [1.0, 0.0]}, {'num_count': 227, 'sum_payoffs': 53.852756710500444, 'action': [0.0, 0.0]}, {'num_count': 239, 'sum_payoffs': 58.19363718060857, 'action': [2.0, 0.0]}, {'num_count': 231, 'sum_payoffs': 55.19544693003729, 'action': [1.0, 1.5707963267948966]}, {'num_count': 220, 'sum_payoffs': 51.24946234017651, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.11042360780580676, 0.11327939076630177, 0.11137553545930509, 0.11613517372679677, 0.11185149928605426, 0.10804378867206092, 0.11375535459305093, 0.1099476439790576, 0.10471204188481675]
Actions to choose Agent 1: dict_values([{'num_count': 359, 'sum_payoffs': 80.01026258638741, 'action': [1.0, 1.5707963267948966]}, {'num_count': 339, 'sum_payoffs': 73.56735407036544, 'action': [0.0, 1.5707963267948966]}, {'num_count': 337, 'sum_payoffs': 72.77805086578623, 'action': [0.0, -1.5707963267948966]}, {'num_count': 360, 'sum_payoffs': 80.33918436691724, 'action': [1.0, 0.0]}, {'num_count': 346, 'sum_payoffs': 75.68657028598781, 'action': [0.0, 0.0]}, {'num_count': 359, 'sum_payoffs': 80.01265366648089, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.17087101380295097, 0.16135173726796764, 0.1603998096144693, 0.17134697762970014, 0.1646834840552118, 0.17087101380295097]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 52.76485896110535 s
