Searching game tree in timestep 0...
Max timehorizon: 12
Actions to choose Agent 0: dict_values([{'num_count': 289, 'sum_payoffs': 69.56417707768651, 'action': [0.0, -1.5707963267948966]}, {'num_count': 297, 'sum_payoffs': 72.51303775704727, 'action': [2.0, 0.0]}, {'num_count': 291, 'sum_payoffs': 70.30528409946882, 'action': [1.0, 0.0]}, {'num_count': 277, 'sum_payoffs': 65.28955363830224, 'action': [0.0, 0.0]}, {'num_count': 292, 'sum_payoffs': 70.66750047835254, 'action': [2.0, 1.5707963267948966]}, {'num_count': 283, 'sum_payoffs': 67.48858295679432, 'action': [0.0, 1.5707963267948966]}, {'num_count': 289, 'sum_payoffs': 69.52336955037515, 'action': [1.0, 1.5707963267948966]}, {'num_count': 293, 'sum_payoffs': 71.0700817043554, 'action': [1.0, -1.5707963267948966]}, {'num_count': 289, 'sum_payoffs': 69.50163476434349, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.1111111111111111, 0.11418685121107267, 0.1118800461361015, 0.10649750096116878, 0.1122645136485967, 0.10880430603613994, 0.1111111111111111, 0.11264898116109189, 0.1111111111111111]
Actions to choose Agent 1: dict_values([{'num_count': 420, 'sum_payoffs': 91.33831861736633, 'action': [0.0, -1.5707963267948966]}, {'num_count': 445, 'sum_payoffs': 99.2001778058764, 'action': [1.0, 1.5707963267948966]}, {'num_count': 445, 'sum_payoffs': 99.19274821194865, 'action': [1.0, -1.5707963267948966]}, {'num_count': 417, 'sum_payoffs': 90.37147056369957, 'action': [0.0, 0.0]}, {'num_count': 453, 'sum_payoffs': 101.69713489691165, 'action': [1.0, 0.0]}, {'num_count': 420, 'sum_payoffs': 91.31993585980186, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.16147635524798154, 0.1710880430603614, 0.1710880430603614, 0.16032295271049596, 0.17416378316032297, 0.16147635524798154]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 66.13161897659302 s
