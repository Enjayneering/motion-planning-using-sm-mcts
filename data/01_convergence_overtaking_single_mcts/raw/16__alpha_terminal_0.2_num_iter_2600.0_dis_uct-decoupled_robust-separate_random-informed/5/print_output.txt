Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 314, 'sum_payoffs': 76.04914932572112, 'action': [2.0, 1.5707963267948966]}, {'num_count': 275, 'sum_payoffs': 62.383808085605274, 'action': [1.0, 1.5707963267948966]}, {'num_count': 239, 'sum_payoffs': 50.05953544137399, 'action': [0.0, -1.5707963267948966]}, {'num_count': 314, 'sum_payoffs': 76.0425946320752, 'action': [1.0, 0.0]}, {'num_count': 269, 'sum_payoffs': 60.292027889088594, 'action': [1.0, -1.5707963267948966]}, {'num_count': 237, 'sum_payoffs': 49.39312951400675, 'action': [0.0, 1.5707963267948966]}, {'num_count': 275, 'sum_payoffs': 62.45152784891283, 'action': [0.0, 0.0]}, {'num_count': 314, 'sum_payoffs': 76.08978118370565, 'action': [2.0, -1.5707963267948966]}, {'num_count': 363, 'sum_payoffs': 93.6289463808025, 'action': [2.0, 0.0]}])
Weights num count: [0.12072279892349097, 0.1057285659361784, 0.0918877354863514, 0.12072279892349097, 0.10342176086120723, 0.09111880046136102, 0.1057285659361784, 0.12072279892349097, 0.1395617070357555]
Actions to choose Agent 1: dict_values([{'num_count': 508, 'sum_payoffs': 148.12014280254743, 'action': [1.0, 0.0]}, {'num_count': 449, 'sum_payoffs': 125.83327899175046, 'action': [1.0, 1.5707963267948966]}, {'num_count': 379, 'sum_payoffs': 99.91580295148339, 'action': [0.0, 1.5707963267948966]}, {'num_count': 450, 'sum_payoffs': 126.28533557209144, 'action': [1.0, -1.5707963267948966]}, {'num_count': 384, 'sum_payoffs': 101.79301651828916, 'action': [0.0, -1.5707963267948966]}, {'num_count': 430, 'sum_payoffs': 118.71260020193776, 'action': [0.0, 0.0]}])
Weights num count: [0.19530949634755862, 0.17262591311034217, 0.14571318723567858, 0.17301038062283736, 0.14763552479815456, 0.1653210303729335]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 4.361835718154907 s
