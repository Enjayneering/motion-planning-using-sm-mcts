Searching game tree in timestep 0...
Max timehorizon: 12
Actions to choose Agent 0: dict_values([{'num_count': 520, 'sum_payoffs': 122.21155547792976, 'action': [2.0, -1.5707963267948966]}, {'num_count': 527, 'sum_payoffs': 124.61771111474995, 'action': [2.0, 1.5707963267948966]}, {'num_count': 495, 'sum_payoffs': 114.12637548224463, 'action': [0.0, 0.0]}, {'num_count': 488, 'sum_payoffs': 111.94358591046198, 'action': [0.0, 1.5707963267948966]}, {'num_count': 530, 'sum_payoffs': 125.5881493649247, 'action': [2.0, 0.0]}, {'num_count': 509, 'sum_payoffs': 118.75223819148995, 'action': [1.0, 1.5707963267948966]}, {'num_count': 507, 'sum_payoffs': 118.07828830881353, 'action': [0.0, -1.5707963267948966]}, {'num_count': 509, 'sum_payoffs': 118.67422650639185, 'action': [1.0, 0.0]}, {'num_count': 515, 'sum_payoffs': 120.67360329711359, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.11301890893284068, 0.11454031732232123, 0.10758530754183873, 0.10606389915235818, 0.11519234948924147, 0.11062812432079983, 0.11019343620951967, 0.11062812432079983, 0.1119321886546403]
Actions to choose Agent 1: dict_values([{'num_count': 793, 'sum_payoffs': 170.49439096575065, 'action': [1.0, 1.5707963267948966]}, {'num_count': 753, 'sum_payoffs': 159.0278523378782, 'action': [0.0, 1.5707963267948966]}, {'num_count': 742, 'sum_payoffs': 155.93444758582177, 'action': [0.0, -1.5707963267948966]}, {'num_count': 794, 'sum_payoffs': 170.85536013572295, 'action': [1.0, 0.0]}, {'num_count': 776, 'sum_payoffs': 165.65439620595382, 'action': [1.0, -1.5707963267948966]}, {'num_count': 742, 'sum_payoffs': 155.9529494015435, 'action': [0.0, 0.0]}])
Weights num count: [0.17235383612258204, 0.16366007389697892, 0.16126928928493806, 0.17257118017822212, 0.16865898717670072, 0.16126928928493806]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 114.75171875953674 s
