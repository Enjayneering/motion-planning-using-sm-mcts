Searching game tree in timestep 0...
Max timehorizon: 12
Actions to choose Agent 0: dict_values([{'num_count': 175, 'sum_payoffs': 42.01681103827704, 'action': [1.0, 0.0]}, {'num_count': 188, 'sum_payoffs': 47.091429120130144, 'action': [2.0, 1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 42.35985418916269, 'action': [0.0, 0.0]}, {'num_count': 180, 'sum_payoffs': 43.97907703271434, 'action': [2.0, -1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 41.29349947561001, 'action': [1.0, 1.5707963267948966]}, {'num_count': 172, 'sum_payoffs': 40.96531989562037, 'action': [1.0, -1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 41.28399041338017, 'action': [0.0, 1.5707963267948966]}, {'num_count': 185, 'sum_payoffs': 45.90258299582004, 'action': [2.0, 0.0]}, {'num_count': 178, 'sum_payoffs': 43.1526665685046, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.10930668332292318, 0.1174266083697689, 0.1099312929419113, 0.11242973141786383, 0.1080574640849469, 0.10743285446595878, 0.1080574640849469, 0.1155527795128045, 0.11118051217988757]
Actions to choose Agent 1: dict_values([{'num_count': 271, 'sum_payoffs': 60.170897803345746, 'action': [1.0, 0.0]}, {'num_count': 275, 'sum_payoffs': 61.44466634807228, 'action': [1.0, 1.5707963267948966]}, {'num_count': 261, 'sum_payoffs': 56.78575795567379, 'action': [0.0, 0.0]}, {'num_count': 273, 'sum_payoffs': 60.829286620605565, 'action': [1.0, -1.5707963267948966]}, {'num_count': 257, 'sum_payoffs': 55.38499866306295, 'action': [0.0, -1.5707963267948966]}, {'num_count': 263, 'sum_payoffs': 57.39911137269211, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.16926920674578388, 0.1717676452217364, 0.16302311055590257, 0.17051842598376016, 0.16052467207995003, 0.16427232979387882]
Selected final action: [2.0, 1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 48.7199490070343 s
