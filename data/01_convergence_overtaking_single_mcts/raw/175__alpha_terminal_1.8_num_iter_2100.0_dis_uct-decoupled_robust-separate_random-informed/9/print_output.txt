Searching game tree in timestep 0...
Max timehorizon: 12
Actions to choose Agent 0: dict_values([{'num_count': 232, 'sum_payoffs': 55.74764873662894, 'action': [1.0, 1.5707963267948966]}, {'num_count': 239, 'sum_payoffs': 58.3255270524962, 'action': [1.0, -1.5707963267948966]}, {'num_count': 221, 'sum_payoffs': 51.64653325077982, 'action': [0.0, 1.5707963267948966]}, {'num_count': 232, 'sum_payoffs': 55.70687329211828, 'action': [1.0, 0.0]}, {'num_count': 244, 'sum_payoffs': 60.17730303103304, 'action': [2.0, 1.5707963267948966]}, {'num_count': 239, 'sum_payoffs': 58.31853826444345, 'action': [2.0, -1.5707963267948966]}, {'num_count': 239, 'sum_payoffs': 58.30899154094206, 'action': [2.0, 0.0]}, {'num_count': 223, 'sum_payoffs': 52.47009525397061, 'action': [0.0, 0.0]}, {'num_count': 231, 'sum_payoffs': 55.329873380508225, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.11042360780580676, 0.11375535459305093, 0.10518800571156592, 0.11042360780580676, 0.11613517372679677, 0.11375535459305093, 0.11375535459305093, 0.10613993336506425, 0.1099476439790576]
Actions to choose Agent 1: dict_values([{'num_count': 361, 'sum_payoffs': 80.68067589380347, 'action': [1.0, 0.0]}, {'num_count': 342, 'sum_payoffs': 74.47901626009086, 'action': [0.0, 1.5707963267948966]}, {'num_count': 336, 'sum_payoffs': 72.50668687568506, 'action': [0.0, -1.5707963267948966]}, {'num_count': 358, 'sum_payoffs': 79.70615235518264, 'action': [1.0, -1.5707963267948966]}, {'num_count': 358, 'sum_payoffs': 79.68736123567747, 'action': [1.0, 1.5707963267948966]}, {'num_count': 345, 'sum_payoffs': 75.45506117329552, 'action': [0.0, 0.0]}])
Weights num count: [0.1718229414564493, 0.16277962874821514, 0.15992384578772012, 0.1703950499762018, 0.1703950499762018, 0.16420752022846263]
Selected final action: [2.0, 1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 55.10356640815735 s
