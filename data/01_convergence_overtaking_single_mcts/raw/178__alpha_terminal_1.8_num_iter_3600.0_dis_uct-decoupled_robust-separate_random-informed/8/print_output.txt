Searching game tree in timestep 0...
Max timehorizon: 12
Actions to choose Agent 0: dict_values([{'num_count': 398, 'sum_payoffs': 93.81354711263269, 'action': [1.0, 0.0]}, {'num_count': 385, 'sum_payoffs': 89.41159891448747, 'action': [0.0, 0.0]}, {'num_count': 403, 'sum_payoffs': 95.5124246467884, 'action': [1.0, -1.5707963267948966]}, {'num_count': 380, 'sum_payoffs': 87.69515526924958, 'action': [0.0, 1.5707963267948966]}, {'num_count': 424, 'sum_payoffs': 102.61682548040244, 'action': [2.0, 0.0]}, {'num_count': 399, 'sum_payoffs': 94.19711324263848, 'action': [0.0, -1.5707963267948966]}, {'num_count': 403, 'sum_payoffs': 95.4936745955593, 'action': [2.0, 1.5707963267948966]}, {'num_count': 409, 'sum_payoffs': 97.58841607581176, 'action': [2.0, -1.5707963267948966]}, {'num_count': 399, 'sum_payoffs': 94.1065176368741, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.11052485420716468, 0.10691474590391557, 0.11191335740072202, 0.10552624271035824, 0.11774507081366287, 0.11080255484587614, 0.11191335740072202, 0.11357956123299083, 0.11080255484587614]
Actions to choose Agent 1: dict_values([{'num_count': 623, 'sum_payoffs': 136.31334038850255, 'action': [1.0, 0.0]}, {'num_count': 580, 'sum_payoffs': 123.39282941617776, 'action': [0.0, -1.5707963267948966]}, {'num_count': 610, 'sum_payoffs': 132.44209417446618, 'action': [1.0, -1.5707963267948966]}, {'num_count': 579, 'sum_payoffs': 123.10511985706675, 'action': [0.0, 1.5707963267948966]}, {'num_count': 626, 'sum_payoffs': 137.18882911031656, 'action': [1.0, 1.5707963267948966]}, {'num_count': 582, 'sum_payoffs': 124.04603877285659, 'action': [0.0, 0.0]}])
Weights num count: [0.1730074979172452, 0.16106637045265204, 0.1693973896139961, 0.16078866981394058, 0.17384059983337963, 0.16162177173007497]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 101.44776177406311 s
