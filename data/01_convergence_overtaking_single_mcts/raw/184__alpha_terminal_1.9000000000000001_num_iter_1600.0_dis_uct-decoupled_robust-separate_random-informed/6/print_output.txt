Searching game tree in timestep 0...
Max timehorizon: 13
Actions to choose Agent 0: dict_values([{'num_count': 177, 'sum_payoffs': 41.24309353673467, 'action': [0.0, 1.5707963267948966]}, {'num_count': 177, 'sum_payoffs': 41.17032316267682, 'action': [1.0, 1.5707963267948966]}, {'num_count': 182, 'sum_payoffs': 43.110264526644215, 'action': [2.0, 0.0]}, {'num_count': 175, 'sum_payoffs': 40.467972991122686, 'action': [0.0, -1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 40.74987080881389, 'action': [0.0, 0.0]}, {'num_count': 180, 'sum_payoffs': 42.43110532420887, 'action': [2.0, -1.5707963267948966]}, {'num_count': 184, 'sum_payoffs': 43.96944151078239, 'action': [1.0, -1.5707963267948966]}, {'num_count': 170, 'sum_payoffs': 38.600014038669556, 'action': [1.0, 0.0]}, {'num_count': 179, 'sum_payoffs': 42.00299140817084, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.11055590256089944, 0.11055590256089944, 0.1136789506558401, 0.10930668332292318, 0.1099312929419113, 0.11242973141786383, 0.11492816989381636, 0.1061836352279825, 0.11180512179887571]
Actions to choose Agent 1: dict_values([{'num_count': 261, 'sum_payoffs': 54.413065302431114, 'action': [0.0, 0.0]}, {'num_count': 271, 'sum_payoffs': 57.75955804050728, 'action': [1.0, -1.5707963267948966]}, {'num_count': 275, 'sum_payoffs': 59.13997356819553, 'action': [1.0, 0.0]}, {'num_count': 265, 'sum_payoffs': 55.84139709642558, 'action': [0.0, -1.5707963267948966]}, {'num_count': 262, 'sum_payoffs': 54.78694258953395, 'action': [0.0, 1.5707963267948966]}, {'num_count': 266, 'sum_payoffs': 56.157203899423955, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.16302311055590257, 0.16926920674578388, 0.1717676452217364, 0.1655215490318551, 0.16364772017489068, 0.16614615865084323]
Selected final action: [1.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.22222222219629628, 0.2777777777453703]
Runtime: 51.469850063323975 s
