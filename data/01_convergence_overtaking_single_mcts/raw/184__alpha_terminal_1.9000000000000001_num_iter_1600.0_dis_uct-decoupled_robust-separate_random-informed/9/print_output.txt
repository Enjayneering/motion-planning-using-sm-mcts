Searching game tree in timestep 0...
Max timehorizon: 13
Actions to choose Agent 0: dict_values([{'num_count': 174, 'sum_payoffs': 40.052882426788535, 'action': [0.0, 0.0]}, {'num_count': 177, 'sum_payoffs': 41.19774520133286, 'action': [0.0, -1.5707963267948966]}, {'num_count': 175, 'sum_payoffs': 40.42993565157639, 'action': [1.0, 1.5707963267948966]}, {'num_count': 175, 'sum_payoffs': 40.533263805522196, 'action': [1.0, 0.0]}, {'num_count': 182, 'sum_payoffs': 43.10457912249441, 'action': [2.0, 0.0]}, {'num_count': 180, 'sum_payoffs': 42.27985018419883, 'action': [2.0, 1.5707963267948966]}, {'num_count': 181, 'sum_payoffs': 42.696277394965534, 'action': [2.0, -1.5707963267948966]}, {'num_count': 179, 'sum_payoffs': 41.90796189390706, 'action': [1.0, -1.5707963267948966]}, {'num_count': 177, 'sum_payoffs': 41.204235828477, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.10868207370393504, 0.11055590256089944, 0.10930668332292318, 0.10930668332292318, 0.1136789506558401, 0.11242973141786383, 0.11305434103685197, 0.11180512179887571, 0.11055590256089944]
Actions to choose Agent 1: dict_values([{'num_count': 269, 'sum_payoffs': 57.386124399503665, 'action': [0.0, -1.5707963267948966]}, {'num_count': 268, 'sum_payoffs': 57.06109064876398, 'action': [1.0, 0.0]}, {'num_count': 260, 'sum_payoffs': 54.39636546503993, 'action': [0.0, 0.0]}, {'num_count': 254, 'sum_payoffs': 52.48744253928362, 'action': [0.0, 1.5707963267948966]}, {'num_count': 278, 'sum_payoffs': 60.39511206578174, 'action': [1.0, 1.5707963267948966]}, {'num_count': 271, 'sum_payoffs': 57.99717634879566, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.1680199875078076, 0.16739537788881947, 0.16239850093691444, 0.15865084322298564, 0.1736414740787008, 0.16926920674578388]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 45.92442178726196 s
