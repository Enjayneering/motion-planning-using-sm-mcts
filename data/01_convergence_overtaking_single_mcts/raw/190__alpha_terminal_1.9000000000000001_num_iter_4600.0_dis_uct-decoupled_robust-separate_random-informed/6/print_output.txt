Searching game tree in timestep 0...
Max timehorizon: 13
Actions to choose Agent 0: dict_values([{'num_count': 547, 'sum_payoffs': 126.8559955153775, 'action': [2.0, 0.0]}, {'num_count': 500, 'sum_payoffs': 111.80228375052761, 'action': [1.0, 1.5707963267948966]}, {'num_count': 502, 'sum_payoffs': 112.5036019636829, 'action': [0.0, -1.5707963267948966]}, {'num_count': 516, 'sum_payoffs': 116.98876337920005, 'action': [2.0, 1.5707963267948966]}, {'num_count': 522, 'sum_payoffs': 118.85272871557393, 'action': [2.0, -1.5707963267948966]}, {'num_count': 518, 'sum_payoffs': 117.59517236235769, 'action': [1.0, 0.0]}, {'num_count': 494, 'sum_payoffs': 110.02939478848137, 'action': [0.0, 1.5707963267948966]}, {'num_count': 492, 'sum_payoffs': 109.41505891811379, 'action': [0.0, 0.0]}, {'num_count': 509, 'sum_payoffs': 114.71694084463803, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.1188871984351228, 0.10867202782003912, 0.10910671593131928, 0.11214953271028037, 0.11345359704412085, 0.11258422082156053, 0.10736796348619865, 0.1069332753749185, 0.11062812432079983]
Actions to choose Agent 1: dict_values([{'num_count': 799, 'sum_payoffs': 165.96679216745943, 'action': [1.0, 0.0]}, {'num_count': 758, 'sum_payoffs': 154.50273845336315, 'action': [0.0, 0.0]}, {'num_count': 787, 'sum_payoffs': 162.57164113900572, 'action': [1.0, -1.5707963267948966]}, {'num_count': 784, 'sum_payoffs': 161.7813411583659, 'action': [1.0, 1.5707963267948966]}, {'num_count': 740, 'sum_payoffs': 149.46614575779424, 'action': [0.0, 1.5707963267948966]}, {'num_count': 732, 'sum_payoffs': 147.2849572326531, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.17365790045642251, 0.16474679417517932, 0.1710497717887416, 0.17039773962182134, 0.1608346011736579, 0.15909584872853727]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 134.1496617794037 s
