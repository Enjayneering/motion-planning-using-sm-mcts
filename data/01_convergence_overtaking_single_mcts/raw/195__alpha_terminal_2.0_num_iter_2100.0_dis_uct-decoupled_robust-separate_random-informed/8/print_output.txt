Searching game tree in timestep 0...
Max timehorizon: 14
Actions to choose Agent 0: dict_values([{'num_count': 237, 'sum_payoffs': 54.317710323832515, 'action': [2.0, -1.5707963267948966]}, {'num_count': 228, 'sum_payoffs': 51.03817628589736, 'action': [1.0, 0.0]}, {'num_count': 229, 'sum_payoffs': 51.45899126139177, 'action': [0.0, 0.0]}, {'num_count': 229, 'sum_payoffs': 51.404761119314365, 'action': [1.0, 1.5707963267948966]}, {'num_count': 238, 'sum_payoffs': 54.67742359441991, 'action': [1.0, -1.5707963267948966]}, {'num_count': 230, 'sum_payoffs': 51.71830723814767, 'action': [0.0, 1.5707963267948966]}, {'num_count': 241, 'sum_payoffs': 55.75833997519194, 'action': [2.0, 0.0]}, {'num_count': 234, 'sum_payoffs': 53.199180355466304, 'action': [0.0, -1.5707963267948966]}, {'num_count': 234, 'sum_payoffs': 53.10711337684809, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.1128034269395526, 0.10851975249881009, 0.10899571632555925, 0.10899571632555925, 0.11327939076630177, 0.10947168015230842, 0.11470728224654926, 0.11137553545930509, 0.11137553545930509]
Actions to choose Agent 1: dict_values([{'num_count': 334, 'sum_payoffs': 67.24176523385172, 'action': [0.0, 0.0]}, {'num_count': 344, 'sum_payoffs': 70.28204767142759, 'action': [0.0, 1.5707963267948966]}, {'num_count': 361, 'sum_payoffs': 75.62836468444587, 'action': [1.0, 0.0]}, {'num_count': 360, 'sum_payoffs': 75.30208196531542, 'action': [1.0, -1.5707963267948966]}, {'num_count': 340, 'sum_payoffs': 69.08479152454628, 'action': [0.0, -1.5707963267948966]}, {'num_count': 361, 'sum_payoffs': 75.53046078877382, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.1589719181342218, 0.16373155640171347, 0.1718229414564493, 0.17134697762970014, 0.1618277010947168, 0.1718229414564493]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 69.23209047317505 s
