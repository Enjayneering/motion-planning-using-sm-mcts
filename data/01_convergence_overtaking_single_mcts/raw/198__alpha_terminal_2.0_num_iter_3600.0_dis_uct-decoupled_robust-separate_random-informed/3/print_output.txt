Searching game tree in timestep 0...
Max timehorizon: 14
Actions to choose Agent 0: dict_values([{'num_count': 417, 'sum_payoffs': 95.07812398075576, 'action': [2.0, 0.0]}, {'num_count': 381, 'sum_payoffs': 83.40536807258945, 'action': [0.0, 1.5707963267948966]}, {'num_count': 403, 'sum_payoffs': 90.4526673409599, 'action': [1.0, 1.5707963267948966]}, {'num_count': 396, 'sum_payoffs': 88.21515290011712, 'action': [1.0, 0.0]}, {'num_count': 405, 'sum_payoffs': 91.14346590455825, 'action': [1.0, -1.5707963267948966]}, {'num_count': 398, 'sum_payoffs': 88.82991563196808, 'action': [0.0, 0.0]}, {'num_count': 413, 'sum_payoffs': 93.76855537071312, 'action': [2.0, -1.5707963267948966]}, {'num_count': 402, 'sum_payoffs': 90.06530880341698, 'action': [2.0, 1.5707963267948966]}, {'num_count': 385, 'sum_payoffs': 84.69677796705679, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.11580116634268259, 0.1058039433490697, 0.11191335740072202, 0.10996945292974174, 0.11246875867814496, 0.11052485420716468, 0.11469036378783672, 0.11163565676201055, 0.10691474590391557]
Actions to choose Agent 1: dict_values([{'num_count': 575, 'sum_payoffs': 114.05337365064744, 'action': [0.0, 0.0]}, {'num_count': 591, 'sum_payoffs': 118.62496565592474, 'action': [0.0, -1.5707963267948966]}, {'num_count': 623, 'sum_payoffs': 127.78343410797022, 'action': [1.0, 0.0]}, {'num_count': 588, 'sum_payoffs': 117.77339756918717, 'action': [0.0, 1.5707963267948966]}, {'num_count': 612, 'sum_payoffs': 124.52716754451238, 'action': [1.0, 1.5707963267948966]}, {'num_count': 611, 'sum_payoffs': 124.338326974638, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.1596778672590947, 0.1641210774784782, 0.1730074979172452, 0.16328797556234378, 0.16995279089141904, 0.16967509025270758]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 101.7769455909729 s
