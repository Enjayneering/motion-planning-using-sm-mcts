Searching game tree in timestep 0...
Max timehorizon: 14
Actions to choose Agent 0: dict_values([{'num_count': 173, 'sum_payoffs': 38.62647357409914, 'action': [1.0, 1.5707963267948966]}, {'num_count': 189, 'sum_payoffs': 44.60319890146069, 'action': [2.0, 0.0]}, {'num_count': 177, 'sum_payoffs': 40.22014820743759, 'action': [1.0, -1.5707963267948966]}, {'num_count': 170, 'sum_payoffs': 37.593121033901866, 'action': [1.0, 0.0]}, {'num_count': 176, 'sum_payoffs': 39.84914534748614, 'action': [2.0, 1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 40.43897882358156, 'action': [0.0, -1.5707963267948966]}, {'num_count': 177, 'sum_payoffs': 40.09411850200228, 'action': [0.0, 0.0]}, {'num_count': 184, 'sum_payoffs': 42.74674421509796, 'action': [2.0, -1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 39.75474049709244, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.1080574640849469, 0.11805121798875702, 0.11055590256089944, 0.1061836352279825, 0.1099312929419113, 0.11118051217988757, 0.11055590256089944, 0.11492816989381636, 0.1099312929419113]
Actions to choose Agent 1: dict_values([{'num_count': 263, 'sum_payoffs': 53.56481893606719, 'action': [0.0, 1.5707963267948966]}, {'num_count': 258, 'sum_payoffs': 51.886424964454484, 'action': [0.0, -1.5707963267948966]}, {'num_count': 269, 'sum_payoffs': 55.416123647764856, 'action': [1.0, 1.5707963267948966]}, {'num_count': 278, 'sum_payoffs': 58.32793993736407, 'action': [1.0, 0.0]}, {'num_count': 259, 'sum_payoffs': 52.16340963485443, 'action': [0.0, 0.0]}, {'num_count': 273, 'sum_payoffs': 56.70755353468453, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.16427232979387882, 0.16114928169893816, 0.1680199875078076, 0.1736414740787008, 0.1617738913179263, 0.17051842598376016]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 46.866395473480225 s
