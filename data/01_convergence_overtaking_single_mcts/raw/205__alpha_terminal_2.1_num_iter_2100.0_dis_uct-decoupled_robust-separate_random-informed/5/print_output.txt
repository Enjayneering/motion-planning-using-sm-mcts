Searching game tree in timestep 0...
Max timehorizon: 14
Actions to choose Agent 0: dict_values([{'num_count': 237, 'sum_payoffs': 54.472891346421896, 'action': [1.0, -1.5707963267948966]}, {'num_count': 222, 'sum_payoffs': 49.15971448002686, 'action': [1.0, 0.0]}, {'num_count': 234, 'sum_payoffs': 53.44018435731887, 'action': [0.0, 0.0]}, {'num_count': 232, 'sum_payoffs': 52.64176831378006, 'action': [1.0, 1.5707963267948966]}, {'num_count': 243, 'sum_payoffs': 56.650960819779336, 'action': [2.0, 0.0]}, {'num_count': 232, 'sum_payoffs': 52.659365900359475, 'action': [0.0, -1.5707963267948966]}, {'num_count': 234, 'sum_payoffs': 53.3301810684503, 'action': [2.0, -1.5707963267948966]}, {'num_count': 230, 'sum_payoffs': 51.939299510256426, 'action': [0.0, 1.5707963267948966]}, {'num_count': 236, 'sum_payoffs': 54.10712922805634, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.1128034269395526, 0.10566396953831508, 0.11137553545930509, 0.11042360780580676, 0.11565920990004759, 0.11042360780580676, 0.11137553545930509, 0.10947168015230842, 0.11232746311280342]
Actions to choose Agent 1: dict_values([{'num_count': 347, 'sum_payoffs': 70.92774960651495, 'action': [1.0, -1.5707963267948966]}, {'num_count': 365, 'sum_payoffs': 76.49547128571959, 'action': [1.0, 0.0]}, {'num_count': 352, 'sum_payoffs': 72.50138032112996, 'action': [0.0, -1.5707963267948966]}, {'num_count': 338, 'sum_payoffs': 68.23550208254021, 'action': [0.0, 0.0]}, {'num_count': 354, 'sum_payoffs': 73.16588375636172, 'action': [1.0, 1.5707963267948966]}, {'num_count': 344, 'sum_payoffs': 70.06793265309402, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.16515944788196096, 0.173726796763446, 0.16753926701570682, 0.16087577344121848, 0.16849119466920515, 0.16373155640171347]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 62.6552529335022 s
