Searching game tree in timestep 0...
Max timehorizon: 14
Actions to choose Agent 0: dict_values([{'num_count': 293, 'sum_payoffs': 67.27318282926747, 'action': [2.0, 1.5707963267948966]}, {'num_count': 291, 'sum_payoffs': 66.58528877339397, 'action': [1.0, 1.5707963267948966]}, {'num_count': 281, 'sum_payoffs': 63.0208742889135, 'action': [0.0, -1.5707963267948966]}, {'num_count': 297, 'sum_payoffs': 68.61833455534126, 'action': [2.0, -1.5707963267948966]}, {'num_count': 277, 'sum_payoffs': 61.8090605231727, 'action': [0.0, 1.5707963267948966]}, {'num_count': 286, 'sum_payoffs': 64.82431536461755, 'action': [0.0, 0.0]}, {'num_count': 294, 'sum_payoffs': 67.5998420537895, 'action': [1.0, -1.5707963267948966]}, {'num_count': 282, 'sum_payoffs': 63.487633104366395, 'action': [1.0, 0.0]}, {'num_count': 299, 'sum_payoffs': 69.363624253989, 'action': [2.0, 0.0]}])
Weights num count: [0.11264898116109189, 0.1118800461361015, 0.10803537101114956, 0.11418685121107267, 0.10649750096116878, 0.10995770857362552, 0.11303344867358708, 0.10841983852364476, 0.11495578623606305]
Actions to choose Agent 1: dict_values([{'num_count': 419, 'sum_payoffs': 84.62220267008172, 'action': [0.0, -1.5707963267948966]}, {'num_count': 443, 'sum_payoffs': 91.82349602210023, 'action': [1.0, 1.5707963267948966]}, {'num_count': 437, 'sum_payoffs': 89.96120261338866, 'action': [1.0, 0.0]}, {'num_count': 425, 'sum_payoffs': 86.32904893806335, 'action': [0.0, 0.0]}, {'num_count': 423, 'sum_payoffs': 85.81177954281408, 'action': [0.0, 1.5707963267948966]}, {'num_count': 453, 'sum_payoffs': 94.87189979455131, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.16109188773548636, 0.170319108035371, 0.16801230296039985, 0.16339869281045752, 0.16262975778546712, 0.17416378316032297]
Selected final action: [2.0, 0.0, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 77.51672434806824 s
