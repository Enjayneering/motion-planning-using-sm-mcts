Searching game tree in timestep 0...
Max timehorizon: 14
Actions to choose Agent 0: dict_values([{'num_count': 505, 'sum_payoffs': 109.8318478275623, 'action': [2.0, -1.5707963267948966]}, {'num_count': 545, 'sum_payoffs': 122.26901112150983, 'action': [2.0, 0.0]}, {'num_count': 506, 'sum_payoffs': 110.14938045021347, 'action': [1.0, 0.0]}, {'num_count': 502, 'sum_payoffs': 108.88626436008954, 'action': [0.0, 0.0]}, {'num_count': 492, 'sum_payoffs': 105.85951014261367, 'action': [0.0, 1.5707963267948966]}, {'num_count': 504, 'sum_payoffs': 109.61220198423834, 'action': [1.0, 1.5707963267948966]}, {'num_count': 520, 'sum_payoffs': 114.56454519351949, 'action': [2.0, 1.5707963267948966]}, {'num_count': 522, 'sum_payoffs': 115.16689951202653, 'action': [1.0, -1.5707963267948966]}, {'num_count': 504, 'sum_payoffs': 109.6172087279826, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.10975874809823952, 0.11845251032384264, 0.10997609215387959, 0.10910671593131928, 0.1069332753749185, 0.10954140404259943, 0.11301890893284068, 0.11345359704412085, 0.10954140404259943]
Actions to choose Agent 1: dict_values([{'num_count': 794, 'sum_payoffs': 159.9816326238541, 'action': [1.0, 0.0]}, {'num_count': 736, 'sum_payoffs': 144.1997592031702, 'action': [0.0, -1.5707963267948966]}, {'num_count': 737, 'sum_payoffs': 144.4338948054095, 'action': [0.0, 1.5707963267948966]}, {'num_count': 802, 'sum_payoffs': 162.18672298643455, 'action': [1.0, 1.5707963267948966]}, {'num_count': 786, 'sum_payoffs': 157.7961377669922, 'action': [1.0, -1.5707963267948966]}, {'num_count': 745, 'sum_payoffs': 146.6363164848155, 'action': [0.0, 0.0]}])
Weights num count: [0.17257118017822212, 0.15996522495109758, 0.16018256900673766, 0.17430993262334274, 0.1708324277331015, 0.16192132145185828]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 119.98528909683228 s
