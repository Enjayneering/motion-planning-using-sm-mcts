Searching game tree in timestep 0...
Max timehorizon: 15
Actions to choose Agent 0: dict_values([{'num_count': 230, 'sum_payoffs': 50.806301385268554, 'action': [1.0, 0.0]}, {'num_count': 223, 'sum_payoffs': 48.37404811513918, 'action': [0.0, 0.0]}, {'num_count': 227, 'sum_payoffs': 49.70680036884481, 'action': [1.0, 1.5707963267948966]}, {'num_count': 242, 'sum_payoffs': 54.99658504957924, 'action': [2.0, -1.5707963267948966]}, {'num_count': 247, 'sum_payoffs': 56.80144249046795, 'action': [2.0, 0.0]}, {'num_count': 240, 'sum_payoffs': 54.22353396940017, 'action': [1.0, -1.5707963267948966]}, {'num_count': 221, 'sum_payoffs': 47.57559682862528, 'action': [0.0, 1.5707963267948966]}, {'num_count': 240, 'sum_payoffs': 54.22013333175878, 'action': [2.0, 1.5707963267948966]}, {'num_count': 230, 'sum_payoffs': 50.74932839382579, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.10947168015230842, 0.10613993336506425, 0.10804378867206092, 0.11518324607329843, 0.11756306520704426, 0.1142313184198001, 0.10518800571156592, 0.1142313184198001, 0.10947168015230842]
Actions to choose Agent 1: dict_values([{'num_count': 340, 'sum_payoffs': 67.22846311827432, 'action': [0.0, -1.5707963267948966]}, {'num_count': 360, 'sum_payoffs': 73.30733565810047, 'action': [1.0, 1.5707963267948966]}, {'num_count': 355, 'sum_payoffs': 71.69888815101179, 'action': [1.0, 0.0]}, {'num_count': 360, 'sum_payoffs': 73.25479585191108, 'action': [1.0, -1.5707963267948966]}, {'num_count': 350, 'sum_payoffs': 70.18984506133911, 'action': [0.0, 0.0]}, {'num_count': 335, 'sum_payoffs': 65.67267142146717, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.1618277010947168, 0.17134697762970014, 0.1689671584959543, 0.17134697762970014, 0.16658733936220846, 0.15944788196097096]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 60.37914443016052 s
