Searching game tree in timestep 0...
Max timehorizon: 15
Actions to choose Agent 0: dict_values([{'num_count': 294, 'sum_payoffs': 65.80879940929272, 'action': [2.0, 1.5707963267948966]}, {'num_count': 291, 'sum_payoffs': 64.8318604180235, 'action': [2.0, -1.5707963267948966]}, {'num_count': 283, 'sum_payoffs': 62.19306851464046, 'action': [1.0, 1.5707963267948966]}, {'num_count': 289, 'sum_payoffs': 64.17156666044312, 'action': [0.0, -1.5707963267948966]}, {'num_count': 283, 'sum_payoffs': 62.101678323969274, 'action': [1.0, 0.0]}, {'num_count': 294, 'sum_payoffs': 65.91132869789148, 'action': [1.0, -1.5707963267948966]}, {'num_count': 304, 'sum_payoffs': 69.287238536448, 'action': [2.0, 0.0]}, {'num_count': 277, 'sum_payoffs': 60.03090400306635, 'action': [0.0, 1.5707963267948966]}, {'num_count': 285, 'sum_payoffs': 62.840097692117375, 'action': [0.0, 0.0]}])
Weights num count: [0.11303344867358708, 0.1118800461361015, 0.10880430603613994, 0.1111111111111111, 0.10880430603613994, 0.11303344867358708, 0.11687812379853903, 0.10649750096116878, 0.10957324106113034]
Actions to choose Agent 1: dict_values([{'num_count': 445, 'sum_payoffs': 90.5437118627456, 'action': [1.0, 0.0]}, {'num_count': 438, 'sum_payoffs': 88.37717889909858, 'action': [1.0, 1.5707963267948966]}, {'num_count': 423, 'sum_payoffs': 83.97213621201972, 'action': [0.0, 1.5707963267948966]}, {'num_count': 413, 'sum_payoffs': 81.07553623386869, 'action': [0.0, 0.0]}, {'num_count': 453, 'sum_payoffs': 92.91819511397821, 'action': [1.0, -1.5707963267948966]}, {'num_count': 428, 'sum_payoffs': 85.44293895155731, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.1710880430603614, 0.16839677047289503, 0.16262975778546712, 0.1587850826605152, 0.17416378316032297, 0.1645520953479431]
Selected final action: [2.0, 0.0, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 74.61828780174255 s
