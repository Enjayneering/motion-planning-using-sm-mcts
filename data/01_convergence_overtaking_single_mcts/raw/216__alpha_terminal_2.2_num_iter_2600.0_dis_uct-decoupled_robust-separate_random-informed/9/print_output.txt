Searching game tree in timestep 0...
Max timehorizon: 15
Actions to choose Agent 0: dict_values([{'num_count': 271, 'sum_payoffs': 58.236494459580506, 'action': [0.0, 0.0]}, {'num_count': 301, 'sum_payoffs': 68.41002350040925, 'action': [2.0, -1.5707963267948966]}, {'num_count': 288, 'sum_payoffs': 64.10217754063213, 'action': [1.0, 1.5707963267948966]}, {'num_count': 293, 'sum_payoffs': 65.79890845326824, 'action': [2.0, 1.5707963267948966]}, {'num_count': 300, 'sum_payoffs': 68.16435215998038, 'action': [2.0, 0.0]}, {'num_count': 292, 'sum_payoffs': 65.34206291076103, 'action': [1.0, 0.0]}, {'num_count': 277, 'sum_payoffs': 60.3039411428875, 'action': [0.0, 1.5707963267948966]}, {'num_count': 289, 'sum_payoffs': 64.40728112978492, 'action': [1.0, -1.5707963267948966]}, {'num_count': 289, 'sum_payoffs': 64.28622018176604, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.10419069588619762, 0.11572472126105345, 0.11072664359861592, 0.11264898116109189, 0.11534025374855825, 0.1122645136485967, 0.10649750096116878, 0.1111111111111111, 0.1111111111111111]
Actions to choose Agent 1: dict_values([{'num_count': 447, 'sum_payoffs': 90.7382531457922, 'action': [1.0, 1.5707963267948966]}, {'num_count': 451, 'sum_payoffs': 91.98614231323302, 'action': [1.0, 0.0]}, {'num_count': 413, 'sum_payoffs': 80.73950707414241, 'action': [0.0, -1.5707963267948966]}, {'num_count': 446, 'sum_payoffs': 90.50017506140647, 'action': [1.0, -1.5707963267948966]}, {'num_count': 420, 'sum_payoffs': 82.8210152712519, 'action': [0.0, 1.5707963267948966]}, {'num_count': 423, 'sum_payoffs': 83.62445366191683, 'action': [0.0, 0.0]}])
Weights num count: [0.17185697808535177, 0.17339484813533257, 0.1587850826605152, 0.1714725105728566, 0.16147635524798154, 0.16262975778546712]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 74.15514969825745 s
