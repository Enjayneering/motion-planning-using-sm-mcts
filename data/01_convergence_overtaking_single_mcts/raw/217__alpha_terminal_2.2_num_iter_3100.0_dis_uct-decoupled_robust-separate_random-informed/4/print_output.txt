Searching game tree in timestep 0...
Max timehorizon: 15
Actions to choose Agent 0: dict_values([{'num_count': 343, 'sum_payoffs': 75.5611881314479, 'action': [1.0, 0.0]}, {'num_count': 338, 'sum_payoffs': 73.92729429192454, 'action': [0.0, -1.5707963267948966]}, {'num_count': 364, 'sum_payoffs': 82.52760013805366, 'action': [2.0, 0.0]}, {'num_count': 340, 'sum_payoffs': 74.6002471746532, 'action': [1.0, 1.5707963267948966]}, {'num_count': 358, 'sum_payoffs': 80.55318037257817, 'action': [2.0, 1.5707963267948966]}, {'num_count': 349, 'sum_payoffs': 77.4881163544067, 'action': [1.0, -1.5707963267948966]}, {'num_count': 331, 'sum_payoffs': 71.65730169143713, 'action': [0.0, 0.0]}, {'num_count': 351, 'sum_payoffs': 78.12464746382201, 'action': [2.0, -1.5707963267948966]}, {'num_count': 326, 'sum_payoffs': 70.01356263610303, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.11060948081264109, 0.10899709771041599, 0.11738148984198646, 0.10964205095130602, 0.11544663011931634, 0.11254434053531119, 0.10673976136730087, 0.11318929377620122, 0.10512737826507579]
Actions to choose Agent 1: dict_values([{'num_count': 508, 'sum_payoffs': 100.0000044418283, 'action': [0.0, -1.5707963267948966]}, {'num_count': 499, 'sum_payoffs': 97.45855182102305, 'action': [0.0, 0.0]}, {'num_count': 524, 'sum_payoffs': 104.65920332794694, 'action': [1.0, 0.0]}, {'num_count': 531, 'sum_payoffs': 106.63606456393009, 'action': [1.0, 1.5707963267948966]}, {'num_count': 505, 'sum_payoffs': 99.12481239539802, 'action': [0.0, 1.5707963267948966]}, {'num_count': 533, 'sum_payoffs': 107.2618672575817, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.163818123186069, 0.16091583360206385, 0.1689777491131893, 0.17123508545630442, 0.16285069332473395, 0.17188003869719445]
Selected final action: [2.0, 0.0, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 97.05559730529785 s
