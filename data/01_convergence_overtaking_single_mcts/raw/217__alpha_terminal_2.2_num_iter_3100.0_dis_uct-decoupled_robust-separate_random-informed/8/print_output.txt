Searching game tree in timestep 0...
Max timehorizon: 15
Actions to choose Agent 0: dict_values([{'num_count': 343, 'sum_payoffs': 75.52788024048944, 'action': [1.0, 1.5707963267948966]}, {'num_count': 348, 'sum_payoffs': 77.16281855926148, 'action': [1.0, 0.0]}, {'num_count': 340, 'sum_payoffs': 74.49558245751206, 'action': [0.0, 1.5707963267948966]}, {'num_count': 360, 'sum_payoffs': 81.18530583637359, 'action': [2.0, 0.0]}, {'num_count': 329, 'sum_payoffs': 70.89668662379007, 'action': [0.0, 0.0]}, {'num_count': 354, 'sum_payoffs': 79.14346536739653, 'action': [2.0, -1.5707963267948966]}, {'num_count': 332, 'sum_payoffs': 71.97753704602057, 'action': [0.0, -1.5707963267948966]}, {'num_count': 350, 'sum_payoffs': 77.76338950832286, 'action': [1.0, -1.5707963267948966]}, {'num_count': 344, 'sum_payoffs': 75.80427313906706, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.11060948081264109, 0.11222186391486617, 0.10964205095130602, 0.11609158336020639, 0.10609480812641084, 0.11415672363753628, 0.10706223798774589, 0.11286681715575621, 0.1109319574330861]
Actions to choose Agent 1: dict_values([{'num_count': 511, 'sum_payoffs': 101.54097006107305, 'action': [0.0, -1.5707963267948966]}, {'num_count': 511, 'sum_payoffs': 101.59040735239176, 'action': [0.0, 0.0]}, {'num_count': 530, 'sum_payoffs': 107.0079088451761, 'action': [1.0, -1.5707963267948966]}, {'num_count': 501, 'sum_payoffs': 98.62377220470023, 'action': [0.0, 1.5707963267948966]}, {'num_count': 532, 'sum_payoffs': 107.64168238203976, 'action': [1.0, 0.0]}, {'num_count': 515, 'sum_payoffs': 102.68469637934717, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.16478555304740405, 0.16478555304740405, 0.1709126088358594, 0.16156078684295389, 0.17155756207674944, 0.16607545952918412]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 91.27732706069946 s
