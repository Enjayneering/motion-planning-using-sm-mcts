Searching game tree in timestep 0...
Max timehorizon: 15
Actions to choose Agent 0: dict_values([{'num_count': 398, 'sum_payoffs': 86.61341932334021, 'action': [1.0, 0.0]}, {'num_count': 403, 'sum_payoffs': 88.20531380662466, 'action': [1.0, 1.5707963267948966]}, {'num_count': 412, 'sum_payoffs': 91.09402499158054, 'action': [2.0, 0.0]}, {'num_count': 390, 'sum_payoffs': 84.00151997312841, 'action': [0.0, -1.5707963267948966]}, {'num_count': 385, 'sum_payoffs': 82.54293385411908, 'action': [0.0, 0.0]}, {'num_count': 400, 'sum_payoffs': 87.28256510508565, 'action': [1.0, -1.5707963267948966]}, {'num_count': 410, 'sum_payoffs': 90.44171829981588, 'action': [2.0, 1.5707963267948966]}, {'num_count': 418, 'sum_payoffs': 92.97358399551817, 'action': [2.0, -1.5707963267948966]}, {'num_count': 384, 'sum_payoffs': 82.20969697317031, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.11052485420716468, 0.11191335740072202, 0.11441266314912524, 0.10830324909747292, 0.10691474590391557, 0.11108025548458761, 0.11385726187170231, 0.11607886698139405, 0.10663704526520411]
Actions to choose Agent 1: dict_values([{'num_count': 581, 'sum_payoffs': 113.18036217456752, 'action': [0.0, 0.0]}, {'num_count': 621, 'sum_payoffs': 124.39395209767646, 'action': [1.0, 1.5707963267948966]}, {'num_count': 616, 'sum_payoffs': 123.00437693959698, 'action': [1.0, 0.0]}, {'num_count': 574, 'sum_payoffs': 111.20043476867627, 'action': [0.0, -1.5707963267948966]}, {'num_count': 617, 'sum_payoffs': 123.21038494843788, 'action': [1.0, -1.5707963267948966]}, {'num_count': 591, 'sum_payoffs': 115.92949093570054, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.1613440710913635, 0.17245209663982228, 0.17106359344626493, 0.15940016662038323, 0.1713412940849764, 0.1641210774784782]
Selected final action: [2.0, -1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 106.64264249801636 s
