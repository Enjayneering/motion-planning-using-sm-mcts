Searching game tree in timestep 0...
Max timehorizon: 15
Actions to choose Agent 0: dict_values([{'num_count': 396, 'sum_payoffs': 85.88220879742225, 'action': [0.0, 1.5707963267948966]}, {'num_count': 405, 'sum_payoffs': 88.78189645355955, 'action': [1.0, -1.5707963267948966]}, {'num_count': 388, 'sum_payoffs': 83.36198339172624, 'action': [0.0, 0.0]}, {'num_count': 389, 'sum_payoffs': 83.63868574236224, 'action': [1.0, 0.0]}, {'num_count': 416, 'sum_payoffs': 92.31114576280446, 'action': [2.0, -1.5707963267948966]}, {'num_count': 401, 'sum_payoffs': 87.49158328184095, 'action': [2.0, 1.5707963267948966]}, {'num_count': 400, 'sum_payoffs': 87.16535227711574, 'action': [1.0, 1.5707963267948966]}, {'num_count': 389, 'sum_payoffs': 83.69844975287938, 'action': [0.0, -1.5707963267948966]}, {'num_count': 416, 'sum_payoffs': 92.34453719672825, 'action': [2.0, 0.0]}])
Weights num count: [0.10996945292974174, 0.11246875867814496, 0.10774784782004998, 0.10802554845876146, 0.11552346570397112, 0.11135795612329909, 0.11108025548458761, 0.10802554845876146, 0.11552346570397112]
Actions to choose Agent 1: dict_values([{'num_count': 588, 'sum_payoffs': 114.32003132769283, 'action': [0.0, 0.0]}, {'num_count': 619, 'sum_payoffs': 123.04853869255102, 'action': [1.0, 1.5707963267948966]}, {'num_count': 606, 'sum_payoffs': 119.34210992459244, 'action': [1.0, 0.0]}, {'num_count': 612, 'sum_payoffs': 121.0391295624736, 'action': [1.0, -1.5707963267948966]}, {'num_count': 581, 'sum_payoffs': 112.36291831234853, 'action': [0.0, -1.5707963267948966]}, {'num_count': 594, 'sum_payoffs': 116.03312260099727, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.16328797556234378, 0.17189669536239932, 0.16828658705915023, 0.16995279089141904, 0.1613440710913635, 0.1649541793946126]
Selected final action: [2.0, -1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 105.79595613479614 s
