Searching game tree in timestep 0...
Max timehorizon: 15
Actions to choose Agent 0: dict_values([{'num_count': 450, 'sum_payoffs': 96.65934907333185, 'action': [1.0, 0.0]}, {'num_count': 465, 'sum_payoffs': 101.36496699535196, 'action': [1.0, 1.5707963267948966]}, {'num_count': 434, 'sum_payoffs': 91.7818463285998, 'action': [0.0, 0.0]}, {'num_count': 452, 'sum_payoffs': 97.36767840569652, 'action': [1.0, -1.5707963267948966]}, {'num_count': 442, 'sum_payoffs': 94.22418053110152, 'action': [0.0, 1.5707963267948966]}, {'num_count': 460, 'sum_payoffs': 99.88339295339244, 'action': [2.0, 1.5707963267948966]}, {'num_count': 473, 'sum_payoffs': 103.91075163166568, 'action': [2.0, -1.5707963267948966]}, {'num_count': 445, 'sum_payoffs': 95.16305571099979, 'action': [0.0, -1.5707963267948966]}, {'num_count': 479, 'sum_payoffs': 105.82607543107873, 'action': [2.0, 0.0]}])
Weights num count: [0.1097293343087052, 0.11338697878566203, 0.10582784686661789, 0.11021702023896611, 0.10777859058766155, 0.11216776396000976, 0.11533772250670568, 0.10851011948305292, 0.11680078029748842]
Actions to choose Agent 1: dict_values([{'num_count': 666, 'sum_payoffs': 128.2418670624562, 'action': [0.0, 1.5707963267948966]}, {'num_count': 697, 'sum_payoffs': 136.77711923581273, 'action': [1.0, 1.5707963267948966]}, {'num_count': 700, 'sum_payoffs': 137.56352346654106, 'action': [1.0, 0.0]}, {'num_count': 698, 'sum_payoffs': 136.96563483974143, 'action': [1.0, -1.5707963267948966]}, {'num_count': 674, 'sum_payoffs': 130.41457021191755, 'action': [0.0, -1.5707963267948966]}, {'num_count': 665, 'sum_payoffs': 128.07059969886492, 'action': [0.0, 0.0]}])
Weights num count: [0.1623994147768837, 0.16995854669592783, 0.17069007559131918, 0.17020238966105827, 0.16435015849792733, 0.16215557181175322]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 116.94612574577332 s
