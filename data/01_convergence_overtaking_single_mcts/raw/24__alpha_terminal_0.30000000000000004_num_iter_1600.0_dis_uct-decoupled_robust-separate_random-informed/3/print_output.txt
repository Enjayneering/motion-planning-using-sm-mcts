Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 212, 'sum_payoffs': 55.00376622369331, 'action': [2.0, 0.0]}, {'num_count': 194, 'sum_payoffs': 48.0114290601379, 'action': [1.0, 0.0]}, {'num_count': 170, 'sum_payoffs': 38.891206564196494, 'action': [1.0, -1.5707963267948966]}, {'num_count': 172, 'sum_payoffs': 39.53458052930237, 'action': [0.0, 0.0]}, {'num_count': 169, 'sum_payoffs': 38.4305673186787, 'action': [1.0, 1.5707963267948966]}, {'num_count': 153, 'sum_payoffs': 32.46833104650474, 'action': [0.0, -1.5707963267948966]}, {'num_count': 155, 'sum_payoffs': 33.186884812987174, 'action': [0.0, 1.5707963267948966]}, {'num_count': 187, 'sum_payoffs': 45.30799816729589, 'action': [2.0, 1.5707963267948966]}, {'num_count': 188, 'sum_payoffs': 45.61219389546806, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.13241723922548407, 0.12117426608369769, 0.1061836352279825, 0.10743285446595878, 0.10555902560899438, 0.09556527170518427, 0.09681449094316052, 0.11680199875078076, 0.1174266083697689]
Actions to choose Agent 1: dict_values([{'num_count': 278, 'sum_payoffs': 78.99017881053575, 'action': [1.0, 1.5707963267948966]}, {'num_count': 233, 'sum_payoffs': 61.242204974293465, 'action': [0.0, 1.5707963267948966]}, {'num_count': 302, 'sum_payoffs': 88.56912122180654, 'action': [1.0, 0.0]}, {'num_count': 241, 'sum_payoffs': 64.3103448169149, 'action': [0.0, -1.5707963267948966]}, {'num_count': 263, 'sum_payoffs': 72.92578347300429, 'action': [0.0, 0.0]}, {'num_count': 283, 'sum_payoffs': 80.98635463534126, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.1736414740787008, 0.14553404122423486, 0.18863210493441598, 0.15053091817613992, 0.16427232979387882, 0.17676452217364147]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 2.76882004737854 s
