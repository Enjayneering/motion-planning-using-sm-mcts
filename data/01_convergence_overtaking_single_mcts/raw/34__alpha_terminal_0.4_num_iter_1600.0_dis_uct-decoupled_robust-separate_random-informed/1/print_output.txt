Searching game tree in timestep 0...
Max timehorizon: 3
Actions to choose Agent 0: dict_values([{'num_count': 166, 'sum_payoffs': 59.44802450996935, 'action': [1.0, 0.0]}, {'num_count': 180, 'sum_payoffs': 66.64325080672742, 'action': [2.0, 1.5707963267948966]}, {'num_count': 199, 'sum_payoffs': 76.35761945317512, 'action': [1.0, -1.5707963267948966]}, {'num_count': 198, 'sum_payoffs': 75.78000956077611, 'action': [2.0, -1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 63.01169639664296, 'action': [0.0, -1.5707963267948966]}, {'num_count': 183, 'sum_payoffs': 68.04401860172665, 'action': [1.0, 1.5707963267948966]}, {'num_count': 157, 'sum_payoffs': 54.84236672942576, 'action': [0.0, 0.0]}, {'num_count': 173, 'sum_payoffs': 62.787337876114755, 'action': [2.0, 0.0]}, {'num_count': 171, 'sum_payoffs': 61.84708548997832, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.10368519675202999, 0.11242973141786383, 0.12429731417863835, 0.12367270455965022, 0.1080574640849469, 0.11430356027482823, 0.09806371018113678, 0.1080574640849469, 0.10680824484697064]
Actions to choose Agent 1: dict_values([{'num_count': 300, 'sum_payoffs': 123.02516216392442, 'action': [1.0, 1.5707963267948966]}, {'num_count': 237, 'sum_payoffs': 90.51824484278794, 'action': [0.0, 0.0]}, {'num_count': 278, 'sum_payoffs': 111.57208355090084, 'action': [1.0, 0.0]}, {'num_count': 304, 'sum_payoffs': 125.01998625184446, 'action': [1.0, -1.5707963267948966]}, {'num_count': 247, 'sum_payoffs': 95.68142602614691, 'action': [0.0, 1.5707963267948966]}, {'num_count': 234, 'sum_payoffs': 88.95169795579766, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.18738288569643974, 0.14803247970018737, 0.1736414740787008, 0.18988132417239226, 0.15427857589006871, 0.146158650843223]
Selected final action: [1.0, -1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.22222222219629628, 0.2777777777453703]
Runtime: 6.08135724067688 s
