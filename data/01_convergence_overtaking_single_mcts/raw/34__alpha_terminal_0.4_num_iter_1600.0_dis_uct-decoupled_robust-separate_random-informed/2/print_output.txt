Searching game tree in timestep 0...
Max timehorizon: 3
Actions to choose Agent 0: dict_values([{'num_count': 158, 'sum_payoffs': 55.52364154307512, 'action': [0.0, 0.0]}, {'num_count': 155, 'sum_payoffs': 53.826120262340545, 'action': [1.0, 0.0]}, {'num_count': 177, 'sum_payoffs': 65.05906821277695, 'action': [2.0, 0.0]}, {'num_count': 194, 'sum_payoffs': 73.9004081183725, 'action': [1.0, -1.5707963267948966]}, {'num_count': 184, 'sum_payoffs': 68.75171050529188, 'action': [1.0, 1.5707963267948966]}, {'num_count': 205, 'sum_payoffs': 79.67746222016603, 'action': [2.0, -1.5707963267948966]}, {'num_count': 175, 'sum_payoffs': 63.99277924937547, 'action': [0.0, 1.5707963267948966]}, {'num_count': 174, 'sum_payoffs': 63.63131236632634, 'action': [0.0, -1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 65.71691417739207, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.09868831980012492, 0.09681449094316052, 0.11055590256089944, 0.12117426608369769, 0.11492816989381636, 0.12804497189256714, 0.10930668332292318, 0.10868207370393504, 0.11118051217988757]
Actions to choose Agent 1: dict_values([{'num_count': 237, 'sum_payoffs': 90.58349899353702, 'action': [0.0, 1.5707963267948966]}, {'num_count': 301, 'sum_payoffs': 123.51124786765035, 'action': [1.0, 1.5707963267948966]}, {'num_count': 283, 'sum_payoffs': 114.13455943809186, 'action': [1.0, 0.0]}, {'num_count': 234, 'sum_payoffs': 89.13901549409896, 'action': [0.0, -1.5707963267948966]}, {'num_count': 308, 'sum_payoffs': 127.22728696954927, 'action': [1.0, -1.5707963267948966]}, {'num_count': 237, 'sum_payoffs': 90.4589898027177, 'action': [0.0, 0.0]}])
Weights num count: [0.14803247970018737, 0.18800749531542785, 0.17676452217364147, 0.146158650843223, 0.19237976264834478, 0.14803247970018737]
Selected final action: [2.0, -1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 6.224964618682861 s
