Searching game tree in timestep 0...
Max timehorizon: 3
Actions to choose Agent 0: dict_values([{'num_count': 261, 'sum_payoffs': 92.57386918961096, 'action': [1.0, 0.0]}, {'num_count': 260, 'sum_payoffs': 91.84972539314205, 'action': [0.0, 1.5707963267948966]}, {'num_count': 280, 'sum_payoffs': 101.6516936644877, 'action': [2.0, 0.0]}, {'num_count': 314, 'sum_payoffs': 118.15387903756582, 'action': [2.0, -1.5707963267948966]}, {'num_count': 323, 'sum_payoffs': 122.61645175428137, 'action': [1.0, -1.5707963267948966]}, {'num_count': 312, 'sum_payoffs': 117.03756090542323, 'action': [2.0, 1.5707963267948966]}, {'num_count': 297, 'sum_payoffs': 109.85566065665084, 'action': [0.0, -1.5707963267948966]}, {'num_count': 247, 'sum_payoffs': 85.89409493096099, 'action': [0.0, 0.0]}, {'num_count': 306, 'sum_payoffs': 114.14517121044628, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.10034602076124567, 0.09996155324875049, 0.10765090349865436, 0.12072279892349097, 0.12418300653594772, 0.11995386389850057, 0.11418685121107267, 0.09496347558631296, 0.11764705882352941]
Actions to choose Agent 1: dict_values([{'num_count': 459, 'sum_payoffs': 182.1914773209109, 'action': [1.0, 0.0]}, {'num_count': 379, 'sum_payoffs': 143.35577940948195, 'action': [0.0, 0.0]}, {'num_count': 376, 'sum_payoffs': 141.9826988600088, 'action': [0.0, 1.5707963267948966]}, {'num_count': 490, 'sum_payoffs': 197.4075682228047, 'action': [1.0, 1.5707963267948966]}, {'num_count': 413, 'sum_payoffs': 159.70315630433592, 'action': [0.0, -1.5707963267948966]}, {'num_count': 483, 'sum_payoffs': 194.01620687083576, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.17647058823529413, 0.14571318723567858, 0.144559784698193, 0.18838908112264513, 0.1587850826605152, 0.18569780853517878]
Selected final action: [1.0, -1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.22222222219629628, 0.2777777777453703]
Runtime: 9.957188367843628 s
