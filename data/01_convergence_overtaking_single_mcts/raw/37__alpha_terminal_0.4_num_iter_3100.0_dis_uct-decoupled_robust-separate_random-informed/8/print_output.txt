Searching game tree in timestep 0...
Max timehorizon: 3
Actions to choose Agent 0: dict_values([{'num_count': 339, 'sum_payoffs': 118.79928383051853, 'action': [0.0, -1.5707963267948966]}, {'num_count': 359, 'sum_payoffs': 127.85644697213579, 'action': [2.0, 1.5707963267948966]}, {'num_count': 331, 'sum_payoffs': 115.05324994375528, 'action': [2.0, 0.0]}, {'num_count': 324, 'sum_payoffs': 111.9376829424785, 'action': [0.0, 0.0]}, {'num_count': 339, 'sum_payoffs': 118.76175756942517, 'action': [0.0, 1.5707963267948966]}, {'num_count': 368, 'sum_payoffs': 132.00898244747876, 'action': [2.0, -1.5707963267948966]}, {'num_count': 356, 'sum_payoffs': 126.62842189717887, 'action': [1.0, 1.5707963267948966]}, {'num_count': 322, 'sum_payoffs': 110.98284614351294, 'action': [1.0, 0.0]}, {'num_count': 362, 'sum_payoffs': 129.16686926579135, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.10931957433086101, 0.11576910673976137, 0.10673976136730087, 0.10448242502418574, 0.10931957433086101, 0.11867139632376653, 0.11480167687842631, 0.1038374717832957, 0.11673653660109642]
Actions to choose Agent 1: dict_values([{'num_count': 546, 'sum_payoffs': 212.32725181117937, 'action': [1.0, 0.0]}, {'num_count': 500, 'sum_payoffs': 190.6087967738497, 'action': [0.0, -1.5707963267948966]}, {'num_count': 489, 'sum_payoffs': 185.310473427076, 'action': [0.0, 1.5707963267948966]}, {'num_count': 562, 'sum_payoffs': 219.86021910844667, 'action': [1.0, 1.5707963267948966]}, {'num_count': 455, 'sum_payoffs': 169.41833853351991, 'action': [0.0, 0.0]}, {'num_count': 548, 'sum_payoffs': 213.29779821263918, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.17607223476297967, 0.16123831022250887, 0.15769106739761368, 0.18123186069009997, 0.14672686230248308, 0.1767171880038697]
Selected final action: [2.0, -1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 11.242296934127808 s
