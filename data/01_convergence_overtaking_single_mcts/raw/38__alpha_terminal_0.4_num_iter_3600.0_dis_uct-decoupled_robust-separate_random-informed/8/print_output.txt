Searching game tree in timestep 0...
Max timehorizon: 3
Actions to choose Agent 0: dict_values([{'num_count': 403, 'sum_payoffs': 136.1067626178801, 'action': [2.0, 0.0]}, {'num_count': 403, 'sum_payoffs': 136.1842051038657, 'action': [0.0, -1.5707963267948966]}, {'num_count': 414, 'sum_payoffs': 140.86108231185753, 'action': [1.0, 1.5707963267948966]}, {'num_count': 382, 'sum_payoffs': 126.8345984641736, 'action': [1.0, 0.0]}, {'num_count': 390, 'sum_payoffs': 130.535629207991, 'action': [0.0, 1.5707963267948966]}, {'num_count': 431, 'sum_payoffs': 148.37887592606396, 'action': [2.0, -1.5707963267948966]}, {'num_count': 409, 'sum_payoffs': 138.82603302916527, 'action': [2.0, 1.5707963267948966]}, {'num_count': 396, 'sum_payoffs': 133.03902867044516, 'action': [1.0, -1.5707963267948966]}, {'num_count': 372, 'sum_payoffs': 122.61176728750598, 'action': [0.0, 0.0]}])
Weights num count: [0.11191335740072202, 0.11191335740072202, 0.11496806442654818, 0.10608164398778117, 0.10830324909747292, 0.11968897528464316, 0.11357956123299083, 0.10996945292974174, 0.10330463760066648]
Actions to choose Agent 1: dict_values([{'num_count': 555, 'sum_payoffs': 199.74601030493045, 'action': [0.0, 0.0]}, {'num_count': 642, 'sum_payoffs': 238.9720259822811, 'action': [1.0, 1.5707963267948966]}, {'num_count': 572, 'sum_payoffs': 207.30930768416133, 'action': [0.0, 1.5707963267948966]}, {'num_count': 630, 'sum_payoffs': 233.4445216043222, 'action': [1.0, 0.0]}, {'num_count': 627, 'sum_payoffs': 232.05645389726104, 'action': [1.0, -1.5707963267948966]}, {'num_count': 574, 'sum_payoffs': 208.27687536486764, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.15412385448486532, 0.17828381005276311, 0.1588447653429603, 0.17495140238822549, 0.1741183004720911, 0.15940016662038323]
Selected final action: [2.0, -1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 12.14444613456726 s
