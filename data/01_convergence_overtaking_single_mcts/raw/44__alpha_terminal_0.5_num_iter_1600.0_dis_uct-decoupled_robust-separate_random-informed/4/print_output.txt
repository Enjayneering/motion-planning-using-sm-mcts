Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 174, 'sum_payoffs': 59.37288649066862, 'action': [1.0, 1.5707963267948966]}, {'num_count': 184, 'sum_payoffs': 64.22090605206118, 'action': [2.0, -1.5707963267948966]}, {'num_count': 182, 'sum_payoffs': 63.42214322332146, 'action': [2.0, 0.0]}, {'num_count': 175, 'sum_payoffs': 59.907681598960615, 'action': [1.0, 0.0]}, {'num_count': 180, 'sum_payoffs': 62.46074476814736, 'action': [1.0, -1.5707963267948966]}, {'num_count': 181, 'sum_payoffs': 62.69340860909252, 'action': [2.0, 1.5707963267948966]}, {'num_count': 183, 'sum_payoffs': 63.79749163010729, 'action': [0.0, 0.0]}, {'num_count': 175, 'sum_payoffs': 59.90522535767826, 'action': [0.0, -1.5707963267948966]}, {'num_count': 166, 'sum_payoffs': 55.49124362700725, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.10868207370393504, 0.11492816989381636, 0.1136789506558401, 0.10930668332292318, 0.11242973141786383, 0.11305434103685197, 0.11430356027482823, 0.10930668332292318, 0.10368519675202999]
Actions to choose Agent 1: dict_values([{'num_count': 284, 'sum_payoffs': 104.94985840340598, 'action': [1.0, 0.0]}, {'num_count': 293, 'sum_payoffs': 109.48398100624652, 'action': [1.0, 1.5707963267948966]}, {'num_count': 245, 'sum_payoffs': 86.382473903063, 'action': [0.0, 1.5707963267948966]}, {'num_count': 248, 'sum_payoffs': 87.80219245215191, 'action': [0.0, 0.0]}, {'num_count': 286, 'sum_payoffs': 106.08834648973533, 'action': [1.0, -1.5707963267948966]}, {'num_count': 244, 'sum_payoffs': 85.67752691181671, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.1773891317926296, 0.1830106183635228, 0.15302935665209244, 0.15490318550905685, 0.17863835103060588, 0.1524047470331043]
Selected final action: [2.0, -1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 9.537596464157104 s
