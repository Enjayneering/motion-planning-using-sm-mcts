Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 180, 'sum_payoffs': 62.641738558919826, 'action': [2.0, 0.0]}, {'num_count': 170, 'sum_payoffs': 57.62955770052145, 'action': [1.0, 0.0]}, {'num_count': 183, 'sum_payoffs': 64.12605000465521, 'action': [1.0, 1.5707963267948966]}, {'num_count': 162, 'sum_payoffs': 53.83246701394817, 'action': [0.0, 1.5707963267948966]}, {'num_count': 172, 'sum_payoffs': 58.626216937185404, 'action': [0.0, -1.5707963267948966]}, {'num_count': 180, 'sum_payoffs': 62.662934684309704, 'action': [1.0, -1.5707963267948966]}, {'num_count': 191, 'sum_payoffs': 67.96941270518482, 'action': [2.0, 1.5707963267948966]}, {'num_count': 166, 'sum_payoffs': 55.73704073087046, 'action': [0.0, 0.0]}, {'num_count': 196, 'sum_payoffs': 70.47057437955603, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.11242973141786383, 0.1061836352279825, 0.11430356027482823, 0.10118675827607745, 0.10743285446595878, 0.11242973141786383, 0.1193004372267333, 0.10368519675202999, 0.12242348532167395]
Actions to choose Agent 1: dict_values([{'num_count': 288, 'sum_payoffs': 106.6938077757754, 'action': [1.0, 0.0]}, {'num_count': 292, 'sum_payoffs': 108.68262698528291, 'action': [1.0, 1.5707963267948966]}, {'num_count': 293, 'sum_payoffs': 109.19956844117861, 'action': [1.0, -1.5707963267948966]}, {'num_count': 235, 'sum_payoffs': 81.36738747236244, 'action': [0.0, -1.5707963267948966]}, {'num_count': 246, 'sum_payoffs': 86.59691880110212, 'action': [0.0, 0.0]}, {'num_count': 246, 'sum_payoffs': 86.64464651955763, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.17988757026858213, 0.18238600874453467, 0.1830106183635228, 0.14678326046221113, 0.15365396627108058, 0.15365396627108058]
Selected final action: [2.0, -1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 9.55678677558899 s
