Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 219, 'sum_payoffs': 73.63090931622055, 'action': [0.0, -1.5707963267948966]}, {'num_count': 250, 'sum_payoffs': 88.2353266009736, 'action': [1.0, -1.5707963267948966]}, {'num_count': 218, 'sum_payoffs': 73.1302140725387, 'action': [1.0, 0.0]}, {'num_count': 248, 'sum_payoffs': 87.30772195112664, 'action': [2.0, 1.5707963267948966]}, {'num_count': 221, 'sum_payoffs': 74.49840890838716, 'action': [0.0, 0.0]}, {'num_count': 237, 'sum_payoffs': 82.11228536000579, 'action': [2.0, 0.0]}, {'num_count': 237, 'sum_payoffs': 82.10945299175143, 'action': [1.0, 1.5707963267948966]}, {'num_count': 252, 'sum_payoffs': 88.99462243611258, 'action': [2.0, -1.5707963267948966]}, {'num_count': 218, 'sum_payoffs': 73.01622593250835, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.10423607805806759, 0.11899095668729176, 0.10376011423131842, 0.11803902903379343, 0.10518800571156592, 0.1128034269395526, 0.1128034269395526, 0.1199428843407901, 0.10376011423131842]
Actions to choose Agent 1: dict_values([{'num_count': 382, 'sum_payoffs': 142.96630015213285, 'action': [1.0, 0.0]}, {'num_count': 327, 'sum_payoffs': 117.08963448110404, 'action': [0.0, 1.5707963267948966]}, {'num_count': 310, 'sum_payoffs': 109.00716955741751, 'action': [0.0, -1.5707963267948966]}, {'num_count': 323, 'sum_payoffs': 115.15909171252456, 'action': [0.0, 0.0]}, {'num_count': 370, 'sum_payoffs': 137.17090689314574, 'action': [1.0, 1.5707963267948966]}, {'num_count': 388, 'sum_payoffs': 145.78655469770058, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.18181818181818182, 0.15564017134697763, 0.1475487862922418, 0.15373631603998097, 0.17610661589719181, 0.1846739647786768]
Selected final action: [2.0, -1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 12.62447190284729 s
