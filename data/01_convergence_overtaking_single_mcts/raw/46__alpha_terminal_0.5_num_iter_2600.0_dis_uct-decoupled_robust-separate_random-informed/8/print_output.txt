Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 302, 'sum_payoffs': 105.00991909072964, 'action': [2.0, 0.0]}, {'num_count': 301, 'sum_payoffs': 104.55114419981548, 'action': [1.0, 1.5707963267948966]}, {'num_count': 302, 'sum_payoffs': 104.92020892465293, 'action': [1.0, -1.5707963267948966]}, {'num_count': 300, 'sum_payoffs': 103.99327883730989, 'action': [2.0, 1.5707963267948966]}, {'num_count': 273, 'sum_payoffs': 91.59641460044477, 'action': [0.0, 0.0]}, {'num_count': 305, 'sum_payoffs': 106.41550085779312, 'action': [2.0, -1.5707963267948966]}, {'num_count': 280, 'sum_payoffs': 94.86975171169209, 'action': [1.0, 0.0]}, {'num_count': 260, 'sum_payoffs': 85.81881529126267, 'action': [0.0, 1.5707963267948966]}, {'num_count': 277, 'sum_payoffs': 93.48834184471286, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.11610918877354863, 0.11572472126105345, 0.11610918877354863, 0.11534025374855825, 0.104959630911188, 0.11726259131103421, 0.10765090349865436, 0.09996155324875049, 0.10649750096116878]
Actions to choose Agent 1: dict_values([{'num_count': 407, 'sum_payoffs': 145.74857836288697, 'action': [0.0, 0.0]}, {'num_count': 372, 'sum_payoffs': 129.80909537341873, 'action': [0.0, -1.5707963267948966]}, {'num_count': 503, 'sum_payoffs': 190.0963958185405, 'action': [1.0, 0.0]}, {'num_count': 458, 'sum_payoffs': 169.15451754723034, 'action': [1.0, -1.5707963267948966]}, {'num_count': 391, 'sum_payoffs': 138.36105052392443, 'action': [0.0, 1.5707963267948966]}, {'num_count': 469, 'sum_payoffs': 174.27194888831454, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.15647827758554403, 0.14302191464821223, 0.19338715878508267, 0.17608612072279892, 0.1503267973856209, 0.18031526336024606]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 15.313270568847656 s
