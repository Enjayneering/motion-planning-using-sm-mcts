Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 317, 'sum_payoffs': 105.09756596196642, 'action': [0.0, 1.5707963267948966]}, {'num_count': 373, 'sum_payoffs': 130.3455892982001, 'action': [2.0, -1.5707963267948966]}, {'num_count': 344, 'sum_payoffs': 117.17783603764097, 'action': [0.0, 0.0]}, {'num_count': 351, 'sum_payoffs': 120.39040660848947, 'action': [2.0, 1.5707963267948966]}, {'num_count': 367, 'sum_payoffs': 127.4933408118629, 'action': [2.0, 0.0]}, {'num_count': 365, 'sum_payoffs': 126.60939907975018, 'action': [1.0, -1.5707963267948966]}, {'num_count': 327, 'sum_payoffs': 109.6122934857713, 'action': [1.0, 0.0]}, {'num_count': 322, 'sum_payoffs': 107.36130002002166, 'action': [0.0, -1.5707963267948966]}, {'num_count': 334, 'sum_payoffs': 112.68350200903748, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.10222508868107062, 0.12028377942599161, 0.1109319574330861, 0.11318929377620122, 0.11834891970332151, 0.11770396646243148, 0.1054498548855208, 0.1038374717832957, 0.10770719122863592]
Actions to choose Agent 1: dict_values([{'num_count': 556, 'sum_payoffs': 204.65637854760965, 'action': [1.0, 1.5707963267948966]}, {'num_count': 455, 'sum_payoffs': 159.3190610937418, 'action': [0.0, -1.5707963267948966]}, {'num_count': 588, 'sum_payoffs': 219.19659181896026, 'action': [1.0, 0.0]}, {'num_count': 468, 'sum_payoffs': 165.14789176276352, 'action': [0.0, 1.5707963267948966]}, {'num_count': 558, 'sum_payoffs': 205.56401392223316, 'action': [1.0, -1.5707963267948966]}, {'num_count': 475, 'sum_payoffs': 168.11841799072485, 'action': [0.0, 0.0]}])
Weights num count: [0.17929700096742987, 0.14672686230248308, 0.18961625282167044, 0.1509190583682683, 0.1799419542083199, 0.15317639471138342]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 18.13421082496643 s
