Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 365, 'sum_payoffs': 127.16696497838929, 'action': [2.0, 0.0]}, {'num_count': 358, 'sum_payoffs': 123.93271289173981, 'action': [1.0, -1.5707963267948966]}, {'num_count': 314, 'sum_payoffs': 104.11026474117693, 'action': [0.0, 1.5707963267948966]}, {'num_count': 331, 'sum_payoffs': 111.84484297301097, 'action': [1.0, 0.0]}, {'num_count': 326, 'sum_payoffs': 109.58948913175543, 'action': [0.0, -1.5707963267948966]}, {'num_count': 332, 'sum_payoffs': 112.25814481625261, 'action': [0.0, 0.0]}, {'num_count': 341, 'sum_payoffs': 116.34344890069254, 'action': [1.0, 1.5707963267948966]}, {'num_count': 386, 'sum_payoffs': 136.6175645900594, 'action': [2.0, -1.5707963267948966]}, {'num_count': 347, 'sum_payoffs': 119.00441659421065, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.11770396646243148, 0.11544663011931634, 0.10125765881973557, 0.10673976136730087, 0.10512737826507579, 0.10706223798774589, 0.10996452757175104, 0.12447597549177684, 0.11189938729442116]
Actions to choose Agent 1: dict_values([{'num_count': 470, 'sum_payoffs': 165.97135289755613, 'action': [0.0, 0.0]}, {'num_count': 615, 'sum_payoffs': 231.50998309872048, 'action': [1.0, 0.0]}, {'num_count': 468, 'sum_payoffs': 165.03167079775517, 'action': [0.0, -1.5707963267948966]}, {'num_count': 530, 'sum_payoffs': 192.91232531733928, 'action': [1.0, 1.5707963267948966]}, {'num_count': 461, 'sum_payoffs': 161.9275028755594, 'action': [0.0, 1.5707963267948966]}, {'num_count': 556, 'sum_payoffs': 204.7210511053929, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.15156401160915833, 0.1983231215736859, 0.1509190583682683, 0.1709126088358594, 0.14866172202515318, 0.17929700096742987]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 17.794991970062256 s
