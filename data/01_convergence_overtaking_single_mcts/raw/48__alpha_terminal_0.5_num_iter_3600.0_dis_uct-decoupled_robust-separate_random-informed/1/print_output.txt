Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 396, 'sum_payoffs': 133.94893174516923, 'action': [1.0, 1.5707963267948966]}, {'num_count': 393, 'sum_payoffs': 132.6366898227792, 'action': [1.0, 0.0]}, {'num_count': 383, 'sum_payoffs': 128.21964248731697, 'action': [0.0, 0.0]}, {'num_count': 455, 'sum_payoffs': 160.08319684458397, 'action': [2.0, 0.0]}, {'num_count': 416, 'sum_payoffs': 142.78089172374555, 'action': [2.0, -1.5707963267948966]}, {'num_count': 358, 'sum_payoffs': 117.3348161812934, 'action': [0.0, 1.5707963267948966]}, {'num_count': 363, 'sum_payoffs': 119.53787655651956, 'action': [0.0, -1.5707963267948966]}, {'num_count': 417, 'sum_payoffs': 143.16889604915525, 'action': [1.0, -1.5707963267948966]}, {'num_count': 419, 'sum_payoffs': 144.14324168413577, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.10996945292974174, 0.10913635101360733, 0.10635934462649264, 0.1263537906137184, 0.11552346570397112, 0.09941682865870592, 0.10080533185226326, 0.11580116634268259, 0.11635656762010553]
Actions to choose Agent 1: dict_values([{'num_count': 529, 'sum_payoffs': 184.26102391754543, 'action': [0.0, 1.5707963267948966]}, {'num_count': 677, 'sum_payoffs': 249.5413832704122, 'action': [1.0, -1.5707963267948966]}, {'num_count': 682, 'sum_payoffs': 251.77645401240397, 'action': [1.0, 0.0]}, {'num_count': 531, 'sum_payoffs': 185.03830151166767, 'action': [0.0, -1.5707963267948966]}, {'num_count': 642, 'sum_payoffs': 233.931907798854, 'action': [1.0, 1.5707963267948966]}, {'num_count': 539, 'sum_payoffs': 188.63202453765368, 'action': [0.0, 0.0]}])
Weights num count: [0.14690363787836713, 0.18800333240766454, 0.1893918356012219, 0.14745903915579006, 0.17828381005276311, 0.1496806442654818]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 19.88235569000244 s
