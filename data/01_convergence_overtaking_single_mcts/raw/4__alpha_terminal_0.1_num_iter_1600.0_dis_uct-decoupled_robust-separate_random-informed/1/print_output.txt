Searching game tree in timestep 0...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 204, 'sum_payoffs': 57.11144426834261, 'action': [2.0, 1.5707963267948966]}, {'num_count': 153, 'sum_payoffs': 36.51174412185071, 'action': [0.0, 1.5707963267948966]}, {'num_count': 154, 'sum_payoffs': 36.88155921424285, 'action': [0.0, 0.0]}, {'num_count': 154, 'sum_payoffs': 36.80159919426617, 'action': [0.0, -1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 45.61719139669513, 'action': [1.0, 0.0]}, {'num_count': 204, 'sum_payoffs': 57.09145426334831, 'action': [2.0, 0.0]}, {'num_count': 176, 'sum_payoffs': 45.577211386706786, 'action': [1.0, 1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 45.55722138171261, 'action': [1.0, -1.5707963267948966]}, {'num_count': 203, 'sum_payoffs': 56.68165916096789, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.127420362273579, 0.09556527170518427, 0.09618988132417239, 0.09618988132417239, 0.1099312929419113, 0.127420362273579, 0.1099312929419113, 0.1099312929419113, 0.1267957526545909]
Actions to choose Agent 1: dict_values([{'num_count': 242, 'sum_payoffs': 74.34282857331664, 'action': [0.0, -1.5707963267948966]}, {'num_count': 244, 'sum_payoffs': 75.10244876309508, 'action': [0.0, 0.0]}, {'num_count': 293, 'sum_payoffs': 96.56171912433658, 'action': [1.0, 1.5707963267948966]}, {'num_count': 290, 'sum_payoffs': 95.19240378223596, 'action': [1.0, 0.0]}, {'num_count': 240, 'sum_payoffs': 73.40329833859064, 'action': [0.0, 1.5707963267948966]}, {'num_count': 291, 'sum_payoffs': 95.6221888896106, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.15115552779512806, 0.1524047470331043, 0.1830106183635228, 0.1811367895065584, 0.14990630855715179, 0.18176139912554654]
Selected final action: [2.0, 1.5707963267948966, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 0.24993634223937988 s
