Searching game tree in timestep 0...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 174, 'sum_payoffs': 44.85757120691667, 'action': [1.0, 0.0]}, {'num_count': 204, 'sum_payoffs': 57.0314842483659, 'action': [2.0, 0.0]}, {'num_count': 154, 'sum_payoffs': 36.821589199260345, 'action': [0.0, -1.5707963267948966]}, {'num_count': 204, 'sum_payoffs': 57.051474253360084, 'action': [2.0, 1.5707963267948966]}, {'num_count': 204, 'sum_payoffs': 57.17141428332501, 'action': [2.0, -1.5707963267948966]}, {'num_count': 153, 'sum_payoffs': 36.491754116856534, 'action': [0.0, 0.0]}, {'num_count': 177, 'sum_payoffs': 45.967016484093094, 'action': [1.0, 1.5707963267948966]}, {'num_count': 154, 'sum_payoffs': 36.82158919926034, 'action': [0.0, 1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 45.65717140668346, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.10868207370393504, 0.127420362273579, 0.09618988132417239, 0.127420362273579, 0.127420362273579, 0.09556527170518427, 0.11055590256089944, 0.09618988132417239, 0.1099312929419113]
Actions to choose Agent 1: dict_values([{'num_count': 241, 'sum_payoffs': 73.87306345595361, 'action': [0.0, 1.5707963267948966]}, {'num_count': 292, 'sum_payoffs': 96.07196400197944, 'action': [1.0, -1.5707963267948966]}, {'num_count': 242, 'sum_payoffs': 74.3028485633283, 'action': [0.0, -1.5707963267948966]}, {'num_count': 293, 'sum_payoffs': 96.46176909936575, 'action': [1.0, 1.5707963267948966]}, {'num_count': 290, 'sum_payoffs': 95.19240378223597, 'action': [1.0, 0.0]}, {'num_count': 242, 'sum_payoffs': 74.32283856832247, 'action': [0.0, 0.0]}])
Weights num count: [0.15053091817613992, 0.18238600874453467, 0.15115552779512806, 0.1830106183635228, 0.1811367895065584, 0.15115552779512806]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 0.23670673370361328 s
