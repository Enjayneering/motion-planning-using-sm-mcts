Searching game tree in timestep 0...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 154, 'sum_payoffs': 36.84157920425451, 'action': [0.0, 0.0]}, {'num_count': 177, 'sum_payoffs': 45.94702647909892, 'action': [1.0, 1.5707963267948966]}, {'num_count': 205, 'sum_payoffs': 57.56121938071137, 'action': [2.0, 0.0]}, {'num_count': 154, 'sum_payoffs': 36.82158919926034, 'action': [0.0, 1.5707963267948966]}, {'num_count': 201, 'sum_payoffs': 55.92203897118948, 'action': [2.0, -1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 45.6971514166718, 'action': [1.0, -1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 45.63718140168929, 'action': [1.0, 0.0]}, {'num_count': 154, 'sum_payoffs': 36.781609189272004, 'action': [0.0, -1.5707963267948966]}, {'num_count': 203, 'sum_payoffs': 56.6816591609679, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.09618988132417239, 0.11055590256089944, 0.12804497189256714, 0.09618988132417239, 0.12554653341661462, 0.1099312929419113, 0.1099312929419113, 0.09618988132417239, 0.1267957526545909]
Actions to choose Agent 1: dict_values([{'num_count': 293, 'sum_payoffs': 96.54172911934243, 'action': [1.0, -1.5707963267948966]}, {'num_count': 244, 'sum_payoffs': 75.18240878307178, 'action': [0.0, 1.5707963267948966]}, {'num_count': 292, 'sum_payoffs': 96.05197399698527, 'action': [1.0, 0.0]}, {'num_count': 287, 'sum_payoffs': 93.94302847010032, 'action': [1.0, 1.5707963267948966]}, {'num_count': 241, 'sum_payoffs': 73.87306345595363, 'action': [0.0, 0.0]}, {'num_count': 243, 'sum_payoffs': 74.65267365072626, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.1830106183635228, 0.1524047470331043, 0.18238600874453467, 0.17926296064959402, 0.15053091817613992, 0.15178013741411617]
Selected final action: [2.0, 0.0, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 0.24044060707092285 s
