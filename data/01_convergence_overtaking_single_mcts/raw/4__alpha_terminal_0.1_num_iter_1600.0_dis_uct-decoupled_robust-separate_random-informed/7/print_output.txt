Searching game tree in timestep 0...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 154, 'sum_payoffs': 36.82158919926034, 'action': [0.0, 0.0]}, {'num_count': 175, 'sum_payoffs': 45.14742627933213, 'action': [1.0, 1.5707963267948966]}, {'num_count': 153, 'sum_payoffs': 36.41179409687985, 'action': [0.0, -1.5707963267948966]}, {'num_count': 203, 'sum_payoffs': 56.72163917095627, 'action': [2.0, -1.5707963267948966]}, {'num_count': 203, 'sum_payoffs': 56.721639170956266, 'action': [2.0, 0.0]}, {'num_count': 177, 'sum_payoffs': 45.987006489087264, 'action': [1.0, 0.0]}, {'num_count': 176, 'sum_payoffs': 45.67716141167764, 'action': [1.0, -1.5707963267948966]}, {'num_count': 154, 'sum_payoffs': 36.86156920924868, 'action': [0.0, 1.5707963267948966]}, {'num_count': 205, 'sum_payoffs': 57.54122937571715, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.09618988132417239, 0.10930668332292318, 0.09556527170518427, 0.1267957526545909, 0.1267957526545909, 0.11055590256089944, 0.1099312929419113, 0.09618988132417239, 0.12804497189256714]
Actions to choose Agent 1: dict_values([{'num_count': 289, 'sum_payoffs': 94.82258868984381, 'action': [1.0, -1.5707963267948966]}, {'num_count': 293, 'sum_payoffs': 96.5017491093541, 'action': [1.0, 0.0]}, {'num_count': 239, 'sum_payoffs': 72.97351323121599, 'action': [0.0, 0.0]}, {'num_count': 293, 'sum_payoffs': 96.50174910935407, 'action': [1.0, 1.5707963267948966]}, {'num_count': 241, 'sum_payoffs': 73.87306345595364, 'action': [0.0, -1.5707963267948966]}, {'num_count': 245, 'sum_payoffs': 75.57221388045812, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.18051217988757026, 0.1830106183635228, 0.14928169893816365, 0.1830106183635228, 0.15053091817613992, 0.15302935665209244]
Selected final action: [2.0, 1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 0.2471170425415039 s
