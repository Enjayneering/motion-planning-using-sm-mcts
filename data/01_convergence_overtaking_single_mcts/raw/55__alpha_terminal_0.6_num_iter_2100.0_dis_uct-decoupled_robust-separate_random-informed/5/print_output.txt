Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 213, 'sum_payoffs': 70.72854354502012, 'action': [0.0, -1.5707963267948966]}, {'num_count': 242, 'sum_payoffs': 84.32982944065648, 'action': [1.0, -1.5707963267948966]}, {'num_count': 217, 'sum_payoffs': 72.56201797963152, 'action': [0.0, 1.5707963267948966]}, {'num_count': 249, 'sum_payoffs': 87.64274258082891, 'action': [2.0, -1.5707963267948966]}, {'num_count': 241, 'sum_payoffs': 83.84213418321909, 'action': [0.0, 0.0]}, {'num_count': 223, 'sum_payoffs': 75.34681092194779, 'action': [1.0, 0.0]}, {'num_count': 243, 'sum_payoffs': 84.7980627753728, 'action': [2.0, 0.0]}, {'num_count': 230, 'sum_payoffs': 78.6612466129848, 'action': [1.0, 1.5707963267948966]}, {'num_count': 242, 'sum_payoffs': 84.15317224414305, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.10138029509757258, 0.11518324607329843, 0.10328415040456926, 0.1185149928605426, 0.11470728224654926, 0.10613993336506425, 0.11565920990004759, 0.10947168015230842, 0.11518324607329843]
Actions to choose Agent 1: dict_values([{'num_count': 370, 'sum_payoffs': 136.5681440665363, 'action': [1.0, -1.5707963267948966]}, {'num_count': 383, 'sum_payoffs': 142.6780900369363, 'action': [1.0, 1.5707963267948966]}, {'num_count': 395, 'sum_payoffs': 148.36665340546114, 'action': [1.0, 0.0]}, {'num_count': 329, 'sum_payoffs': 117.36611494091721, 'action': [0.0, 0.0]}, {'num_count': 320, 'sum_payoffs': 113.19015721197816, 'action': [0.0, -1.5707963267948966]}, {'num_count': 303, 'sum_payoffs': 105.18490481759457, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.17610661589719181, 0.182294145644931, 0.188005711565921, 0.15659209900047596, 0.15230842455973345, 0.14421703950499762]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 14.367287397384644 s
