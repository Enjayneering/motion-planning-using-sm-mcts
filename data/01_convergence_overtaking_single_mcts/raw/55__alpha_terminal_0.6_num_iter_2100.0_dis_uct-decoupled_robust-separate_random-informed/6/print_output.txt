Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 210, 'sum_payoffs': 69.33903625276916, 'action': [0.0, 0.0]}, {'num_count': 251, 'sum_payoffs': 88.65529619655081, 'action': [2.0, 0.0]}, {'num_count': 234, 'sum_payoffs': 80.52915979869366, 'action': [1.0, -1.5707963267948966]}, {'num_count': 227, 'sum_payoffs': 77.32705961213627, 'action': [0.0, -1.5707963267948966]}, {'num_count': 238, 'sum_payoffs': 82.30016492879848, 'action': [1.0, 1.5707963267948966]}, {'num_count': 250, 'sum_payoffs': 88.16784640213834, 'action': [2.0, -1.5707963267948966]}, {'num_count': 237, 'sum_payoffs': 81.95997118513505, 'action': [2.0, 1.5707963267948966]}, {'num_count': 237, 'sum_payoffs': 81.96343876585932, 'action': [1.0, 0.0]}, {'num_count': 216, 'sum_payoffs': 72.14203918726221, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.09995240361732509, 0.11946692051404094, 0.11137553545930509, 0.10804378867206092, 0.11327939076630177, 0.11899095668729176, 0.1128034269395526, 0.1128034269395526, 0.10280818657782008]
Actions to choose Agent 1: dict_values([{'num_count': 318, 'sum_payoffs': 112.4190996287879, 'action': [0.0, 1.5707963267948966]}, {'num_count': 303, 'sum_payoffs': 105.58387640553947, 'action': [0.0, -1.5707963267948966]}, {'num_count': 327, 'sum_payoffs': 116.7058619998291, 'action': [0.0, 0.0]}, {'num_count': 370, 'sum_payoffs': 136.65993281499027, 'action': [1.0, 1.5707963267948966]}, {'num_count': 379, 'sum_payoffs': 141.1120320072765, 'action': [1.0, -1.5707963267948966]}, {'num_count': 403, 'sum_payoffs': 152.52067168221498, 'action': [1.0, 0.0]}])
Weights num count: [0.15135649690623512, 0.14421703950499762, 0.15564017134697763, 0.17610661589719181, 0.18039029033793433, 0.19181342217991432]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 13.389700651168823 s
