Searching game tree in timestep 0...
Max timehorizon: 4
Actions to choose Agent 0: dict_values([{'num_count': 372, 'sum_payoffs': 123.39255042851661, 'action': [0.0, 0.0]}, {'num_count': 405, 'sum_payoffs': 137.85523894893717, 'action': [1.0, 1.5707963267948966]}, {'num_count': 387, 'sum_payoffs': 130.01398623195843, 'action': [1.0, 0.0]}, {'num_count': 423, 'sum_payoffs': 145.89113469676207, 'action': [2.0, 1.5707963267948966]}, {'num_count': 359, 'sum_payoffs': 117.6561259614981, 'action': [0.0, 1.5707963267948966]}, {'num_count': 382, 'sum_payoffs': 127.81028153060632, 'action': [0.0, -1.5707963267948966]}, {'num_count': 406, 'sum_payoffs': 138.1945400878174, 'action': [1.0, -1.5707963267948966]}, {'num_count': 440, 'sum_payoffs': 153.40328121517769, 'action': [2.0, 0.0]}, {'num_count': 426, 'sum_payoffs': 147.17603734914988, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.10330463760066648, 0.11246875867814496, 0.10747014718133852, 0.1174673701749514, 0.09969452929741739, 0.10608164398778117, 0.11274645931685642, 0.12218828103304638, 0.11830047209108581]
Actions to choose Agent 1: dict_values([{'num_count': 498, 'sum_payoffs': 170.91413391010423, 'action': [0.0, 1.5707963267948966]}, {'num_count': 635, 'sum_payoffs': 231.11121772321334, 'action': [1.0, -1.5707963267948966]}, {'num_count': 695, 'sum_payoffs': 257.92840318788586, 'action': [1.0, 0.0]}, {'num_count': 553, 'sum_payoffs': 195.0123340339167, 'action': [0.0, -1.5707963267948966]}, {'num_count': 664, 'sum_payoffs': 243.90734903526823, 'action': [1.0, 1.5707963267948966]}, {'num_count': 555, 'sum_payoffs': 195.85481305413487, 'action': [0.0, 0.0]}])
Weights num count: [0.13829491807831157, 0.17633990558178284, 0.19300194390447098, 0.1535684532074424, 0.18439322410441544, 0.15412385448486532]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 21.419188261032104 s
