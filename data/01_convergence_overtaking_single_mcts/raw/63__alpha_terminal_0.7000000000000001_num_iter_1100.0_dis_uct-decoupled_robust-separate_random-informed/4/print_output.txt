Searching game tree in timestep 0...
Max timehorizon: 5
Actions to choose Agent 0: dict_values([{'num_count': 133, 'sum_payoffs': 45.25803439727711, 'action': [2.0, 0.0]}, {'num_count': 123, 'sum_payoffs': 40.28883512796267, 'action': [1.0, 0.0]}, {'num_count': 118, 'sum_payoffs': 37.805689157493674, 'action': [0.0, 1.5707963267948966]}, {'num_count': 119, 'sum_payoffs': 38.3049830469547, 'action': [1.0, 1.5707963267948966]}, {'num_count': 122, 'sum_payoffs': 39.7747895386578, 'action': [2.0, -1.5707963267948966]}, {'num_count': 117, 'sum_payoffs': 37.341521770704865, 'action': [0.0, -1.5707963267948966]}, {'num_count': 126, 'sum_payoffs': 41.73326010763133, 'action': [1.0, -1.5707963267948966]}, {'num_count': 116, 'sum_payoffs': 36.73382641185655, 'action': [0.0, 0.0]}, {'num_count': 126, 'sum_payoffs': 41.563773288512735, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.12079927338782924, 0.11171662125340599, 0.10717529518619437, 0.1080835603996367, 0.11080835603996367, 0.10626702997275204, 0.11444141689373297, 0.10535876475930972, 0.11444141689373297]
Actions to choose Agent 1: dict_values([{'num_count': 200, 'sum_payoffs': 69.04359634979052, 'action': [1.0, 0.0]}, {'num_count': 187, 'sum_payoffs': 62.921965587770345, 'action': [1.0, 1.5707963267948966]}, {'num_count': 192, 'sum_payoffs': 65.15236048102715, 'action': [1.0, -1.5707963267948966]}, {'num_count': 174, 'sum_payoffs': 56.742307808150876, 'action': [0.0, -1.5707963267948966]}, {'num_count': 174, 'sum_payoffs': 56.78264037288021, 'action': [0.0, 0.0]}, {'num_count': 173, 'sum_payoffs': 56.24607324540945, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.18165304268846502, 0.16984559491371481, 0.17438692098092642, 0.15803814713896458, 0.15803814713896458, 0.15712988192552224]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 10.294859886169434 s
