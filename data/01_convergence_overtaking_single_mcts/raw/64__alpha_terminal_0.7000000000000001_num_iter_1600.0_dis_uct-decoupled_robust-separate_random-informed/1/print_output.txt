Searching game tree in timestep 0...
Max timehorizon: 5
Actions to choose Agent 0: dict_values([{'num_count': 162, 'sum_payoffs': 50.72967567916651, 'action': [0.0, 1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 58.343351647871756, 'action': [1.0, 0.0]}, {'num_count': 169, 'sum_payoffs': 54.08230793455322, 'action': [0.0, 0.0]}, {'num_count': 178, 'sum_payoffs': 58.142850557546154, 'action': [2.0, 1.5707963267948966]}, {'num_count': 188, 'sum_payoffs': 62.94690318093198, 'action': [2.0, 0.0]}, {'num_count': 184, 'sum_payoffs': 61.112988377565365, 'action': [0.0, -1.5707963267948966]}, {'num_count': 185, 'sum_payoffs': 61.620429078191954, 'action': [2.0, -1.5707963267948966]}, {'num_count': 175, 'sum_payoffs': 56.887867943832966, 'action': [1.0, 1.5707963267948966]}, {'num_count': 181, 'sum_payoffs': 59.798965343951906, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.10118675827607745, 0.11118051217988757, 0.10555902560899438, 0.11118051217988757, 0.1174266083697689, 0.11492816989381636, 0.1155527795128045, 0.10930668332292318, 0.11305434103685197]
Actions to choose Agent 1: dict_values([{'num_count': 258, 'sum_payoffs': 84.66644281710707, 'action': [0.0, -1.5707963267948966]}, {'num_count': 254, 'sum_payoffs': 82.99777162370003, 'action': [0.0, 0.0]}, {'num_count': 239, 'sum_payoffs': 76.2663373624296, 'action': [0.0, 1.5707963267948966]}, {'num_count': 289, 'sum_payoffs': 98.72085032321777, 'action': [1.0, 1.5707963267948966]}, {'num_count': 271, 'sum_payoffs': 90.58035249759267, 'action': [1.0, -1.5707963267948966]}, {'num_count': 289, 'sum_payoffs': 98.77188777387292, 'action': [1.0, 0.0]}])
Weights num count: [0.16114928169893816, 0.15865084322298564, 0.14928169893816365, 0.18051217988757026, 0.16926920674578388, 0.18051217988757026]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 13.158479928970337 s
