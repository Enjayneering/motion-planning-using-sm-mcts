Searching game tree in timestep 0...
Max timehorizon: 5
Actions to choose Agent 0: dict_values([{'num_count': 172, 'sum_payoffs': 55.16350269511711, 'action': [0.0, -1.5707963267948966]}, {'num_count': 180, 'sum_payoffs': 59.046712434141014, 'action': [2.0, -1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 58.02011257141269, 'action': [1.0, 0.0]}, {'num_count': 192, 'sum_payoffs': 64.671120015678, 'action': [2.0, 0.0]}, {'num_count': 176, 'sum_payoffs': 57.14924972453404, 'action': [1.0, 1.5707963267948966]}, {'num_count': 175, 'sum_payoffs': 56.60428690394424, 'action': [1.0, -1.5707963267948966]}, {'num_count': 183, 'sum_payoffs': 60.41834106396009, 'action': [2.0, 1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 55.61808550189738, 'action': [0.0, 0.0]}, {'num_count': 171, 'sum_payoffs': 54.66301002770832, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.10743285446595878, 0.11242973141786383, 0.11118051217988757, 0.11992504684572143, 0.1099312929419113, 0.10930668332292318, 0.11430356027482823, 0.1080574640849469, 0.10680824484697064]
Actions to choose Agent 1: dict_values([{'num_count': 248, 'sum_payoffs': 80.577339440878, 'action': [0.0, 1.5707963267948966]}, {'num_count': 277, 'sum_payoffs': 93.70367377608369, 'action': [1.0, 1.5707963267948966]}, {'num_count': 246, 'sum_payoffs': 79.7240421328711, 'action': [0.0, 0.0]}, {'num_count': 254, 'sum_payoffs': 83.24620577873473, 'action': [0.0, -1.5707963267948966]}, {'num_count': 283, 'sum_payoffs': 96.3632891119077, 'action': [1.0, -1.5707963267948966]}, {'num_count': 292, 'sum_payoffs': 100.33134417433048, 'action': [1.0, 0.0]}])
Weights num count: [0.15490318550905685, 0.17301686445971268, 0.15365396627108058, 0.15865084322298564, 0.17676452217364147, 0.18238600874453467]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 15.36869478225708 s
