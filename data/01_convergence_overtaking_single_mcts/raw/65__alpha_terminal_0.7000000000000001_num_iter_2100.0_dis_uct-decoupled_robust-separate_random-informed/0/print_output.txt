Searching game tree in timestep 0...
Max timehorizon: 5
Actions to choose Agent 0: dict_values([{'num_count': 237, 'sum_payoffs': 77.61344017885646, 'action': [1.0, 1.5707963267948966]}, {'num_count': 210, 'sum_payoffs': 65.45494485354382, 'action': [0.0, 1.5707963267948966]}, {'num_count': 242, 'sum_payoffs': 79.84412493997199, 'action': [2.0, 0.0]}, {'num_count': 239, 'sum_payoffs': 78.34733562101184, 'action': [1.0, 0.0]}, {'num_count': 249, 'sum_payoffs': 83.00179453035318, 'action': [1.0, -1.5707963267948966]}, {'num_count': 218, 'sum_payoffs': 69.10082549124893, 'action': [0.0, 0.0]}, {'num_count': 240, 'sum_payoffs': 79.0004160543993, 'action': [2.0, -1.5707963267948966]}, {'num_count': 223, 'sum_payoffs': 71.25249226439297, 'action': [0.0, -1.5707963267948966]}, {'num_count': 242, 'sum_payoffs': 79.84673512962742, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.1128034269395526, 0.09995240361732509, 0.11518324607329843, 0.11375535459305093, 0.1185149928605426, 0.10376011423131842, 0.1142313184198001, 0.10613993336506425, 0.11518324607329843]
Actions to choose Agent 1: dict_values([{'num_count': 313, 'sum_payoffs': 101.04119119561989, 'action': [0.0, 1.5707963267948966]}, {'num_count': 335, 'sum_payoffs': 110.72915439695987, 'action': [0.0, 0.0]}, {'num_count': 312, 'sum_payoffs': 100.64093550223166, 'action': [0.0, -1.5707963267948966]}, {'num_count': 370, 'sum_payoffs': 126.07424681643428, 'action': [1.0, 1.5707963267948966]}, {'num_count': 379, 'sum_payoffs': 130.16569011122343, 'action': [1.0, -1.5707963267948966]}, {'num_count': 391, 'sum_payoffs': 135.49078614665058, 'action': [1.0, 0.0]}])
Weights num count: [0.1489766777724893, 0.15944788196097096, 0.14850071394574013, 0.17610661589719181, 0.18039029033793433, 0.1861018562589243]
Selected final action: [1.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.22222222219629628, 0.2777777777453703]
Runtime: 17.761233806610107 s
