Searching game tree in timestep 0...
Max timehorizon: 5
Actions to choose Agent 0: dict_values([{'num_count': 329, 'sum_payoffs': 105.02571299503425, 'action': [0.0, 0.0]}, {'num_count': 348, 'sum_payoffs': 113.21038321517412, 'action': [1.0, -1.5707963267948966]}, {'num_count': 322, 'sum_payoffs': 102.05119128367834, 'action': [0.0, -1.5707963267948966]}, {'num_count': 342, 'sum_payoffs': 110.59424466540507, 'action': [1.0, 1.5707963267948966]}, {'num_count': 348, 'sum_payoffs': 113.18085694024577, 'action': [1.0, 0.0]}, {'num_count': 378, 'sum_payoffs': 126.32581691673015, 'action': [2.0, 0.0]}, {'num_count': 370, 'sum_payoffs': 122.67001911043252, 'action': [2.0, -1.5707963267948966]}, {'num_count': 348, 'sum_payoffs': 113.23635399437224, 'action': [2.0, 1.5707963267948966]}, {'num_count': 315, 'sum_payoffs': 99.01522078661267, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.10609480812641084, 0.11222186391486617, 0.1038374717832957, 0.11028700419219607, 0.11222186391486617, 0.12189616252821671, 0.11931634956465656, 0.11222186391486617, 0.10158013544018059]
Actions to choose Agent 1: dict_values([{'num_count': 484, 'sum_payoffs': 157.89985869302052, 'action': [0.0, 0.0]}, {'num_count': 528, 'sum_payoffs': 176.30962560029934, 'action': [1.0, 1.5707963267948966]}, {'num_count': 554, 'sum_payoffs': 187.3668391928084, 'action': [1.0, -1.5707963267948966]}, {'num_count': 466, 'sum_payoffs': 150.32050165008866, 'action': [0.0, 1.5707963267948966]}, {'num_count': 590, 'sum_payoffs': 202.57940775432115, 'action': [1.0, 0.0]}, {'num_count': 478, 'sum_payoffs': 155.39172601073955, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.1560786842953886, 0.17026765559496937, 0.17865204772653984, 0.15027410512737827, 0.19026120606256047, 0.15414382457271847]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 27.25721287727356 s
