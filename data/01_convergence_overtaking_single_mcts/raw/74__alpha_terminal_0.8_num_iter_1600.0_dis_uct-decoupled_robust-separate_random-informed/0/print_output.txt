Searching game tree in timestep 0...
Max timehorizon: 6
Actions to choose Agent 0: dict_values([{'num_count': 183, 'sum_payoffs': 57.12209597719631, 'action': [1.0, 1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 53.936127176476965, 'action': [0.0, -1.5707963267948966]}, {'num_count': 177, 'sum_payoffs': 54.38870392408466, 'action': [1.0, -1.5707963267948966]}, {'num_count': 167, 'sum_payoffs': 49.9683888433903, 'action': [0.0, 1.5707963267948966]}, {'num_count': 188, 'sum_payoffs': 59.4950048102868, 'action': [2.0, 0.0]}, {'num_count': 184, 'sum_payoffs': 57.51192991596667, 'action': [2.0, 1.5707963267948966]}, {'num_count': 171, 'sum_payoffs': 51.712338587446574, 'action': [0.0, 0.0]}, {'num_count': 183, 'sum_payoffs': 57.224871681397474, 'action': [2.0, -1.5707963267948966]}, {'num_count': 171, 'sum_payoffs': 51.65263483351663, 'action': [1.0, 0.0]}])
Weights num count: [0.11430356027482823, 0.1099312929419113, 0.11055590256089944, 0.10430980637101811, 0.1174266083697689, 0.11492816989381636, 0.10680824484697064, 0.11430356027482823, 0.10680824484697064]
Actions to choose Agent 1: dict_values([{'num_count': 246, 'sum_payoffs': 73.51439529641125, 'action': [0.0, 0.0]}, {'num_count': 287, 'sum_payoffs': 91.1602609649433, 'action': [1.0, 1.5707963267948966]}, {'num_count': 244, 'sum_payoffs': 72.78816810035882, 'action': [0.0, 1.5707963267948966]}, {'num_count': 270, 'sum_payoffs': 83.82135913601428, 'action': [1.0, -1.5707963267948966]}, {'num_count': 248, 'sum_payoffs': 74.52299739489612, 'action': [0.0, -1.5707963267948966]}, {'num_count': 305, 'sum_payoffs': 98.89741341121466, 'action': [1.0, 0.0]}])
Weights num count: [0.15365396627108058, 0.17926296064959402, 0.1524047470331043, 0.16864459712679575, 0.15490318550905685, 0.1905059337913804]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 17.834919214248657 s
