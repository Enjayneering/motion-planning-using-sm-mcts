Searching game tree in timestep 0...
Max timehorizon: 6
Actions to choose Agent 0: dict_values([{'num_count': 183, 'sum_payoffs': 57.47608648330405, 'action': [1.0, -1.5707963267948966]}, {'num_count': 171, 'sum_payoffs': 52.07091103315241, 'action': [0.0, 0.0]}, {'num_count': 169, 'sum_payoffs': 51.194891181000095, 'action': [0.0, -1.5707963267948966]}, {'num_count': 180, 'sum_payoffs': 56.033928922143865, 'action': [1.0, 1.5707963267948966]}, {'num_count': 174, 'sum_payoffs': 53.34933534395064, 'action': [1.0, 0.0]}, {'num_count': 169, 'sum_payoffs': 51.08231558234901, 'action': [0.0, 1.5707963267948966]}, {'num_count': 189, 'sum_payoffs': 60.149445812210544, 'action': [2.0, 0.0]}, {'num_count': 178, 'sum_payoffs': 55.21536600320685, 'action': [2.0, 1.5707963267948966]}, {'num_count': 187, 'sum_payoffs': 59.37368629394091, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.11430356027482823, 0.10680824484697064, 0.10555902560899438, 0.11242973141786383, 0.10868207370393504, 0.10555902560899438, 0.11805121798875702, 0.11118051217988757, 0.11680199875078076]
Actions to choose Agent 1: dict_values([{'num_count': 287, 'sum_payoffs': 91.11154088867586, 'action': [1.0, 1.5707963267948966]}, {'num_count': 240, 'sum_payoffs': 71.10483044288138, 'action': [0.0, 1.5707963267948966]}, {'num_count': 287, 'sum_payoffs': 91.10722776304704, 'action': [1.0, 0.0]}, {'num_count': 280, 'sum_payoffs': 88.0330212568567, 'action': [1.0, -1.5707963267948966]}, {'num_count': 253, 'sum_payoffs': 76.57776902458858, 'action': [0.0, -1.5707963267948966]}, {'num_count': 253, 'sum_payoffs': 76.50930393023782, 'action': [0.0, 0.0]}])
Weights num count: [0.17926296064959402, 0.14990630855715179, 0.17926296064959402, 0.1748906933166771, 0.1580262336039975, 0.1580262336039975]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 17.019001722335815 s
