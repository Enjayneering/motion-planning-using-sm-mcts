Searching game tree in timestep 0...
Max timehorizon: 6
Actions to choose Agent 0: dict_values([{'num_count': 177, 'sum_payoffs': 54.93124281648663, 'action': [1.0, 0.0]}, {'num_count': 177, 'sum_payoffs': 54.88313244413539, 'action': [0.0, 0.0]}, {'num_count': 171, 'sum_payoffs': 52.097096367414075, 'action': [0.0, 1.5707963267948966]}, {'num_count': 185, 'sum_payoffs': 58.608591091252066, 'action': [2.0, 0.0]}, {'num_count': 179, 'sum_payoffs': 55.76482060608805, 'action': [1.0, -1.5707963267948966]}, {'num_count': 176, 'sum_payoffs': 54.40208736785234, 'action': [1.0, 1.5707963267948966]}, {'num_count': 184, 'sum_payoffs': 58.01746771375956, 'action': [2.0, -1.5707963267948966]}, {'num_count': 180, 'sum_payoffs': 56.2900733146053, 'action': [2.0, 1.5707963267948966]}, {'num_count': 171, 'sum_payoffs': 52.213934860315106, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.11055590256089944, 0.11055590256089944, 0.10680824484697064, 0.1155527795128045, 0.11180512179887571, 0.1099312929419113, 0.11492816989381636, 0.11242973141786383, 0.10680824484697064]
Actions to choose Agent 1: dict_values([{'num_count': 293, 'sum_payoffs': 93.56448165930576, 'action': [1.0, 0.0]}, {'num_count': 285, 'sum_payoffs': 89.9861154469393, 'action': [1.0, -1.5707963267948966]}, {'num_count': 240, 'sum_payoffs': 70.88614222556431, 'action': [0.0, -1.5707963267948966]}, {'num_count': 246, 'sum_payoffs': 73.50346862652935, 'action': [0.0, 1.5707963267948966]}, {'num_count': 254, 'sum_payoffs': 76.82750768052003, 'action': [0.0, 0.0]}, {'num_count': 282, 'sum_payoffs': 88.77534424374637, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.1830106183635228, 0.17801374141161774, 0.14990630855715179, 0.15365396627108058, 0.15865084322298564, 0.17613991255465333]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 16.917240858078003 s
