Searching game tree in timestep 0...
Max timehorizon: 6
Actions to choose Agent 0: dict_values([{'num_count': 431, 'sum_payoffs': 128.74363537166948, 'action': [0.0, -1.5707963267948966]}, {'num_count': 437, 'sum_payoffs': 131.11300351203707, 'action': [0.0, 0.0]}, {'num_count': 474, 'sum_payoffs': 145.92282373786492, 'action': [2.0, -1.5707963267948966]}, {'num_count': 460, 'sum_payoffs': 140.3651690284295, 'action': [2.0, 1.5707963267948966]}, {'num_count': 463, 'sum_payoffs': 141.50778020892122, 'action': [1.0, -1.5707963267948966]}, {'num_count': 500, 'sum_payoffs': 156.4525732366136, 'action': [2.0, 0.0]}, {'num_count': 416, 'sum_payoffs': 122.86870555583931, 'action': [0.0, 1.5707963267948966]}, {'num_count': 473, 'sum_payoffs': 145.5833371358883, 'action': [1.0, 0.0]}, {'num_count': 446, 'sum_payoffs': 134.69568624399093, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.10509631797122652, 0.10655937576200927, 0.11558156547183614, 0.11216776396000976, 0.11289929285540112, 0.12192148256522799, 0.10143867349426969, 0.11533772250670568, 0.10875396244818337]
Actions to choose Agent 1: dict_values([{'num_count': 617, 'sum_payoffs': 182.20588933739253, 'action': [0.0, -1.5707963267948966]}, {'num_count': 752, 'sum_payoffs': 233.69612099388976, 'action': [1.0, 0.0]}, {'num_count': 606, 'sum_payoffs': 178.04107946001935, 'action': [0.0, 1.5707963267948966]}, {'num_count': 658, 'sum_payoffs': 197.622792435053, 'action': [0.0, 0.0]}, {'num_count': 738, 'sum_payoffs': 228.3245711035226, 'action': [1.0, 1.5707963267948966]}, {'num_count': 729, 'sum_payoffs': 224.84480229235388, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.15045110948549134, 0.1833699097781029, 0.14776883686905634, 0.16044867105584004, 0.1799561082662765, 0.17776152158010242]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 39.82745289802551 s
