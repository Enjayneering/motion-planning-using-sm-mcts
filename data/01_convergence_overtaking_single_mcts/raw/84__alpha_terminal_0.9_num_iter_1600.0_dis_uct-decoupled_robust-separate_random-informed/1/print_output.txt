Searching game tree in timestep 0...
Max timehorizon: 6
Actions to choose Agent 0: dict_values([{'num_count': 181, 'sum_payoffs': 56.82121286922204, 'action': [2.0, 1.5707963267948966]}, {'num_count': 184, 'sum_payoffs': 58.04795615772433, 'action': [2.0, -1.5707963267948966]}, {'num_count': 178, 'sum_payoffs': 55.28110625176393, 'action': [1.0, -1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 53.183362969894816, 'action': [1.0, 1.5707963267948966]}, {'num_count': 173, 'sum_payoffs': 53.07847739819454, 'action': [0.0, 0.0]}, {'num_count': 178, 'sum_payoffs': 55.3232666531907, 'action': [1.0, 0.0]}, {'num_count': 187, 'sum_payoffs': 59.50298984191756, 'action': [2.0, 0.0]}, {'num_count': 179, 'sum_payoffs': 55.870924779390194, 'action': [0.0, -1.5707963267948966]}, {'num_count': 167, 'sum_payoffs': 50.360676736524425, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.11305434103685197, 0.11492816989381636, 0.11118051217988757, 0.1080574640849469, 0.1080574640849469, 0.11118051217988757, 0.11680199875078076, 0.11180512179887571, 0.10430980637101811]
Actions to choose Agent 1: dict_values([{'num_count': 239, 'sum_payoffs': 70.46310289584491, 'action': [0.0, 1.5707963267948966]}, {'num_count': 285, 'sum_payoffs': 90.14258148384944, 'action': [1.0, 1.5707963267948966]}, {'num_count': 285, 'sum_payoffs': 90.02775495405204, 'action': [1.0, -1.5707963267948966]}, {'num_count': 256, 'sum_payoffs': 77.76849944711682, 'action': [0.0, 0.0]}, {'num_count': 281, 'sum_payoffs': 88.38271947273242, 'action': [1.0, 0.0]}, {'num_count': 254, 'sum_payoffs': 76.84706482420076, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.14928169893816365, 0.17801374141161774, 0.17801374141161774, 0.1599000624609619, 0.1755153029356652, 0.15865084322298564]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 16.98752522468567 s
