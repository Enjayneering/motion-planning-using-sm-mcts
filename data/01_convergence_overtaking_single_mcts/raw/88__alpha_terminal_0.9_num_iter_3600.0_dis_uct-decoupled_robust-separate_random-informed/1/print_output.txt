Searching game tree in timestep 0...
Max timehorizon: 6
Actions to choose Agent 0: dict_values([{'num_count': 415, 'sum_payoffs': 128.19611405970255, 'action': [2.0, 1.5707963267948966]}, {'num_count': 400, 'sum_payoffs': 122.0711743825479, 'action': [1.0, 1.5707963267948966]}, {'num_count': 383, 'sum_payoffs': 115.23962985055573, 'action': [0.0, -1.5707963267948966]}, {'num_count': 425, 'sum_payoffs': 132.4031271703832, 'action': [2.0, -1.5707963267948966]}, {'num_count': 359, 'sum_payoffs': 105.62888054924247, 'action': [0.0, 1.5707963267948966]}, {'num_count': 380, 'sum_payoffs': 113.97406188819794, 'action': [0.0, 0.0]}, {'num_count': 396, 'sum_payoffs': 120.34717245294348, 'action': [1.0, 0.0]}, {'num_count': 432, 'sum_payoffs': 135.14047736999652, 'action': [2.0, 0.0]}, {'num_count': 410, 'sum_payoffs': 126.19203634493033, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.11524576506525964, 0.11108025548458761, 0.10635934462649264, 0.11802277145237434, 0.09969452929741739, 0.10552624271035824, 0.10996945292974174, 0.11996667592335462, 0.11385726187170231]
Actions to choose Agent 1: dict_values([{'num_count': 643, 'sum_payoffs': 199.18786551477135, 'action': [1.0, -1.5707963267948966]}, {'num_count': 548, 'sum_payoffs': 162.43579636007317, 'action': [0.0, -1.5707963267948966]}, {'num_count': 645, 'sum_payoffs': 199.97342814585392, 'action': [1.0, 1.5707963267948966]}, {'num_count': 581, 'sum_payoffs': 175.12479700029323, 'action': [0.0, 0.0]}, {'num_count': 526, 'sum_payoffs': 154.0914039708023, 'action': [0.0, 1.5707963267948966]}, {'num_count': 657, 'sum_payoffs': 204.69662217064243, 'action': [1.0, 0.0]}])
Weights num count: [0.17856151069147458, 0.15217995001388504, 0.17911691196889754, 0.1613440710913635, 0.1460705359622327, 0.18244931963343516]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 38.115432262420654 s
