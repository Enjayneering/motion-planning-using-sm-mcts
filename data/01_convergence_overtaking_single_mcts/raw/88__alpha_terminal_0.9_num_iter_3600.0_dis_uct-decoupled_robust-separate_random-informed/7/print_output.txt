Searching game tree in timestep 0...
Max timehorizon: 6
Actions to choose Agent 0: dict_values([{'num_count': 419, 'sum_payoffs': 129.98655070027098, 'action': [2.0, 1.5707963267948966]}, {'num_count': 380, 'sum_payoffs': 114.14176744234298, 'action': [0.0, 0.0]}, {'num_count': 382, 'sum_payoffs': 114.96118521955856, 'action': [1.0, 1.5707963267948966]}, {'num_count': 363, 'sum_payoffs': 107.31500133629716, 'action': [0.0, 1.5707963267948966]}, {'num_count': 446, 'sum_payoffs': 141.16596813474473, 'action': [2.0, 0.0]}, {'num_count': 401, 'sum_payoffs': 122.671360540416, 'action': [1.0, -1.5707963267948966]}, {'num_count': 401, 'sum_payoffs': 122.66142051061944, 'action': [1.0, 0.0]}, {'num_count': 380, 'sum_payoffs': 114.09958384859196, 'action': [0.0, -1.5707963267948966]}, {'num_count': 428, 'sum_payoffs': 133.7048462178559, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.11635656762010553, 0.10552624271035824, 0.10608164398778117, 0.10080533185226326, 0.1238544848653152, 0.11135795612329909, 0.11135795612329909, 0.10552624271035824, 0.11885587336850875]
Actions to choose Agent 1: dict_values([{'num_count': 548, 'sum_payoffs': 163.33404442232157, 'action': [0.0, -1.5707963267948966]}, {'num_count': 571, 'sum_payoffs': 172.20460759349817, 'action': [0.0, 0.0]}, {'num_count': 527, 'sum_payoffs': 155.2296065552277, 'action': [0.0, 1.5707963267948966]}, {'num_count': 655, 'sum_payoffs': 204.8728536662369, 'action': [1.0, 0.0]}, {'num_count': 662, 'sum_payoffs': 207.6136193450503, 'action': [1.0, 1.5707963267948966]}, {'num_count': 637, 'sum_payoffs': 197.78131737566184, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.15217995001388504, 0.15856706470424883, 0.14634823660094418, 0.1818939183560122, 0.18383782282699251, 0.17689530685920576]
Selected final action: [2.0, 0.0, 1.0, 1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 40.428757667541504 s
