Searching game tree in timestep 0...
Max timehorizon: 7
Actions to choose Agent 0: dict_values([{'num_count': 253, 'sum_payoffs': 76.78009684578996, 'action': [2.0, -1.5707963267948966]}, {'num_count': 240, 'sum_payoffs': 71.29465590443351, 'action': [2.0, 1.5707963267948966]}, {'num_count': 237, 'sum_payoffs': 69.91149591596127, 'action': [1.0, 1.5707963267948966]}, {'num_count': 230, 'sum_payoffs': 67.09628302965, 'action': [0.0, 0.0]}, {'num_count': 234, 'sum_payoffs': 68.70814162231753, 'action': [2.0, 0.0]}, {'num_count': 227, 'sum_payoffs': 65.81462685676046, 'action': [0.0, -1.5707963267948966]}, {'num_count': 227, 'sum_payoffs': 65.83754120610685, 'action': [1.0, 0.0]}, {'num_count': 235, 'sum_payoffs': 69.0480863516042, 'action': [1.0, -1.5707963267948966]}, {'num_count': 217, 'sum_payoffs': 61.60219781729609, 'action': [0.0, 1.5707963267948966]}])
Weights num count: [0.12041884816753927, 0.1142313184198001, 0.1128034269395526, 0.10947168015230842, 0.11137553545930509, 0.10804378867206092, 0.10804378867206092, 0.11185149928605426, 0.10328415040456926]
Actions to choose Agent 1: dict_values([{'num_count': 371, 'sum_payoffs': 108.6695088783657, 'action': [1.0, 0.0]}, {'num_count': 372, 'sum_payoffs': 109.16687809274234, 'action': [1.0, -1.5707963267948966]}, {'num_count': 372, 'sum_payoffs': 109.08265154487557, 'action': [1.0, 1.5707963267948966]}, {'num_count': 329, 'sum_payoffs': 92.27611340730591, 'action': [0.0, -1.5707963267948966]}, {'num_count': 329, 'sum_payoffs': 92.22420392979087, 'action': [0.0, 1.5707963267948966]}, {'num_count': 327, 'sum_payoffs': 91.49359289567138, 'action': [0.0, 0.0]}])
Weights num count: [0.17658257972394098, 0.17705854355069015, 0.17705854355069015, 0.15659209900047596, 0.15659209900047596, 0.15564017134697763]
Selected final action: [2.0, -1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 29.31914234161377 s
