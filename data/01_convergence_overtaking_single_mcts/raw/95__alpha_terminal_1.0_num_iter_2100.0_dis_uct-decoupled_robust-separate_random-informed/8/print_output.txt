Searching game tree in timestep 0...
Max timehorizon: 7
Actions to choose Agent 0: dict_values([{'num_count': 224, 'sum_payoffs': 64.8503241965139, 'action': [0.0, 0.0]}, {'num_count': 233, 'sum_payoffs': 68.62592396754177, 'action': [1.0, 1.5707963267948966]}, {'num_count': 244, 'sum_payoffs': 73.28835716087488, 'action': [2.0, 0.0]}, {'num_count': 220, 'sum_payoffs': 63.0309110828978, 'action': [0.0, 1.5707963267948966]}, {'num_count': 240, 'sum_payoffs': 71.65278510772512, 'action': [1.0, -1.5707963267948966]}, {'num_count': 220, 'sum_payoffs': 63.19253815612478, 'action': [1.0, 0.0]}, {'num_count': 246, 'sum_payoffs': 74.17883633861587, 'action': [2.0, 1.5707963267948966]}, {'num_count': 246, 'sum_payoffs': 74.15535523436029, 'action': [2.0, -1.5707963267948966]}, {'num_count': 227, 'sum_payoffs': 66.08549350807793, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.10661589719181343, 0.11089957163255593, 0.11613517372679677, 0.10471204188481675, 0.1142313184198001, 0.10471204188481675, 0.1170871013802951, 0.1170871013802951, 0.10804378867206092]
Actions to choose Agent 1: dict_values([{'num_count': 327, 'sum_payoffs': 92.03317427016233, 'action': [0.0, -1.5707963267948966]}, {'num_count': 333, 'sum_payoffs': 94.42319195951754, 'action': [0.0, 0.0]}, {'num_count': 374, 'sum_payoffs': 110.62861137758527, 'action': [1.0, -1.5707963267948966]}, {'num_count': 373, 'sum_payoffs': 110.11063248026397, 'action': [1.0, 0.0]}, {'num_count': 344, 'sum_payoffs': 98.65378934446738, 'action': [0.0, 1.5707963267948966]}, {'num_count': 349, 'sum_payoffs': 100.63957078845188, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.15564017134697763, 0.15849595430747263, 0.17801047120418848, 0.1775345073774393, 0.16373155640171347, 0.1661113755354593]
Selected final action: [2.0, 1.5707963267948966, 1.0, -1.5707963267948966]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 26.877508640289307 s
