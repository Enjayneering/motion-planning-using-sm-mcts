Searching game tree in timestep 0...
Max timehorizon: 7
Actions to choose Agent 0: dict_values([{'num_count': 240, 'sum_payoffs': 71.74266786739535, 'action': [1.0, 1.5707963267948966]}, {'num_count': 226, 'sum_payoffs': 65.66480693510294, 'action': [0.0, 0.0]}, {'num_count': 218, 'sum_payoffs': 62.37653097001709, 'action': [0.0, 1.5707963267948966]}, {'num_count': 243, 'sum_payoffs': 72.90702760543105, 'action': [2.0, -1.5707963267948966]}, {'num_count': 237, 'sum_payoffs': 70.29504546280862, 'action': [2.0, 1.5707963267948966]}, {'num_count': 244, 'sum_payoffs': 73.2867687451477, 'action': [1.0, -1.5707963267948966]}, {'num_count': 246, 'sum_payoffs': 74.24134303064201, 'action': [2.0, 0.0]}, {'num_count': 221, 'sum_payoffs': 63.61726296301012, 'action': [0.0, -1.5707963267948966]}, {'num_count': 225, 'sum_payoffs': 65.24811839353795, 'action': [1.0, 0.0]}])
Weights num count: [0.1142313184198001, 0.10756782484531176, 0.10376011423131842, 0.11565920990004759, 0.1128034269395526, 0.11613517372679677, 0.1170871013802951, 0.10518800571156592, 0.10709186101856259]
Actions to choose Agent 1: dict_values([{'num_count': 330, 'sum_payoffs': 92.76579147144157, 'action': [0.0, 0.0]}, {'num_count': 390, 'sum_payoffs': 116.35929228539331, 'action': [1.0, 0.0]}, {'num_count': 362, 'sum_payoffs': 105.343968156111, 'action': [1.0, -1.5707963267948966]}, {'num_count': 319, 'sum_payoffs': 88.52348634905535, 'action': [0.0, 1.5707963267948966]}, {'num_count': 320, 'sum_payoffs': 88.75525924956487, 'action': [0.0, -1.5707963267948966]}, {'num_count': 379, 'sum_payoffs': 112.03457684812687, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.15706806282722513, 0.18562589243217514, 0.17229890528319847, 0.1518324607329843, 0.15230842455973345, 0.18039029033793433]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 26.77890419960022 s
