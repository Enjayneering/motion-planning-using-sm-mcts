Searching game tree in timestep 0...
Max timehorizon: 7
Actions to choose Agent 0: dict_values([{'num_count': 361, 'sum_payoffs': 107.27681016752153, 'action': [2.0, 0.0]}, {'num_count': 340, 'sum_payoffs': 98.99843929638581, 'action': [1.0, 1.5707963267948966]}, {'num_count': 334, 'sum_payoffs': 96.59030579982745, 'action': [0.0, -1.5707963267948966]}, {'num_count': 364, 'sum_payoffs': 108.57130255767109, 'action': [2.0, -1.5707963267948966]}, {'num_count': 343, 'sum_payoffs': 100.13045031222883, 'action': [1.0, -1.5707963267948966]}, {'num_count': 338, 'sum_payoffs': 98.16361878775014, 'action': [1.0, 0.0]}, {'num_count': 358, 'sum_payoffs': 106.13560892187903, 'action': [2.0, 1.5707963267948966]}, {'num_count': 326, 'sum_payoffs': 93.35254479809538, 'action': [0.0, 1.5707963267948966]}, {'num_count': 336, 'sum_payoffs': 97.2886616148121, 'action': [0.0, 0.0]}])
Weights num count: [0.11641405998065141, 0.10964205095130602, 0.10770719122863592, 0.11738148984198646, 0.11060948081264109, 0.10899709771041599, 0.11544663011931634, 0.10512737826507579, 0.10835214446952596]
Actions to choose Agent 1: dict_values([{'num_count': 505, 'sum_payoffs': 143.8751650228372, 'action': [0.0, 0.0]}, {'num_count': 536, 'sum_payoffs': 155.49804134569777, 'action': [1.0, 1.5707963267948966]}, {'num_count': 478, 'sum_payoffs': 133.7932429659153, 'action': [0.0, -1.5707963267948966]}, {'num_count': 551, 'sum_payoffs': 161.098289583824, 'action': [1.0, -1.5707963267948966]}, {'num_count': 470, 'sum_payoffs': 130.85919837302828, 'action': [0.0, 1.5707963267948966]}, {'num_count': 560, 'sum_payoffs': 164.49301891875874, 'action': [1.0, 0.0]}])
Weights num count: [0.16285069332473395, 0.1728474685585295, 0.15414382457271847, 0.17768461786520479, 0.15156401160915833, 0.18058690744920994]
Selected final action: [2.0, -1.5707963267948966, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 41.97101044654846 s
