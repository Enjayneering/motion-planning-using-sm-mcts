Searching game tree in timestep 0...
Max timehorizon: 7
Actions to choose Agent 0: dict_values([{'num_count': 400, 'sum_payoffs': 116.00855130314808, 'action': [1.0, 1.5707963267948966]}, {'num_count': 427, 'sum_payoffs': 126.50074861808005, 'action': [2.0, -1.5707963267948966]}, {'num_count': 380, 'sum_payoffs': 108.22794367622672, 'action': [0.0, 0.0]}, {'num_count': 393, 'sum_payoffs': 113.28378129887125, 'action': [1.0, 0.0]}, {'num_count': 381, 'sum_payoffs': 108.5438440640358, 'action': [0.0, 1.5707963267948966]}, {'num_count': 379, 'sum_payoffs': 107.73602973716032, 'action': [0.0, -1.5707963267948966]}, {'num_count': 398, 'sum_payoffs': 115.14361909598473, 'action': [1.0, -1.5707963267948966]}, {'num_count': 413, 'sum_payoffs': 121.01858052241043, 'action': [2.0, 1.5707963267948966]}, {'num_count': 429, 'sum_payoffs': 127.39769628538095, 'action': [2.0, 0.0]}])
Weights num count: [0.11108025548458761, 0.11857817272979727, 0.10552624271035824, 0.10913635101360733, 0.1058039433490697, 0.10524854207164676, 0.11052485420716468, 0.11469036378783672, 0.11913357400722022]
Actions to choose Agent 1: dict_values([{'num_count': 575, 'sum_payoffs': 161.6628429095389, 'action': [0.0, 1.5707963267948966]}, {'num_count': 559, 'sum_payoffs': 155.91978730522786, 'action': [0.0, 0.0]}, {'num_count': 633, 'sum_payoffs': 183.02043355905224, 'action': [1.0, -1.5707963267948966]}, {'num_count': 557, 'sum_payoffs': 155.1868077509713, 'action': [0.0, -1.5707963267948966]}, {'num_count': 654, 'sum_payoffs': 190.86352611446603, 'action': [1.0, 0.0]}, {'num_count': 622, 'sum_payoffs': 179.01173658669964, 'action': [1.0, 1.5707963267948966]}])
Weights num count: [0.1596778672590947, 0.1552346570397112, 0.1757845043043599, 0.15467925576228825, 0.18161621771730074, 0.17272979727853374]
Selected final action: [2.0, 0.0, 1.0, 0.0]
Total payoff list: [0.2777777777453703, 0.22222222219629628]
Runtime: 44.84097194671631 s
