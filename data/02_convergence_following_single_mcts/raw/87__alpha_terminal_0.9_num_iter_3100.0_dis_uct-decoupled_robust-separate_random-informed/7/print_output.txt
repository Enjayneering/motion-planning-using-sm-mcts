Searching game tree in timestep 0...
Max timehorizon: 6
Actions to choose Agent 0: dict_values([{'num_count': 364, 'sum_payoffs': 104.875169735456, 'action': [1.0, 0.0]}, {'num_count': 375, 'sum_payoffs': 109.28116507456916, 'action': [2.0, 0.0]}, {'num_count': 348, 'sum_payoffs': 98.63335867393818, 'action': [1.0, -1.5707963267948966]}, {'num_count': 356, 'sum_payoffs': 101.76088229117154, 'action': [2.0, -1.5707963267948966]}, {'num_count': 320, 'sum_payoffs': 87.73145182271043, 'action': [0.0, -1.5707963267948966]}, {'num_count': 335, 'sum_payoffs': 93.56936669520586, 'action': [0.0, 0.0]}, {'num_count': 330, 'sum_payoffs': 91.67840155119536, 'action': [1.0, 1.5707963267948966]}, {'num_count': 306, 'sum_payoffs': 82.35954351948133, 'action': [0.0, 1.5707963267948966]}, {'num_count': 366, 'sum_payoffs': 105.72616026245075, 'action': [2.0, 1.5707963267948966]}])
Weights num count: [0.11738148984198646, 0.12092873266688164, 0.11222186391486617, 0.11480167687842631, 0.10319251854240567, 0.10802966784908094, 0.10641728474685586, 0.09867784585617542, 0.11802644308287649]
Actions to choose Agent 1: dict_values([{'num_count': 347, 'sum_payoffs': 120.24225779693037, 'action': [1.0, 0.0]}, {'num_count': 299, 'sum_payoffs': 98.61243061712239, 'action': [0.0, -1.5707963267948966]}, {'num_count': 333, 'sum_payoffs': 113.94827789541979, 'action': [1.0, 1.5707963267948966]}, {'num_count': 292, 'sum_payoffs': 95.57883423600296, 'action': [0.0, 1.5707963267948966]}, {'num_count': 366, 'sum_payoffs': 128.94428351585196, 'action': [2.0, 1.5707963267948966]}, {'num_count': 411, 'sum_payoffs': 149.64053390920034, 'action': [2.0, 0.0]}, {'num_count': 343, 'sum_payoffs': 118.50790362154069, 'action': [1.0, -1.5707963267948966]}, {'num_count': 322, 'sum_payoffs': 108.94225715886016, 'action': [0.0, 0.0]}, {'num_count': 387, 'sum_payoffs': 138.53257949631316, 'action': [2.0, -1.5707963267948966]}])
Weights num count: [0.11189938729442116, 0.0964205095130603, 0.1073847146081909, 0.09416317316994519, 0.11802644308287649, 0.13253789100290228, 0.11060948081264109, 0.1038374717832957, 0.12479845211222186]
Selected final action: [2.0, 0.0, 2.0, 0.0]
Total payoff list: [0.24999999997083333, 0.24999999997083333]
Runtime: 38.9807915687561 s
