Searching game tree in timestep 0...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 526, 'sum_payoffs': 138.25087453967785, 'action': [2.0, 1.5707963267948966]}, {'num_count': 530, 'sum_payoffs': 139.73013490924626, 'action': [2.0, 0.0]}, {'num_count': 386, 'sum_payoffs': 89.95502247376358, 'action': [0.0, -1.5707963267948966]}, {'num_count': 454, 'sum_payoffs': 113.18340827698898, 'action': [1.0, 0.0]}, {'num_count': 387, 'sum_payoffs': 90.34482757114989, 'action': [0.0, 1.5707963267948966]}, {'num_count': 454, 'sum_payoffs': 113.20339828198316, 'action': [1.0, 1.5707963267948966]}, {'num_count': 383, 'sum_payoffs': 88.90554721156965, 'action': [0.0, 0.0]}, {'num_count': 529, 'sum_payoffs': 139.38030982184833, 'action': [2.0, -1.5707963267948966]}, {'num_count': 451, 'sum_payoffs': 112.1739130247834, 'action': [1.0, -1.5707963267948966]}])
Weights num count: [0.12826139965861985, 0.12923677151914167, 0.09412338454035601, 0.11070470616922702, 0.09436722750548647, 0.11070470616922702, 0.09339185564496465, 0.1289929285540112, 0.10997317727383565]
Actions to choose Agent 1: dict_values([{'num_count': 449, 'sum_payoffs': 147.2963517995395, 'action': [1.0, 0.0]}, {'num_count': 457, 'sum_payoffs': 150.71464265354243, 'action': [1.0, 1.5707963267948966]}, {'num_count': 526, 'sum_payoffs': 180.3098450474106, 'action': [2.0, -1.5707963267948966]}, {'num_count': 539, 'sum_payoffs': 185.8370814282984, 'action': [2.0, 0.0]}, {'num_count': 451, 'sum_payoffs': 148.195902024277, 'action': [1.0, -1.5707963267948966]}, {'num_count': 375, 'sum_payoffs': 116.15192401862299, 'action': [0.0, 1.5707963267948966]}, {'num_count': 391, 'sum_payoffs': 122.84857569166991, 'action': [0.0, 0.0]}, {'num_count': 523, 'sum_payoffs': 178.98050971529833, 'action': [2.0, 1.5707963267948966]}, {'num_count': 389, 'sum_payoffs': 122.0689654968973, 'action': [0.0, -1.5707963267948966]}])
Weights num count: [0.10948549134357474, 0.11143623506461839, 0.12826139965861985, 0.1314313582053158, 0.10997317727383565, 0.091441111923921, 0.0953425993660083, 0.12752987076322847, 0.09485491343574738]
Selected final action: [2.0, 0.0, 2.0, 0.0]
Total payoff list: [0.24999999997083333, 0.24999999997083333]
Runtime: 0.5774490833282471 s
