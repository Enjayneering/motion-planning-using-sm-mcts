Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1554, 'sum_payoffs': 593.223749792372, 'action': [1.0, 0]}, {'num_count': 546, 'sum_payoffs': 171.13274994010382, 'action': [0.0, 0]}])
Weights num count: [0.7396477867682056, 0.2598762494050452]
Actions to choose Agent 1: dict_values([{'num_count': 1535, 'sum_payoffs': 587.3917497944125, 'action': [1.0, 0]}, {'num_count': 565, 'sum_payoffs': 179.5162499371697, 'action': [0.0, 0]}])
Weights num count: [0.7306044740599714, 0.2689195621132794]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 747, 'sum_payoffs': 284.5124999004241, 'action': [0.0, 0]}, {'num_count': 1353, 'sum_payoffs': 565.1774998021921, 'action': [1.0, 0]}])
Weights num count: [0.3555449785816278, 0.643979057591623]
Actions to choose Agent 1: dict_values([{'num_count': 754, 'sum_payoffs': 288.3599998990775, 'action': [0.0, 0]}, {'num_count': 1346, 'sum_payoffs': 562.9499998029719, 'action': [1.0, 0]}])
Weights num count: [0.35887672536887194, 0.6406473108043789]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.33988428115844727 s
