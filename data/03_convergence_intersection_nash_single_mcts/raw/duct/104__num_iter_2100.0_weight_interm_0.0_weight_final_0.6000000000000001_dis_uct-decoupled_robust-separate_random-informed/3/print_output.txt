Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1549, 'sum_payoffs': 590.8544998424536, 'action': [1.0, 0]}, {'num_count': 551, 'sum_payoffs': 173.13749995382966, 'action': [0.0, 0]}])
Weights num count: [0.7372679676344598, 0.2622560685387911]
Actions to choose Agent 1: dict_values([{'num_count': 557, 'sum_payoffs': 176.4179999529546, 'action': [0.0, 0]}, {'num_count': 1543, 'sum_payoffs': 590.8544998424536, 'action': [1.0, 0]}])
Weights num count: [0.26511185149928607, 0.7344121846739647]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1369, 'sum_payoffs': 572.4674998473533, 'action': [1.0, 0]}, {'num_count': 731, 'sum_payoffs': 277.22249992607533, 'action': [0.0, 0]}])
Weights num count: [0.6515944788196097, 0.3479295573536411]
Actions to choose Agent 1: dict_values([{'num_count': 736, 'sum_payoffs': 280.0574999253195, 'action': [0.0, 0]}, {'num_count': 1364, 'sum_payoffs': 571.2524998476773, 'action': [1.0, 0]}])
Weights num count: [0.35030937648738697, 0.6492146596858639]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.32840561866760254 s
