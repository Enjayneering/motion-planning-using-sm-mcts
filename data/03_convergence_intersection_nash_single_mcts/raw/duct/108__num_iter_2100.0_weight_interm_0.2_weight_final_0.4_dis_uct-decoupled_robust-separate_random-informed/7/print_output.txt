Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1481, 'sum_payoffs': 386.2181051601625, 'action': [1.0, 0]}, {'num_count': 619, 'sum_payoffs': 126.97349996613882, 'action': [0.0, 0]}])
Weights num count: [0.7049024274155165, 0.2946216087577344]
Actions to choose Agent 1: dict_values([{'num_count': 630, 'sum_payoffs': 130.7129999651417, 'action': [0.0, 0]}, {'num_count': 1470, 'sum_payoffs': 384.42260516064084, 'action': [1.0, 0]}])
Weights num count: [0.29985721085197525, 0.6996668253212756]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 740, 'sum_payoffs': 182.0099999514629, 'action': [0.0, 0]}, {'num_count': 1360, 'sum_payoffs': 385.7549998971368, 'action': [1.0, 0]}])
Weights num count: [0.35221323179438363, 0.6473108043788672]
Actions to choose Agent 1: dict_values([{'num_count': 1361, 'sum_payoffs': 386.29499989699286, 'action': [1.0, 0]}, {'num_count': 739, 'sum_payoffs': 181.73999995153488, 'action': [0.0, 0]}])
Weights num count: [0.6477867682056164, 0.35173726796763444]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.34130048751831055 s
