Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 646, 'sum_payoffs': 96.24262498235512, 'action': [0.0, 0]}, {'num_count': 1454, 'sum_payoffs': 291.41265784131105, 'action': [1.0, 0]}])
Weights num count: [0.30747263207996195, 0.6920514040932889]
Actions to choose Agent 1: dict_values([{'num_count': 1458, 'sum_payoffs': 293.144032840994, 'action': [1.0, 0]}, {'num_count': 642, 'sum_payoffs': 95.78699998243864, 'action': [0.0, 0]}])
Weights num count: [0.6939552594002856, 0.30556877677296523]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 782, 'sum_payoffs': 143.1112499737637, 'action': [0.0, 0]}, {'num_count': 1318, 'sum_payoffs': 283.4887499480236, 'action': [1.0, 0]}])
Weights num count: [0.3722037125178486, 0.6273203236554021]
Actions to choose Agent 1: dict_values([{'num_count': 1319, 'sum_payoffs': 283.89374994794935, 'action': [1.0, 0]}, {'num_count': 781, 'sum_payoffs': 142.90874997380084, 'action': [0.0, 0]}])
Weights num count: [0.6277962874821513, 0.3717277486910995]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.3462386131286621 s
