Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 651, 'sum_payoffs': 205.03124987697902, 'action': [0.0, 0]}, {'num_count': 1949, 'sum_payoffs': 741.7574995549282, 'action': [1.0, 0]}])
Weights num count: [0.2502883506343714, 0.7493271818531334]
Actions to choose Agent 1: dict_values([{'num_count': 675, 'sum_payoffs': 215.23724987085532, 'action': [0.0, 0]}, {'num_count': 1925, 'sum_payoffs': 733.7384995597388, 'action': [1.0, 0]}])
Weights num count: [0.25951557093425603, 0.7400999615532488]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1666, 'sum_payoffs': 693.9674995836411, 'action': [1.0, 0]}, {'num_count': 934, 'sum_payoffs': 358.62749978482776, 'action': [0.0, 0]}])
Weights num count: [0.6405228758169934, 0.3590926566705113]
Actions to choose Agent 1: dict_values([{'num_count': 937, 'sum_payoffs': 360.2474997838559, 'action': [0.0, 0]}, {'num_count': 1663, 'sum_payoffs': 693.1574995841271, 'action': [1.0, 0]}])
Weights num count: [0.3602460592079969, 0.6393694732795079]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.41783618927001953 s
