Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 652, 'sum_payoffs': 205.2134999538281, 'action': [0.0, 0]}, {'num_count': 1948, 'sum_payoffs': 741.2107498332073, 'action': [1.0, 0]}])
Weights num count: [0.2506728181468666, 0.7489427143406382]
Actions to choose Agent 1: dict_values([{'num_count': 668, 'sum_payoffs': 212.321249952229, 'action': [0.0, 0]}, {'num_count': 1932, 'sum_payoffs': 736.2899998343152, 'action': [1.0, 0]}])
Weights num count: [0.2568242983467897, 0.7427912341407151]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 916, 'sum_payoffs': 350.1224999212201, 'action': [0.0, 0]}, {'num_count': 1684, 'sum_payoffs': 701.8649998420848, 'action': [1.0, 0]}])
Weights num count: [0.35217224144559783, 0.647443291041907]
Actions to choose Agent 1: dict_values([{'num_count': 1678, 'sum_payoffs': 700.0424998424946, 'action': [1.0, 0]}, {'num_count': 922, 'sum_payoffs': 353.5649999204454, 'action': [0.0, 0]}])
Weights num count: [0.6451364859669358, 0.354479046520569]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4056990146636963 s
