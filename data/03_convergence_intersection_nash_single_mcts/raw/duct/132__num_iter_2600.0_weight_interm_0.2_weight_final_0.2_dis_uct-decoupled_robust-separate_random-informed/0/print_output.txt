Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 812, 'sum_payoffs': 123.67687495671363, 'action': [0.0, 0]}, {'num_count': 1788, 'sum_payoffs': 353.70728277094236, 'action': [1.0, 0]}])
Weights num count: [0.31218762014609763, 0.6874279123414071]
Actions to choose Agent 1: dict_values([{'num_count': 810, 'sum_payoffs': 123.72749995669571, 'action': [0.0, 0]}, {'num_count': 1790, 'sum_payoffs': 355.1146577704503, 'action': [1.0, 0]}])
Weights num count: [0.31141868512110726, 0.6881968473663975]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1148, 'sum_payoffs': 224.7187499213522, 'action': [0.0, 0]}, {'num_count': 1452, 'sum_payoffs': 303.1312498939045, 'action': [1.0, 0]}])
Weights num count: [0.4413687043444829, 0.558246828143022]
Actions to choose Agent 1: dict_values([{'num_count': 1149, 'sum_payoffs': 225.0224999212459, 'action': [0.0, 0]}, {'num_count': 1451, 'sum_payoffs': 303.02999989393993, 'action': [1.0, 0]}])
Weights num count: [0.4417531718569781, 0.5578623606305267]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4133734703063965 s
