Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1903, 'sum_payoffs': 585.3383998829422, 'action': [1.0, 0]}, {'num_count': 697, 'sum_payoffs': 172.8881999654212, 'action': [0.0, 0]}])
Weights num count: [0.7316416762783545, 0.2679738562091503]
Actions to choose Agent 1: dict_values([{'num_count': 1898, 'sum_payoffs': 586.3931998827312, 'action': [1.0, 0]}, {'num_count': 702, 'sum_payoffs': 175.9157999648154, 'action': [0.0, 0]}])
Weights num count: [0.7297193387158785, 0.2698961937716263]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 958, 'sum_payoffs': 292.10399994158246, 'action': [0.0, 0]}, {'num_count': 1642, 'sum_payoffs': 550.3499998899347, 'action': [1.0, 0]}])
Weights num count: [0.368319876970396, 0.6312956555171088]
Actions to choose Agent 1: dict_values([{'num_count': 964, 'sum_payoffs': 294.53399994109645, 'action': [0.0, 0]}, {'num_count': 1636, 'sum_payoffs': 548.5679998902913, 'action': [1.0, 0]}])
Weights num count: [0.37062668204536714, 0.6289888504421376]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4304358959197998 s
