Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 957, 'sum_payoffs': 100.85024997310495, 'action': [0.0, 0]}, {'num_count': 1643, 'sum_payoffs': 223.12796046681262, 'action': [1.0, 0]}])
Weights num count: [0.3679354094579008, 0.631680123029604]
Actions to choose Agent 1: dict_values([{'num_count': 1644, 'sum_payoffs': 223.91771046660259, 'action': [1.0, 0]}, {'num_count': 956, 'sum_payoffs': 101.15399997302391, 'action': [0.0, 0]}])
Weights num count: [0.6320645905420992, 0.3675509419454056]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1061, 'sum_payoffs': 130.87499996509862, 'action': [0.0, 0]}, {'num_count': 1539, 'sum_payoffs': 221.7899999408602, 'action': [1.0, 0]}])
Weights num count: [0.407920030757401, 0.5916955017301038]
Actions to choose Agent 1: dict_values([{'num_count': 1538, 'sum_payoffs': 221.7224999408782, 'action': [1.0, 0]}, {'num_count': 1062, 'sum_payoffs': 131.21249996500862, 'action': [0.0, 0]}])
Weights num count: [0.5913110342176087, 0.4083044982698962]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4080190658569336 s
