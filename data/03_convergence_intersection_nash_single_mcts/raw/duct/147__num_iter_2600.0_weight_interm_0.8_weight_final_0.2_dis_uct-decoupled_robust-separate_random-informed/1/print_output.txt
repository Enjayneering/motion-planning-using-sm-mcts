Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1566, 'sum_payoffs': 133.29850260492137, 'action': [1.0, 0]}, {'num_count': 1034, 'sum_payoffs': 64.13894998717153, 'action': [0.0, 0]}])
Weights num count: [0.6020761245674741, 0.3975394079200308]
Actions to choose Agent 1: dict_values([{'num_count': 1574, 'sum_payoffs': 134.82040260461696, 'action': [1.0, 0]}, {'num_count': 1026, 'sum_payoffs': 63.34604998733016, 'action': [0.0, 0]}])
Weights num count: [0.6051518646674356, 0.3944636678200692]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1108, 'sum_payoffs': 80.18099998396464, 'action': [0.0, 0]}, {'num_count': 1492, 'sum_payoffs': 132.57899997348505, 'action': [1.0, 0]}])
Weights num count: [0.4259900038446751, 0.5736255286428297]
Actions to choose Agent 1: dict_values([{'num_count': 1108, 'sum_payoffs': 80.22149998395653, 'action': [0.0, 0]}, {'num_count': 1492, 'sum_payoffs': 132.53849997349315, 'action': [1.0, 0]}])
Weights num count: [0.4259900038446751, 0.5736255286428297]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4291973114013672 s
