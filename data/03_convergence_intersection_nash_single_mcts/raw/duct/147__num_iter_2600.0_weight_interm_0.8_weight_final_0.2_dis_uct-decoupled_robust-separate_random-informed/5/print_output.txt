Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1523, 'sum_payoffs': 128.8426026058121, 'action': [1.0, 0]}, {'num_count': 1077, 'sum_payoffs': 70.36379998592662, 'action': [0.0, 0]}])
Weights num count: [0.5855440215301807, 0.4140715109573241]
Actions to choose Agent 1: dict_values([{'num_count': 1524, 'sum_payoffs': 128.87905260580484, 'action': [1.0, 0]}, {'num_count': 1076, 'sum_payoffs': 70.18154998596303, 'action': [0.0, 0]}])
Weights num count: [0.5859284890426759, 0.41368704344482893]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1264, 'sum_payoffs': 101.48399997970446, 'action': [0.0, 0]}, {'num_count': 1336, 'sum_payoffs': 111.3164999777388, 'action': [1.0, 0]}])
Weights num count: [0.4859669357939254, 0.5136485966935794]
Actions to choose Agent 1: dict_values([{'num_count': 1265, 'sum_payoffs': 101.56499997968825, 'action': [0.0, 0]}, {'num_count': 1335, 'sum_payoffs': 111.15449997777122, 'action': [1.0, 0]}])
Weights num count: [0.4863514033064206, 0.5132641291810842]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4562258720397949 s
