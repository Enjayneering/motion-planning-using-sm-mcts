Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1576, 'sum_payoffs': 135.30325260452042, 'action': [1.0, 0]}, {'num_count': 1024, 'sum_payoffs': 63.18224998736273, 'action': [0.0, 0]}])
Weights num count: [0.605920799692426, 0.39369473279507883]
Actions to choose Agent 1: dict_values([{'num_count': 1021, 'sum_payoffs': 62.78219998744273, 'action': [0.0, 0]}, {'num_count': 1579, 'sum_payoffs': 135.55750260446953, 'action': [1.0, 0]}])
Weights num count: [0.39254133025759325, 0.6070742022299116]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1450, 'sum_payoffs': 126.82799997463601, 'action': [1.0, 0]}, {'num_count': 1150, 'sum_payoffs': 85.8914999828223, 'action': [0.0, 0]}])
Weights num count: [0.5574778931180315, 0.44213763936947326]
Actions to choose Agent 1: dict_values([{'num_count': 1449, 'sum_payoffs': 126.78749997464412, 'action': [1.0, 0]}, {'num_count': 1151, 'sum_payoffs': 86.012999982798, 'action': [0.0, 0]}])
Weights num count: [0.5570934256055363, 0.44252210688196847]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4103982448577881 s
