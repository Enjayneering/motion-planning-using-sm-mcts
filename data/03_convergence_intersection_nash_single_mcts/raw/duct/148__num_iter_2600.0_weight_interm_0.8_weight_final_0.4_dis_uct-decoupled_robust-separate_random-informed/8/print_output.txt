Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 902, 'sum_payoffs': 90.91428945701642, 'action': [0.0, 0]}, {'num_count': 1698, 'sum_payoffs': 232.00496048377715, 'action': [1.0, 0]}])
Weights num count: [0.34678969627066514, 0.6528258362168397]
Actions to choose Agent 1: dict_values([{'num_count': 903, 'sum_payoffs': 91.09653945698302, 'action': [0.0, 0]}, {'num_count': 1697, 'sum_payoffs': 231.94421048378834, 'action': [1.0, 0]}])
Weights num count: [0.34717416378316035, 0.6524413687043444]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1130, 'sum_payoffs': 144.0374999735958, 'action': [0.0, 0]}, {'num_count': 1470, 'sum_payoffs': 208.694999961746, 'action': [1.0, 0]}])
Weights num count: [0.4344482891195694, 0.5651672433679354]
Actions to choose Agent 1: dict_values([{'num_count': 1132, 'sum_payoffs': 144.44249997352156, 'action': [0.0, 0]}, {'num_count': 1468, 'sum_payoffs': 208.42499996179546, 'action': [1.0, 0]}])
Weights num count: [0.43521722414455977, 0.564398308342945]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4331080913543701 s
