Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1658, 'sum_payoffs': 225.20096048502472, 'action': [1.0, 0]}, {'num_count': 942, 'sum_payoffs': 97.94099998204425, 'action': [0.0, 0]}])
Weights num count: [0.6374471357170319, 0.3621683967704729]
Actions to choose Agent 1: dict_values([{'num_count': 1659, 'sum_payoffs': 225.6862104849358, 'action': [1.0, 0]}, {'num_count': 941, 'sum_payoffs': 97.94174998204419, 'action': [0.0, 0]}])
Weights num count: [0.6378316032295271, 0.3617839292579777]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1061, 'sum_payoffs': 130.87499997600722, 'action': [0.0, 0]}, {'num_count': 1539, 'sum_payoffs': 221.78999995934572, 'action': [1.0, 0]}])
Weights num count: [0.407920030757401, 0.5916955017301038]
Actions to choose Agent 1: dict_values([{'num_count': 1062, 'sum_payoffs': 131.21249997594538, 'action': [0.0, 0]}, {'num_count': 1538, 'sum_payoffs': 221.7224999593581, 'action': [1.0, 0]}])
Weights num count: [0.4083044982698962, 0.5913110342176087]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4219379425048828 s
