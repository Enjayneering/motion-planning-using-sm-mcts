Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1709, 'sum_payoffs': 292.3810375438548, 'action': [1.0, 0]}, {'num_count': 891, 'sum_payoffs': 119.51485712236992, 'action': [0.0, 0]}])
Weights num count: [0.6570549788542868, 0.34256055363321797]
Actions to choose Agent 1: dict_values([{'num_count': 1716, 'sum_payoffs': 294.64035897203894, 'action': [1.0, 0]}, {'num_count': 884, 'sum_payoffs': 118.50524997968576, 'action': [0.0, 0]}])
Weights num count: [0.6597462514417531, 0.33986928104575165]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1580, 'sum_payoffs': 290.19857137881695, 'action': [1.0, 0]}, {'num_count': 1020, 'sum_payoffs': 162.4564285435776, 'action': [0.0, 0]}])
Weights num count: [0.6074586697424068, 0.39215686274509803]
Actions to choose Agent 1: dict_values([{'num_count': 1577, 'sum_payoffs': 289.7646428074628, 'action': [1.0, 0]}, {'num_count': 1023, 'sum_payoffs': 163.2374999720151, 'action': [0.0, 0]}])
Weights num count: [0.6063052672049212, 0.3933102652825836]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.40631794929504395 s
