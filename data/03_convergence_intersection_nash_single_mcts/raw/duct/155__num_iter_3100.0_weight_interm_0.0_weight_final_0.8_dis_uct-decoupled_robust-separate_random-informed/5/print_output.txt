Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2311, 'sum_payoffs': 876.2579998028082, 'action': [1.0, 0]}, {'num_count': 789, 'sum_payoffs': 252.23399994324961, 'action': [0.0, 0]}])
Weights num count: [0.745243469848436, 0.254434053531119]
Actions to choose Agent 1: dict_values([{'num_count': 2280, 'sum_payoffs': 866.5987498049818, 'action': [1.0, 0]}, {'num_count': 820, 'sum_payoffs': 265.5382499402564, 'action': [0.0, 0]}])
Weights num count: [0.7352466946146404, 0.2644308287649145]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1900, 'sum_payoffs': 786.7124998230012, 'action': [1.0, 0]}, {'num_count': 1200, 'sum_payoffs': 468.38249989460525, 'action': [0.0, 0]}])
Weights num count: [0.6127055788455337, 0.3869719445340213]
Actions to choose Agent 1: dict_values([{'num_count': 1206, 'sum_payoffs': 471.4199998939217, 'action': [0.0, 0]}, {'num_count': 1894, 'sum_payoffs': 784.4849998235021, 'action': [1.0, 0]}])
Weights num count: [0.3889068042566914, 0.6107707191228636]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.4853851795196533 s
