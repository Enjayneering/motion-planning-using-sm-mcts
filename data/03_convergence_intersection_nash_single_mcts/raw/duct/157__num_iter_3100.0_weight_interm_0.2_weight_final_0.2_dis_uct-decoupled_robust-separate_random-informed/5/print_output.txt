Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 923, 'sum_payoffs': 139.9319999510243, 'action': [0.0, 0]}, {'num_count': 2177, 'sum_payoffs': 430.2871577441486, 'action': [1.0, 0]}])
Weights num count: [0.29764592067075135, 0.7020316027088036]
Actions to choose Agent 1: dict_values([{'num_count': 2175, 'sum_payoffs': 430.74278274398915, 'action': [1.0, 0]}, {'num_count': 925, 'sum_payoffs': 140.7521249507371, 'action': [0.0, 0]}])
Weights num count: [0.7013866494679136, 0.2982908739116414]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1917, 'sum_payoffs': 407.216249857463, 'action': [1.0, 0]}, {'num_count': 1183, 'sum_payoffs': 221.68124992241377, 'action': [0.0, 0]}])
Weights num count: [0.618187681393099, 0.38148984198645597]
Actions to choose Agent 1: dict_values([{'num_count': 1915, 'sum_payoffs': 407.013749857534, 'action': [1.0, 0]}, {'num_count': 1185, 'sum_payoffs': 222.2887499222011, 'action': [0.0, 0]}])
Weights num count: [0.617542728152209, 0.382134795227346]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.49751901626586914 s
