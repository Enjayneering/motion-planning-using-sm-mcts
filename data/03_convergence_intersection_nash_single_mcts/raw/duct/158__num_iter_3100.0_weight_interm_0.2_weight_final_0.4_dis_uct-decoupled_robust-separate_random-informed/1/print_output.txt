Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 848, 'sum_payoffs': 173.75849995366184, 'action': [0.0, 0]}, {'num_count': 2252, 'sum_payoffs': 581.590105108073, 'action': [1.0, 0]}])
Weights num count: [0.27346017413737506, 0.72621734924218]
Actions to choose Agent 1: dict_values([{'num_count': 850, 'sum_payoffs': 175.00349995332965, 'action': [0.0, 0]}, {'num_count': 2250, 'sum_payoffs': 582.5321051078222, 'action': [1.0, 0]}])
Weights num count: [0.2741051273782651, 0.7255723960012899]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1102, 'sum_payoffs': 275.6999999264781, 'action': [0.0, 0]}, {'num_count': 1998, 'sum_payoffs': 561.9299998501679, 'action': [1.0, 0]}])
Weights num count: [0.35536923573040957, 0.6443082876491454]
Actions to choose Agent 1: dict_values([{'num_count': 1996, 'sum_payoffs': 561.6599998502398, 'action': [1.0, 0]}, {'num_count': 1104, 'sum_payoffs': 276.5099999262622, 'action': [0.0, 0]}])
Weights num count: [0.6436633344082554, 0.3560141889712996]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5002286434173584 s
