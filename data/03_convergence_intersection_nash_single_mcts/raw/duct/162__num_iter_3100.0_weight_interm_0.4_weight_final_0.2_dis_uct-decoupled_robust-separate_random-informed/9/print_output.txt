Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1050, 'sum_payoffs': 105.716999971807, 'action': [0.0, 0]}, {'num_count': 2050, 'sum_payoffs': 278.7142104519939, 'action': [1.0, 0]}])
Weights num count: [0.33860045146726864, 0.6610770719122864]
Actions to choose Agent 1: dict_values([{'num_count': 1056, 'sum_payoffs': 106.93199997148298, 'action': [0.0, 0]}, {'num_count': 2044, 'sum_payoffs': 277.98521045218826, 'action': [1.0, 0]}])
Weights num count: [0.34053531118993874, 0.6591422121896162]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1851, 'sum_payoffs': 266.06999992905486, 'action': [1.0, 0]}, {'num_count': 1249, 'sum_payoffs': 154.1624999588901, 'action': [0.0, 0]}])
Weights num count: [0.5969042244437278, 0.40277329893582714]
Actions to choose Agent 1: dict_values([{'num_count': 1251, 'sum_payoffs': 154.56749995878212, 'action': [0.0, 0]}, {'num_count': 1849, 'sum_payoffs': 265.79999992912684, 'action': [1.0, 0]}])
Weights num count: [0.4034182521767172, 0.5962592712028378]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.512122392654419 s
