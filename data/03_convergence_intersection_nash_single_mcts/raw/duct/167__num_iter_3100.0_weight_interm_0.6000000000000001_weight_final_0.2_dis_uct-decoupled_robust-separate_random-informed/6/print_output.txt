Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1973, 'sum_payoffs': 205.66148679582656, 'action': [1.0, 0]}, {'num_count': 1127, 'sum_payoffs': 84.57074998097197, 'action': [0.0, 0]}])
Weights num count: [0.63624637213802, 0.36343115124153497]
Actions to choose Agent 1: dict_values([{'num_count': 1980, 'sum_payoffs': 206.6182992956106, 'action': [1.0, 0]}, {'num_count': 1120, 'sum_payoffs': 83.61393748118701, 'action': [0.0, 0]}])
Weights num count: [0.6385037084811351, 0.3611738148984199]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1841, 'sum_payoffs': 202.17937495451247, 'action': [1.0, 0]}, {'num_count': 1259, 'sum_payoffs': 113.61937497443455, 'action': [0.0, 0]}])
Weights num count: [0.5936794582392777, 0.4059980651402773]
Actions to choose Agent 1: dict_values([{'num_count': 1262, 'sum_payoffs': 114.12562497432062, 'action': [0.0, 0]}, {'num_count': 1838, 'sum_payoffs': 201.8756249545808, 'action': [1.0, 0]}])
Weights num count: [0.4069654950016124, 0.5927120283779426]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.49028539657592773 s
