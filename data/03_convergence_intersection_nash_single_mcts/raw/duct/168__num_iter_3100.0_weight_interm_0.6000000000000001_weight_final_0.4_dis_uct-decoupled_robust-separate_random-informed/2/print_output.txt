Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2135, 'sum_payoffs': 344.1547894048573, 'action': [1.0, 0]}, {'num_count': 965, 'sum_payoffs': 114.75539997704776, 'action': [0.0, 0]}])
Weights num count: [0.6884875846501128, 0.3111899387294421]
Actions to choose Agent 1: dict_values([{'num_count': 2131, 'sum_payoffs': 344.0089894048867, 'action': [1.0, 0]}, {'num_count': 969, 'sum_payoffs': 115.7759999768436, 'action': [0.0, 0]}])
Weights num count: [0.6871976781683328, 0.3124798452112222]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1227, 'sum_payoffs': 183.19499996336236, 'action': [0.0, 0]}, {'num_count': 1873, 'sum_payoffs': 320.54399993588726, 'action': [1.0, 0]}])
Weights num count: [0.39567881328603677, 0.6039987100935182]
Actions to choose Agent 1: dict_values([{'num_count': 1873, 'sum_payoffs': 320.6249999358711, 'action': [1.0, 0]}, {'num_count': 1227, 'sum_payoffs': 183.27599996334618, 'action': [0.0, 0]}])
Weights num count: [0.6039987100935182, 0.39567881328603677]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5244858264923096 s
