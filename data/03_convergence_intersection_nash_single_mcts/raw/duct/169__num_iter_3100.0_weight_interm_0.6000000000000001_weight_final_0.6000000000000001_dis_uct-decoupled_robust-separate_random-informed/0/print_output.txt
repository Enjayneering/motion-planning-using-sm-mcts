Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 959, 'sum_payoffs': 147.9959999728667, 'action': [0.0, 0]}, {'num_count': 2141, 'sum_payoffs': 422.09153281735655, 'action': [1.0, 0]}])
Weights num count: [0.309255079006772, 0.690422444372783]
Actions to choose Agent 1: dict_values([{'num_count': 2153, 'sum_payoffs': 425.5486578167224, 'action': [1.0, 0]}, {'num_count': 947, 'sum_payoffs': 145.63237497330007, 'action': [0.0, 0]}])
Weights num count: [0.6942921638181232, 0.3053853595614318]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1889, 'sum_payoffs': 400.2299999266177, 'action': [1.0, 0]}, {'num_count': 1211, 'sum_payoffs': 228.76874995805684, 'action': [0.0, 0]}])
Weights num count: [0.6091583360206385, 0.3905191873589165]
Actions to choose Agent 1: dict_values([{'num_count': 1886, 'sum_payoffs': 399.6224999267291, 'action': [1.0, 0]}, {'num_count': 1214, 'sum_payoffs': 229.57874995790831, 'action': [0.0, 0]}])
Weights num count: [0.6081909061593035, 0.3914866172202515]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5078103542327881 s
