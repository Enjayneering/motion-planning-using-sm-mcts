Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 991, 'sum_payoffs': 206.00178941874682, 'action': [0.0, 0]}, {'num_count': 2609, 'sum_payoffs': 671.0141050842406, 'action': [1.0, 0]}])
Weights num count: [0.2752013329630658, 0.7245209663982227]
Actions to choose Agent 1: dict_values([{'num_count': 2614, 'sum_payoffs': 673.9364998203038, 'action': [1.0, 0]}, {'num_count': 986, 'sum_payoffs': 205.02339468216587, 'action': [0.0, 0]}])
Weights num count: [0.72590946959178, 0.2738128297695085]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1302, 'sum_payoffs': 328.8899999122976, 'action': [0.0, 0]}, {'num_count': 2298, 'sum_payoffs': 644.0099998282842, 'action': [1.0, 0]}])
Weights num count: [0.3615662316023327, 0.6381560677589558]
Actions to choose Agent 1: dict_values([{'num_count': 2296, 'sum_payoffs': 643.7399998283563, 'action': [1.0, 0]}, {'num_count': 1304, 'sum_payoffs': 329.42999991215356, 'action': [0.0, 0]}])
Weights num count: [0.6376006664815329, 0.36212163287975563]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5686244964599609 s
