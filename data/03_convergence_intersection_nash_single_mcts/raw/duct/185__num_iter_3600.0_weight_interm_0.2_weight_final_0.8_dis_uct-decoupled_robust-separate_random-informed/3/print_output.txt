Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 919, 'sum_payoffs': 230.44433679601374, 'action': [0.0, 0]}, {'num_count': 2681, 'sum_payoffs': 821.3622629936392, 'action': [1.0, 0]}])
Weights num count: [0.25520688697584004, 0.7445154123854485]
Actions to choose Agent 1: dict_values([{'num_count': 929, 'sum_payoffs': 234.08933679528423, 'action': [0.0, 0]}, {'num_count': 2671, 'sum_payoffs': 818.5920629941916, 'action': [1.0, 0]}])
Weights num count: [0.25798389336295474, 0.7417384059983338]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2301, 'sum_payoffs': 768.8879998461979, 'action': [1.0, 0]}, {'num_count': 1299, 'sum_payoffs': 397.7279999204595, 'action': [0.0, 0]}])
Weights num count: [0.6389891696750902, 0.36073312968619825]
Actions to choose Agent 1: dict_values([{'num_count': 1309, 'sum_payoffs': 401.7779999196496, 'action': [0.0, 0]}, {'num_count': 2291, 'sum_payoffs': 765.8099998468138, 'action': [1.0, 0]}])
Weights num count: [0.36351013607331295, 0.6362121632879756]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5870974063873291 s
