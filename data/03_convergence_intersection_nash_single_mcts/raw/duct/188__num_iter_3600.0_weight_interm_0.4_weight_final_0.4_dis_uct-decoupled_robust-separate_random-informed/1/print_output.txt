Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2537, 'sum_payoffs': 498.5397827825447, 'action': [1.0, 0]}, {'num_count': 1063, 'sum_payoffs': 162.26774996349076, 'action': [0.0, 0]}])
Weights num count: [0.704526520410997, 0.2951957789502916]
Actions to choose Agent 1: dict_values([{'num_count': 2528, 'sum_payoffs': 497.1729077828511, 'action': [1.0, 0]}, {'num_count': 1072, 'sum_payoffs': 164.54587496297765, 'action': [0.0, 0]}])
Weights num count: [0.7020272146625938, 0.2976950846986948]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2322, 'sum_payoffs': 495.1012498886148, 'action': [1.0, 0]}, {'num_count': 1278, 'sum_payoffs': 235.14749994708825, 'action': [0.0, 0]}])
Weights num count: [0.6448208830880311, 0.35490141627325744]
Actions to choose Agent 1: dict_values([{'num_count': 1276, 'sum_payoffs': 234.7424999471794, 'action': [0.0, 0]}, {'num_count': 2324, 'sum_payoffs': 495.70874988847817, 'action': [1.0, 0]}])
Weights num count: [0.3543460149958345, 0.645376284365454]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.564584493637085 s
