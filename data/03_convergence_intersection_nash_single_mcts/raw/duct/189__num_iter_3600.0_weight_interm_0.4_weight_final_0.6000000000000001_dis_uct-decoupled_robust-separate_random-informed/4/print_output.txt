Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1041, 'sum_payoffs': 194.98679996100387, 'action': [0.0, 0]}, {'num_count': 2559, 'sum_payoffs': 595.9169761965854, 'action': [1.0, 0]}])
Weights num count: [0.28908636489863926, 0.7106359344626493]
Actions to choose Agent 1: dict_values([{'num_count': 2549, 'sum_payoffs': 593.9207761969842, 'action': [1.0, 0]}, {'num_count': 1051, 'sum_payoffs': 197.85779996043004, 'action': [0.0, 0]}])
Weights num count: [0.7078589280755345, 0.29186337128575396]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1792, 'sum_payoffs': 435.69449991285194, 'action': [0.0, 0]}, {'num_count': 1808, 'sum_payoffs': 440.3069999119293, 'action': [1.0, 0]}])
Weights num count: [0.4976395445709525, 0.502082754790336]
Actions to choose Agent 1: dict_values([{'num_count': 1792, 'sum_payoffs': 435.69449991285194, 'action': [0.0, 0]}, {'num_count': 1808, 'sum_payoffs': 440.3069999119293, 'action': [1.0, 0]}])
Weights num count: [0.4976395445709525, 0.502082754790336]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5611114501953125 s
