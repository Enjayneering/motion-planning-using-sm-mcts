Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1004, 'sum_payoffs': 185.25869996294972, 'action': [0.0, 0]}, {'num_count': 2596, 'sum_payoffs': 604.4143261948847, 'action': [1.0, 0]}])
Weights num count: [0.2788114412663149, 0.7209108580949736]
Actions to choose Agent 1: dict_values([{'num_count': 2597, 'sum_payoffs': 606.6332761944406, 'action': [1.0, 0]}, {'num_count': 1003, 'sum_payoffs': 185.66414996286852, 'action': [0.0, 0]}])
Weights num count: [0.721188558733685, 0.27853374062760344]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2303, 'sum_payoffs': 583.4339998833017, 'action': [1.0, 0]}, {'num_count': 1297, 'sum_payoffs': 292.20299994155397, 'action': [0.0, 0]}])
Weights num count: [0.6395445709525132, 0.3601777284087753]
Actions to choose Agent 1: dict_values([{'num_count': 1301, 'sum_payoffs': 293.53949994128664, 'action': [0.0, 0]}, {'num_count': 2299, 'sum_payoffs': 582.5834998834717, 'action': [1.0, 0]}])
Weights num count: [0.36128853096362123, 0.6384337683976673]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5622272491455078 s
