Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1275, 'sum_payoffs': 94.67043747869944, 'action': [0.0, 0]}, {'num_count': 2325, 'sum_payoffs': 241.16231244572873, 'action': [1.0, 0]}])
Weights num count: [0.35406831435712305, 0.6456539850041655]
Actions to choose Agent 1: dict_values([{'num_count': 2326, 'sum_payoffs': 241.43568744566718, 'action': [1.0, 0]}, {'num_count': 1274, 'sum_payoffs': 94.67043747869948, 'action': [0.0, 0]}])
Weights num count: [0.645931685642877, 0.35379061371841153]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2146, 'sum_payoffs': 234.73124994719083, 'action': [1.0, 0]}, {'num_count': 1454, 'sum_payoffs': 131.74312497035555, 'action': [0.0, 0]}])
Weights num count: [0.5959455706748126, 0.40377672868647596]
Actions to choose Agent 1: dict_values([{'num_count': 1454, 'sum_payoffs': 131.6924999703669, 'action': [0.0, 0]}, {'num_count': 2146, 'sum_payoffs': 234.78187494717943, 'action': [1.0, 0]}])
Weights num count: [0.40377672868647596, 0.5959455706748126]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5420281887054443 s
