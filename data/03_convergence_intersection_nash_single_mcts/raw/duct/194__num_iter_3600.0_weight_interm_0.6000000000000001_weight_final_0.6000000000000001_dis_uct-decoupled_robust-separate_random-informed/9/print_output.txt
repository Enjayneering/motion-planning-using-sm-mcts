Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2543, 'sum_payoffs': 500.00340780307556, 'action': [1.0, 0]}, {'num_count': 1057, 'sum_payoffs': 161.07299997046923, 'action': [0.0, 0]}])
Weights num count: [0.7061927242432657, 0.29352957511802275]
Actions to choose Agent 1: dict_values([{'num_count': 1065, 'sum_payoffs': 163.1744999700839, 'action': [0.0, 0]}, {'num_count': 2535, 'sum_payoffs': 499.17765780322804, 'action': [1.0, 0]}])
Weights num count: [0.2957511802277145, 0.703971119133574]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2176, 'sum_payoffs': 458.95499991585, 'action': [1.0, 0]}, {'num_count': 1424, 'sum_payoffs': 271.19249995027826, 'action': [0.0, 0]}])
Weights num count: [0.6042765898361566, 0.3954457095251319]
Actions to choose Agent 1: dict_values([{'num_count': 1430, 'sum_payoffs': 272.81249994998126, 'action': [0.0, 0]}, {'num_count': 2170, 'sum_payoffs': 457.7399999160728, 'action': [1.0, 0]}])
Weights num count: [0.3971119133574007, 0.6026103860038878]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5430397987365723 s
