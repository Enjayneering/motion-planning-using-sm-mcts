Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1027, 'sum_payoffs': 181.00799996896777, 'action': [0.0, 0]}, {'num_count': 2573, 'sum_payoffs': 573.2499923829097, 'action': [1.0, 0]}])
Weights num count: [0.2851985559566787, 0.7145237434046098]
Actions to choose Agent 1: dict_values([{'num_count': 2563, 'sum_payoffs': 571.6878495260344, 'action': [1.0, 0]}, {'num_count': 1037, 'sum_payoffs': 183.81985711134269, 'action': [0.0, 0]}])
Weights num count: [0.7117467370174951, 0.2879755623437934]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1289, 'sum_payoffs': 274.9757142385797, 'action': [0.0, 0]}, {'num_count': 2311, 'sum_payoffs': 558.9771427613165, 'action': [1.0, 0]}])
Weights num count: [0.3579561232990836, 0.641766176062205]
Actions to choose Agent 1: dict_values([{'num_count': 2301, 'sum_payoffs': 556.6628570474279, 'action': [1.0, 0]}, {'num_count': 1299, 'sum_payoffs': 277.98428566663534, 'action': [0.0, 0]}])
Weights num count: [0.6389891696750902, 0.36073312968619825]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5466279983520508 s
