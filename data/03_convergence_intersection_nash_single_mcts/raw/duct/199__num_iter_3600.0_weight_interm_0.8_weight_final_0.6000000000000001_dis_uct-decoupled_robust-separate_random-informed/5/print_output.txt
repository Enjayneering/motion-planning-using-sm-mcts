Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1128, 'sum_payoffs': 147.48299997471713, 'action': [0.0, 0]}, {'num_count': 2472, 'sum_payoffs': 419.8518946648525, 'action': [1.0, 0]}])
Weights num count: [0.31324632046653705, 0.6864759788947514]
Actions to choose Agent 1: dict_values([{'num_count': 2476, 'sum_payoffs': 422.0331089501929, 'action': [1.0, 0]}, {'num_count': 1124, 'sum_payoffs': 147.33257140331432, 'action': [0.0, 0]}])
Weights num count: [0.6875867814495973, 0.3121355179116912]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1795, 'sum_payoffs': 312.07499994649186, 'action': [0.0, 0]}, {'num_count': 1805, 'sum_payoffs': 314.324999946106, 'action': [1.0, 0]}])
Weights num count: [0.49847264648708695, 0.5012496528742016]
Actions to choose Agent 1: dict_values([{'num_count': 1795, 'sum_payoffs': 312.07499994649186, 'action': [0.0, 0]}, {'num_count': 1805, 'sum_payoffs': 314.324999946106, 'action': [1.0, 0]}])
Weights num count: [0.49847264648708695, 0.5012496528742016]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5673575401306152 s
