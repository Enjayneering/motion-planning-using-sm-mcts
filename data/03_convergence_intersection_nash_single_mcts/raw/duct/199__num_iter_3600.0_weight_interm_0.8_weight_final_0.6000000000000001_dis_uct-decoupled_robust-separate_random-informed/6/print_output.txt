Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1131, 'sum_payoffs': 148.0622142603316, 'action': [0.0, 0]}, {'num_count': 2469, 'sum_payoffs': 419.2270375221025, 'action': [1.0, 0]}])
Weights num count: [0.3140794223826715, 0.685642876978617]
Actions to choose Agent 1: dict_values([{'num_count': 1152, 'sum_payoffs': 152.56574997384527, 'action': [0.0, 0]}, {'num_count': 2448, 'sum_payoffs': 415.8170018084014, 'action': [1.0, 0]}])
Weights num count: [0.3199111357956123, 0.6798111635656762]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2250, 'sum_payoffs': 412.2192856436063, 'action': [1.0, 0]}, {'num_count': 1350, 'sum_payoffs': 213.83357139191116, 'action': [0.0, 0]}])
Weights num count: [0.6248264371008053, 0.3748958622604832]
Actions to choose Agent 1: dict_values([{'num_count': 1354, 'sum_payoffs': 214.87499996316117, 'action': [0.0, 0]}, {'num_count': 2246, 'sum_payoffs': 411.6985713579814, 'action': [1.0, 0]}])
Weights num count: [0.3760066648153291, 0.6237156345459595]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5676865577697754 s
