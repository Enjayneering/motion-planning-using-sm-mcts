Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1080, 'sum_payoffs': 166.37234207822934, 'action': [0.0, 0]}, {'num_count': 2520, 'sum_payoffs': 495.350407814259, 'action': [1.0, 0]}])
Weights num count: [0.29991668980838654, 0.6998056095529019]
Actions to choose Agent 1: dict_values([{'num_count': 1096, 'sum_payoffs': 170.05784207762994, 'action': [0.0, 0]}, {'num_count': 2504, 'sum_payoffs': 492.0294078147982, 'action': [1.0, 0]}])
Weights num count: [0.3043599000277701, 0.6953623993335185]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2176, 'sum_payoffs': 458.9549999254054, 'action': [1.0, 0]}, {'num_count': 1424, 'sum_payoffs': 271.1924999559332, 'action': [0.0, 0]}])
Weights num count: [0.6042765898361566, 0.3954457095251319]
Actions to choose Agent 1: dict_values([{'num_count': 1430, 'sum_payoffs': 272.81249995566986, 'action': [0.0, 0]}, {'num_count': 2170, 'sum_payoffs': 457.73999992560294, 'action': [1.0, 0]}])
Weights num count: [0.3971119133574007, 0.6026103860038878]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5782985687255859 s
