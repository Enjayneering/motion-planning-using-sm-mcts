Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1018, 'sum_payoffs': 329.14349988479955, 'action': [0.0, 0]}, {'num_count': 3082, 'sum_payoffs': 1164.0307495925979, 'action': [1.0, 0]}])
Weights num count: [0.2482321385028042, 0.7515240185320653]
Actions to choose Agent 1: dict_values([{'num_count': 3067, 'sum_payoffs': 1160.0212495940032, 'action': [1.0, 0]}, {'num_count': 1033, 'sum_payoffs': 335.7044998825034, 'action': [0.0, 0]}])
Weights num count: [0.7478663740551085, 0.25188978297976106]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1447, 'sum_payoffs': 559.7099998041053, 'action': [0.0, 0]}, {'num_count': 2653, 'sum_payoffs': 1100.5874996147627, 'action': [1.0, 0]}])
Weights num count: [0.35284077054376983, 0.6469153864910997]
Actions to choose Agent 1: dict_values([{'num_count': 1455, 'sum_payoffs': 563.5574998027585, 'action': [0.0, 0]}, {'num_count': 2645, 'sum_payoffs': 1097.5499996158253, 'action': [1.0, 0]}])
Weights num count: [0.3547915142648135, 0.644964642770056]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6137044429779053 s
