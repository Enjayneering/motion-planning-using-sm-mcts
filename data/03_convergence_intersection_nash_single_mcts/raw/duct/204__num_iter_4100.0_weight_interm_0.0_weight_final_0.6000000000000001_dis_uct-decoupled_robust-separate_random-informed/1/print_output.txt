Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 993, 'sum_payoffs': 319.3019999148548, 'action': [0.0, 0]}, {'num_count': 3107, 'sum_payoffs': 1173.872249687012, 'action': [1.0, 0]}])
Weights num count: [0.2421360643745428, 0.7576200926603267]
Actions to choose Agent 1: dict_values([{'num_count': 3085, 'sum_payoffs': 1167.6757496886642, 'action': [1.0, 0]}, {'num_count': 1015, 'sum_payoffs': 328.7789999123279, 'action': [0.0, 0]}])
Weights num count: [0.7522555474274567, 0.24750060960741282]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1451, 'sum_payoffs': 561.329999850323, 'action': [0.0, 0]}, {'num_count': 2649, 'sum_payoffs': 1098.5624997070227, 'action': [1.0, 0]}])
Weights num count: [0.35381614240429166, 0.6459400146305779]
Actions to choose Agent 1: dict_values([{'num_count': 2635, 'sum_payoffs': 1093.094999708481, 'action': [1.0, 0]}, {'num_count': 1465, 'sum_payoffs': 568.0124998485405, 'action': [0.0, 0]}])
Weights num count: [0.6425262131187516, 0.357229943916118]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6302757263183594 s
