Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1089, 'sum_payoffs': 225.96599993973862, 'action': [0.0, 0]}, {'num_count': 3011, 'sum_payoffs': 773.1656050570159, 'action': [1.0, 0]}])
Weights num count: [0.2655449890270666, 0.734211168007803]
Actions to choose Agent 1: dict_values([{'num_count': 1088, 'sum_payoffs': 226.15199993968878, 'action': [0.0, 0]}, {'num_count': 3012, 'sum_payoffs': 774.6806050566108, 'action': [1.0, 0]}])
Weights num count: [0.2653011460619361, 0.7344550109729334]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2047, 'sum_payoffs': 552.9899998525515, 'action': [0.0, 0]}, {'num_count': 2053, 'sum_payoffs': 554.9099998520396, 'action': [1.0, 0]}])
Weights num count: [0.4991465496220434, 0.5006096074128261]
Actions to choose Agent 1: dict_values([{'num_count': 2053, 'sum_payoffs': 554.9099998520396, 'action': [1.0, 0]}, {'num_count': 2047, 'sum_payoffs': 552.9899998525515, 'action': [0.0, 0]}])
Weights num count: [0.5006096074128261, 0.4991465496220434]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6292157173156738 s
