Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2879, 'sum_payoffs': 563.0619077680285, 'action': [1.0, 0]}, {'num_count': 1221, 'sum_payoffs': 189.23062495742272, 'action': [0.0, 0]}])
Weights num count: [0.7020238966105827, 0.29773226042428674]
Actions to choose Agent 1: dict_values([{'num_count': 2874, 'sum_payoffs': 562.8740327680716, 'action': [1.0, 0]}, {'num_count': 1226, 'sum_payoffs': 190.511999957135, 'action': [0.0, 0]}])
Weights num count: [0.7008046817849305, 0.29895147524993904]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2509, 'sum_payoffs': 529.1212498809592, 'action': [1.0, 0]}, {'num_count': 1591, 'sum_payoffs': 302.3774999319624, 'action': [0.0, 0]}])
Weights num count: [0.6118019995123141, 0.38795415752255547]
Actions to choose Agent 1: dict_values([{'num_count': 2505, 'sum_payoffs': 528.3112498811415, 'action': [1.0, 0]}, {'num_count': 1595, 'sum_payoffs': 303.3899999317346, 'action': [0.0, 0]}])
Weights num count: [0.6108266276517923, 0.3889295293830773]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6362824440002441 s
