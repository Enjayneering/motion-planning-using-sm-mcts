Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2957, 'sum_payoffs': 758.8286051240552, 'action': [1.0, 0]}, {'num_count': 1143, 'sum_payoffs': 241.08899995580077, 'action': [0.0, 0]}])
Weights num count: [0.7210436478907584, 0.2787125091441112]
Actions to choose Agent 1: dict_values([{'num_count': 2954, 'sum_payoffs': 758.6426051240895, 'action': [1.0, 0]}, {'num_count': 1146, 'sum_payoffs': 242.00399995563325, 'action': [0.0, 0]}])
Weights num count: [0.720312118995367, 0.2794440380395026]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1431, 'sum_payoffs': 359.53499993409633, 'action': [0.0, 0]}, {'num_count': 2669, 'sum_payoffs': 747.6899998629694, 'action': [1.0, 0]}])
Weights num count: [0.34893928310168254, 0.650816873933187]
Actions to choose Agent 1: dict_values([{'num_count': 1430, 'sum_payoffs': 359.5349999340964, 'action': [0.0, 0]}, {'num_count': 2670, 'sum_payoffs': 748.4999998628209, 'action': [1.0, 0]}])
Weights num count: [0.34869544013655207, 0.6510607168983175]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6050899028778076 s
