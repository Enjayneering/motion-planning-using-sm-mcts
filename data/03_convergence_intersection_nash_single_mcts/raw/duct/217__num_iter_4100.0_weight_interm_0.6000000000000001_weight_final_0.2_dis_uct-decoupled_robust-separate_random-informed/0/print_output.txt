Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2661, 'sum_payoffs': 273.8314242804847, 'action': [1.0, 0]}, {'num_count': 1439, 'sum_payoffs': 107.10056247590202, 'action': [0.0, 0]}])
Weights num count: [0.6488661302121433, 0.3508900268227262]
Actions to choose Agent 1: dict_values([{'num_count': 2667, 'sum_payoffs': 274.4456742803465, 'action': [1.0, 0]}, {'num_count': 1433, 'sum_payoffs': 106.21293747610171, 'action': [0.0, 0]}])
Weights num count: [0.6503291880029262, 0.3494269690319434]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1793, 'sum_payoffs': 170.92687496154167, 'action': [0.0, 0]}, {'num_count': 2307, 'sum_payoffs': 246.22312494460655, 'action': [1.0, 0]}])
Weights num count: [0.43721043647890756, 0.562545720555962]
Actions to choose Agent 1: dict_values([{'num_count': 2307, 'sum_payoffs': 246.22312494460652, 'action': [1.0, 0]}, {'num_count': 1793, 'sum_payoffs': 170.92687496154164, 'action': [0.0, 0]}])
Weights num count: [0.562545720555962, 0.43721043647890756]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6720180511474609 s
