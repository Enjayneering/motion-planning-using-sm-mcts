Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 3463, 'sum_payoffs': 1305.8212492165521, 'action': [1.0, 0]}, {'num_count': 1137, 'sum_payoffs': 369.6029997782311, 'action': [0.0, 0]}])
Weights num count: [0.7526624646815909, 0.24712019126276896]
Actions to choose Agent 1: dict_values([{'num_count': 3422, 'sum_payoffs': 1292.1524992247512, 'action': [1.0, 0]}, {'num_count': 1178, 'sum_payoffs': 386.5522497680608, 'action': [0.0, 0]}])
Weights num count: [0.7437513584003478, 0.25603129754401216]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1639, 'sum_payoffs': 636.2549996182652, 'action': [0.0, 0]}, {'num_count': 2961, 'sum_payoffs': 1226.3399992641937, 'action': [1.0, 0]}])
Weights num count: [0.3562269071940882, 0.6435557487502717]
Actions to choose Agent 1: dict_values([{'num_count': 1656, 'sum_payoffs': 644.152499613527, 'action': [0.0, 0]}, {'num_count': 2944, 'sum_payoffs': 1219.6574992682042, 'action': [1.0, 0]}])
Weights num count: [0.3599217561399696, 0.6398608998043903]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6787629127502441 s
