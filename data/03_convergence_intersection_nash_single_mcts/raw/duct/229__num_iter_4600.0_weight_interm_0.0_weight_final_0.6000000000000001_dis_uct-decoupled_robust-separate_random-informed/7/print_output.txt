Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 3462, 'sum_payoffs': 1304.727749652124, 'action': [1.0, 0]}, {'num_count': 1138, 'sum_payoffs': 369.9674999013462, 'action': [0.0, 0]}])
Weights num count: [0.7524451206259509, 0.24733753531840905]
Actions to choose Agent 1: dict_values([{'num_count': 1172, 'sum_payoffs': 384.00074989760446, 'action': [0.0, 0]}, {'num_count': 3428, 'sum_payoffs': 1293.9749996549908, 'action': [1.0, 0]}])
Weights num count: [0.2547272332101717, 0.7450554227341882]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 3003, 'sum_payoffs': 1244.96999966797, 'action': [1.0, 0]}, {'num_count': 1597, 'sum_payoffs': 617.6249998353073, 'action': [0.0, 0]}])
Weights num count: [0.6526841990871549, 0.347098456857205]
Actions to choose Agent 1: dict_values([{'num_count': 3004, 'sum_payoffs': 1246.1849996676456, 'action': [1.0, 0]}, {'num_count': 1596, 'sum_payoffs': 617.6249998353073, 'action': [0.0, 0]}])
Weights num count: [0.652901543142795, 0.34688111280156486]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6793665885925293 s
