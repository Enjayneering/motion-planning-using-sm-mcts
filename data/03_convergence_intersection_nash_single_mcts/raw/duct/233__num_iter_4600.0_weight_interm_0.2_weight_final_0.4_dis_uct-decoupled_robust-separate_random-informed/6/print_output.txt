Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1186, 'sum_payoffs': 245.47349993453594, 'action': [0.0, 0]}, {'num_count': 3414, 'sum_payoffs': 874.1114997669614, 'action': [1.0, 0]}])
Weights num count: [0.2577700499891328, 0.7420126059552271]
Actions to choose Agent 1: dict_values([{'num_count': 3409, 'sum_payoffs': 874.6544997668163, 'action': [1.0, 0]}, {'num_count': 1191, 'sum_payoffs': 247.60349993396767, 'action': [0.0, 0]}])
Weights num count: [0.7409258856770268, 0.25885677026733317]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1642, 'sum_payoffs': 416.369999888975, 'action': [0.0, 0]}, {'num_count': 2958, 'sum_payoffs': 826.5299997796222, 'action': [1.0, 0]}])
Weights num count: [0.35687893936100845, 0.6429037165833514]
Actions to choose Agent 1: dict_values([{'num_count': 2959, 'sum_payoffs': 827.0699997794784, 'action': [1.0, 0]}, {'num_count': 1641, 'sum_payoffs': 416.09999988904696, 'action': [0.0, 0]}])
Weights num count: [0.6431210606389915, 0.3566615953053684]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.0047972202301025 s
