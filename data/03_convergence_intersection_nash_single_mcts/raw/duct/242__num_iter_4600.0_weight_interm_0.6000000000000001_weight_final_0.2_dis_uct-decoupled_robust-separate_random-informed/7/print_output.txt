Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1643, 'sum_payoffs': 125.24287497181955, 'action': [0.0, 0]}, {'num_count': 2957, 'sum_payoffs': 301.7156742742126, 'action': [1.0, 0]}])
Weights num count: [0.35709628341664856, 0.6426863725277113]
Actions to choose Agent 1: dict_values([{'num_count': 1632, 'sum_payoffs': 124.20337497205351, 'action': [0.0, 0]}, {'num_count': 2968, 'sum_payoffs': 303.8486742737331, 'action': [1.0, 0]}])
Weights num count: [0.35470549880460767, 0.6450771571397522]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2564, 'sum_payoffs': 271.9406249388182, 'action': [1.0, 0]}, {'num_count': 2036, 'sum_payoffs': 195.73312495596065, 'action': [0.0, 0]}])
Weights num count: [0.5572701586611606, 0.4425124972831993]
Actions to choose Agent 1: dict_values([{'num_count': 2037, 'sum_payoffs': 195.98624995590373, 'action': [0.0, 0]}, {'num_count': 2563, 'sum_payoffs': 271.88999993882965, 'action': [1.0, 0]}])
Weights num count: [0.44272984133883936, 0.5570528146055206]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6827771663665771 s
