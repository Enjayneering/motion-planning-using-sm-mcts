Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1433, 'sum_payoffs': 175.57829996488536, 'action': [0.0, 0]}, {'num_count': 3167, 'sum_payoffs': 500.64138937356415, 'action': [1.0, 0]}])
Weights num count: [0.31145403173223213, 0.6883286242121278]
Actions to choose Agent 1: dict_values([{'num_count': 3182, 'sum_payoffs': 504.3889893728142, 'action': [1.0, 0]}, {'num_count': 1418, 'sum_payoffs': 173.28869996534297, 'action': [0.0, 0]}])
Weights num count: [0.6915887850467289, 0.30819387089763095]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2921, 'sum_payoffs': 500.12099989994977, 'action': [1.0, 0]}, {'num_count': 1679, 'sum_payoffs': 246.69899995066294, 'action': [0.0, 0]}])
Weights num count: [0.6348619865246685, 0.36492066941969137]
Actions to choose Agent 1: dict_values([{'num_count': 2920, 'sum_payoffs': 500.039999899966, 'action': [1.0, 0]}, {'num_count': 1680, 'sum_payoffs': 246.94199995061436, 'action': [0.0, 0]}])
Weights num count: [0.6346446424690285, 0.3651380134753314]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.7012715339660645 s
