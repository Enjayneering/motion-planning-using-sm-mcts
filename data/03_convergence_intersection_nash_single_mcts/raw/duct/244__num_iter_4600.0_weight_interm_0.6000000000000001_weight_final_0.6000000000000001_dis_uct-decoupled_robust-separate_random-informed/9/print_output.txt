Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1389, 'sum_payoffs': 218.11162496001182, 'action': [0.0, 0]}, {'num_count': 3211, 'sum_payoffs': 625.4364077801042, 'action': [1.0, 0]}])
Weights num count: [0.3018908932840687, 0.6978917626602913]
Actions to choose Agent 1: dict_values([{'num_count': 1389, 'sum_payoffs': 218.70899995990231, 'action': [0.0, 0]}, {'num_count': 3211, 'sum_payoffs': 626.8437827798464, 'action': [1.0, 0]}])
Weights num count: [0.3018908932840687, 0.6978917626602913]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1684, 'sum_payoffs': 315.74249994211095, 'action': [0.0, 0]}, {'num_count': 2916, 'sum_payoffs': 616.8037498869338, 'action': [1.0, 0]}])
Weights num count: [0.36600738969789176, 0.6337752662464682]
Actions to choose Agent 1: dict_values([{'num_count': 1690, 'sum_payoffs': 317.36249994181395, 'action': [0.0, 0]}, {'num_count': 2910, 'sum_payoffs': 615.5887498871563, 'action': [1.0, 0]}])
Weights num count: [0.3673114540317322, 0.6324712019126277]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6870052814483643 s
