Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2903, 'sum_payoffs': 242.67595258304453, 'action': [1.0, 0]}, {'num_count': 1697, 'sum_payoffs': 102.0388499795934, 'action': [0.0, 0]}])
Weights num count: [0.6309497935231472, 0.36883286242121277]
Actions to choose Agent 1: dict_values([{'num_count': 2900, 'sum_payoffs': 242.60305258305908, 'action': [1.0, 0]}, {'num_count': 1700, 'sum_payoffs': 102.54914997949136, 'action': [0.0, 0]}])
Weights num count: [0.630297761356227, 0.369484894588133]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2480, 'sum_payoffs': 209.7314999580457, 'action': [1.0, 0]}, {'num_count': 2120, 'sum_payoffs': 165.02849996699297, 'action': [0.0, 0]}])
Weights num count: [0.5390132579873941, 0.46076939795696586]
Actions to choose Agent 1: dict_values([{'num_count': 2479, 'sum_payoffs': 209.6504999580619, 'action': [1.0, 0]}, {'num_count': 2121, 'sum_payoffs': 165.19049996696057, 'action': [0.0, 0]}])
Weights num count: [0.538795913931754, 0.460986742012606]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.7497644424438477 s
