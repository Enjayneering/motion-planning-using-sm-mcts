Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 3113, 'sum_payoffs': 416.1307104500326, 'action': [1.0, 0]}, {'num_count': 1487, 'sum_payoffs': 149.8282499725309, 'action': [0.0, 0]}])
Weights num count: [0.6765920452075636, 0.32319061073679634]
Actions to choose Agent 1: dict_values([{'num_count': 3102, 'sum_payoffs': 414.9157104502562, 'action': [1.0, 0]}, {'num_count': 1498, 'sum_payoffs': 151.89374997215214, 'action': [0.0, 0]}])
Weights num count: [0.6742012605955228, 0.32558139534883723]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2813, 'sum_payoffs': 402.41999992624557, 'action': [1.0, 0]}, {'num_count': 1787, 'sum_payoffs': 220.3124999596185, 'action': [0.0, 0]}])
Weights num count: [0.6113888285155401, 0.38839382742881984]
Actions to choose Agent 1: dict_values([{'num_count': 2811, 'sum_payoffs': 402.21749992628264, 'action': [1.0, 0]}, {'num_count': 1789, 'sum_payoffs': 220.7849999595319, 'action': [0.0, 0]}])
Weights num count: [0.61095414040426, 0.3888285155401]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.722308874130249 s
