Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 332, 'sum_payoffs': 32.432352625092484, 'action': [1.0, 0]}, {'num_count': 268, 'sum_payoffs': 20.179349995964145, 'action': [0.0, 0]}])
Weights num count: [0.5524126455906821, 0.4459234608985025]
Actions to choose Agent 1: dict_values([{'num_count': 331, 'sum_payoffs': 32.43235262509248, 'action': [1.0, 0]}, {'num_count': 269, 'sum_payoffs': 20.543849995891247, 'action': [0.0, 0]}])
Weights num count: [0.5507487520798668, 0.4475873544093178]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 294, 'sum_payoffs': 24.209999995157936, 'action': [0.0, 0]}, {'num_count': 306, 'sum_payoffs': 26.54999999468982, 'action': [1.0, 0]}])
Weights num count: [0.4891846921797005, 0.5091514143094842]
Actions to choose Agent 1: dict_values([{'num_count': 294, 'sum_payoffs': 24.290999995141735, 'action': [0.0, 0]}, {'num_count': 306, 'sum_payoffs': 26.54999999468982, 'action': [1.0, 0]}])
Weights num count: [0.4891846921797005, 0.5091514143094842]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.17800354957580566 s
