Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 299, 'sum_payoffs': 90.57824996829734, 'action': [0.0, 0]}, {'num_count': 801, 'sum_payoffs': 310.3717498913702, 'action': [1.0, 0]}])
Weights num count: [0.27157129881925524, 0.7275204359673024]
Actions to choose Agent 1: dict_values([{'num_count': 316, 'sum_payoffs': 97.8682499657457, 'action': [0.0, 0]}, {'num_count': 784, 'sum_payoffs': 303.4462498937942, 'action': [1.0, 0]}])
Weights num count: [0.28701180744777477, 0.7120799273387829]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 696, 'sum_payoffs': 293.2199998973768, 'action': [1.0, 0]}, {'num_count': 404, 'sum_payoffs': 152.07749994677334, 'action': [0.0, 0]}])
Weights num count: [0.6321525885558583, 0.36693914623069934]
Actions to choose Agent 1: dict_values([{'num_count': 693, 'sum_payoffs': 292.004999897802, 'action': [1.0, 0]}, {'num_count': 407, 'sum_payoffs': 153.69749994620642, 'action': [0.0, 0]}])
Weights num count: [0.6294277929155313, 0.36966394187102636]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.22037720680236816 s
