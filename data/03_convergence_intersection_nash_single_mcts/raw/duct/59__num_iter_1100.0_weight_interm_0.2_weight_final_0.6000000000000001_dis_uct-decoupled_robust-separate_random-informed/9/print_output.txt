Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 761, 'sum_payoffs': 225.30401639667323, 'action': [1.0, 0]}, {'num_count': 339, 'sum_payoffs': 77.14743748264203, 'action': [0.0, 0]}])
Weights num count: [0.6911898274296094, 0.3079019073569482]
Actions to choose Agent 1: dict_values([{'num_count': 343, 'sum_payoffs': 79.14937498219167, 'action': [0.0, 0]}, {'num_count': 757, 'sum_payoffs': 224.9423288967547, 'action': [1.0, 0]}])
Weights num count: [0.3115349682107175, 0.6875567665758402]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 407, 'sum_payoffs': 112.76437497462742, 'action': [0.0, 0]}, {'num_count': 693, 'sum_payoffs': 222.03562495004056, 'action': [1.0, 0]}])
Weights num count: [0.36966394187102636, 0.6294277929155313]
Actions to choose Agent 1: dict_values([{'num_count': 408, 'sum_payoffs': 113.2199999745249, 'action': [0.0, 0]}, {'num_count': 692, 'sum_payoffs': 221.88374995007473, 'action': [1.0, 0]}])
Weights num count: [0.37057220708446864, 0.628519527702089]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.22801709175109863 s
