Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 663, 'sum_payoffs': 116.32753757404417, 'action': [1.0, 0]}, {'num_count': 437, 'sum_payoffs': 61.91742856081418, 'action': [0.0, 0]}])
Weights num count: [0.6021798365122616, 0.39691189827429607]
Actions to choose Agent 1: dict_values([{'num_count': 436, 'sum_payoffs': 62.1575357036301, 'action': [0.0, 0]}, {'num_count': 664, 'sum_payoffs': 117.33714471672818, 'action': [1.0, 0]}])
Weights num count: [0.3960036330608538, 0.6030881017257039]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 610, 'sum_payoffs': 111.50678569517085, 'action': [1.0, 0]}, {'num_count': 490, 'sum_payoffs': 80.87785712899225, 'action': [0.0, 0]}])
Weights num count: [0.5540417801998183, 0.44504995458673935]
Actions to choose Agent 1: dict_values([{'num_count': 609, 'sum_payoffs': 111.41999998089999, 'action': [1.0, 0]}, {'num_count': 491, 'sum_payoffs': 81.31178570034643, 'action': [0.0, 0]}])
Weights num count: [0.553133514986376, 0.44595821980018163]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.2100996971130371 s
