Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1126, 'sum_payoffs': 296.2781051841456, 'action': [1.0, 0]}, {'num_count': 474, 'sum_payoffs': 95.23499997460341, 'action': [0.0, 0]}])
Weights num count: [0.7033104309806371, 0.29606495940037475]
Actions to choose Agent 1: dict_values([{'num_count': 1120, 'sum_payoffs': 295.3631051843895, 'action': [1.0, 0]}, {'num_count': 480, 'sum_payoffs': 97.36499997403537, 'action': [0.0, 0]}])
Weights num count: [0.6995627732667083, 0.29981261711430357]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 632, 'sum_payoffs': 159.7349999574034, 'action': [0.0, 0]}, {'num_count': 968, 'sum_payoffs': 273.02999992718907, 'action': [1.0, 0]}])
Weights num count: [0.3947532792004997, 0.6046221111805122]
Actions to choose Agent 1: dict_values([{'num_count': 965, 'sum_payoffs': 272.219999927405, 'action': [1.0, 0]}, {'num_count': 635, 'sum_payoffs': 160.81499995711542, 'action': [0.0, 0]}])
Weights num count: [0.6027482823235478, 0.3966271080574641]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.32640576362609863 s
