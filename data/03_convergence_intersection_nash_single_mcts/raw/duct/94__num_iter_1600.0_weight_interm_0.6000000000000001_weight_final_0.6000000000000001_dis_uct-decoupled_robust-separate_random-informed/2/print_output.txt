Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1065, 'sum_payoffs': 213.37478285561713, 'action': [1.0, 0]}, {'num_count': 535, 'sum_payoffs': 81.17212498511815, 'action': [0.0, 0]}])
Weights num count: [0.665209244222361, 0.33416614615865087]
Actions to choose Agent 1: dict_values([{'num_count': 528, 'sum_payoffs': 80.12924998530934, 'action': [0.0, 0]}, {'num_count': 1072, 'sum_payoffs': 216.2401578550918, 'action': [1.0, 0]}])
Weights num count: [0.3297938788257339, 0.6695815115552779]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 624, 'sum_payoffs': 115.1662499788874, 'action': [0.0, 0]}, {'num_count': 976, 'sum_payoffs': 210.08249996148373, 'action': [1.0, 0]}])
Weights num count: [0.38975640224859465, 0.6096189881324172]
Actions to choose Agent 1: dict_values([{'num_count': 628, 'sum_payoffs': 116.1787499787018, 'action': [0.0, 0]}, {'num_count': 972, 'sum_payoffs': 209.27249996163226, 'action': [1.0, 0]}])
Weights num count: [0.39225484072454714, 0.6071205496564647]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.2927815914154053 s
