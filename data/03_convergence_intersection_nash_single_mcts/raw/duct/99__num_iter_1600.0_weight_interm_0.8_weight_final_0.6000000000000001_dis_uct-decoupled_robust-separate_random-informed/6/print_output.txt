Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 550, 'sum_payoffs': 71.29256953665076, 'action': [0.0, 0]}, {'num_count': 1050, 'sum_payoffs': 183.7340018482002, 'action': [1.0, 0]}])
Weights num count: [0.3435352904434728, 0.655840099937539]
Actions to choose Agent 1: dict_values([{'num_count': 540, 'sum_payoffs': 69.42378382268538, 'action': [0.0, 0]}, {'num_count': 1060, 'sum_payoffs': 186.69628756197767, 'action': [1.0, 0]}])
Weights num count: [0.3372891942535915, 0.6620861961274204]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 691, 'sum_payoffs': 113.16214283774374, 'action': [0.0, 0]}, {'num_count': 909, 'sum_payoffs': 165.92142854298444, 'action': [1.0, 0]}])
Weights num count: [0.4316052467207995, 0.5677701436602124]
Actions to choose Agent 1: dict_values([{'num_count': 693, 'sum_payoffs': 113.68285712336878, 'action': [0.0, 0]}, {'num_count': 907, 'sum_payoffs': 165.57428568590112, 'action': [1.0, 0]}])
Weights num count: [0.43285446595877575, 0.5665209244222361]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.2863895893096924 s
