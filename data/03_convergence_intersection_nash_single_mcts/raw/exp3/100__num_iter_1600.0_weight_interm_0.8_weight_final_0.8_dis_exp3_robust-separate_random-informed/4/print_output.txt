Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 161, 'sum_payoffs': 24.157124996074458, 'action': [0.0, 0]}, {'num_count': 1439, 'sum_payoffs': 272.1852828505129, 'action': [1.0, 0]}])
Weights num count: [0.100625, 0.899375]
Actions to choose Agent 1: dict_values([{'num_count': 1470, 'sum_payoffs': 279.0196578494026, 'action': [1.0, 0]}, {'num_count': 130, 'sum_payoffs': 20.2387499967112, 'action': [0.0, 0]}])
Weights num count: [0.91875, 0.08125]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1401, 'sum_payoffs': 289.8674999528971, 'action': [1.0, 0]}, {'num_count': 199, 'sum_payoffs': 37.40624999392163, 'action': [0.0, 0]}])
Weights num count: [0.875625, 0.124375]
Actions to choose Agent 1: dict_values([{'num_count': 1458, 'sum_payoffs': 299.9924999512509, 'action': [1.0, 0]}, {'num_count': 142, 'sum_payoffs': 23.433749996192084, 'action': [0.0, 0]}])
Weights num count: [0.91125, 0.08875]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6498501300811768 s
