Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1905, 'sum_payoffs': 709.1347497518142, 'action': [1.0, 0]}, {'num_count': 195, 'sum_payoffs': 54.67499998086356, 'action': [0.0, 0]}])
Weights num count: [0.9071428571428571, 0.09285714285714286]
Actions to choose Agent 1: dict_values([{'num_count': 168, 'sum_payoffs': 47.20274998347888, 'action': [0.0, 0]}, {'num_count': 1932, 'sum_payoffs': 719.887499748052, 'action': [1.0, 0]}])
Weights num count: [0.08, 0.92]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 158, 'sum_payoffs': 57.50999997987139, 'action': [0.0, 0]}, {'num_count': 1942, 'sum_payoffs': 791.5724997229297, 'action': [1.0, 0]}])
Weights num count: [0.07523809523809524, 0.9247619047619048]
Actions to choose Agent 1: dict_values([{'num_count': 1960, 'sum_payoffs': 801.2924997195265, 'action': [1.0, 0]}, {'num_count': 140, 'sum_payoffs': 51.02999998213944, 'action': [0.0, 0]}])
Weights num count: [0.9333333333333333, 0.06666666666666667]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.8282120227813721 s
