Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1949, 'sum_payoffs': 486.09110513352397, 'action': [1.0, 0]}, {'num_count': 151, 'sum_payoffs': 28.47449999240684, 'action': [0.0, 0]}])
Weights num count: [0.9280952380952381, 0.0719047619047619]
Actions to choose Agent 1: dict_values([{'num_count': 147, 'sum_payoffs': 25.166999993288837, 'action': [0.0, 0]}, {'num_count': 1953, 'sum_payoffs': 486.96860513328966, 'action': [1.0, 0]}])
Weights num count: [0.07, 0.93]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1962, 'sum_payoffs': 541.9499998554946, 'action': [1.0, 0]}, {'num_count': 138, 'sum_payoffs': 32.834999991243976, 'action': [0.0, 0]}])
Weights num count: [0.9342857142857143, 0.06571428571428571]
Actions to choose Agent 1: dict_values([{'num_count': 1806, 'sum_payoffs': 493.61999986837964, 'action': [1.0, 0]}, {'num_count': 294, 'sum_payoffs': 67.12499998209971, 'action': [0.0, 0]}])
Weights num count: [0.86, 0.14]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.820941686630249 s
