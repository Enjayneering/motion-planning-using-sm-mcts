Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 204, 'sum_payoffs': 43.91410854275088, 'action': [0.0, 0]}, {'num_count': 1896, 'sum_payoffs': 528.2161873811414, 'action': [1.0, 0]}])
Weights num count: [0.09714285714285714, 0.9028571428571428]
Actions to choose Agent 1: dict_values([{'num_count': 1972, 'sum_payoffs': 553.9609834279798, 'action': [1.0, 0]}, {'num_count': 128, 'sum_payoffs': 26.643937494005076, 'action': [0.0, 0]}])
Weights num count: [0.939047619047619, 0.06095238095238095]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1872, 'sum_payoffs': 575.7524998704633, 'action': [1.0, 0]}, {'num_count': 228, 'sum_payoffs': 60.36749998641708, 'action': [0.0, 0]}])
Weights num count: [0.8914285714285715, 0.10857142857142857]
Actions to choose Agent 1: dict_values([{'num_count': 1953, 'sum_payoffs': 603.2418748642833, 'action': [1.0, 0]}, {'num_count': 147, 'sum_payoffs': 37.738124991508876, 'action': [0.0, 0]}])
Weights num count: [0.93, 0.07]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.8056533336639404 s
