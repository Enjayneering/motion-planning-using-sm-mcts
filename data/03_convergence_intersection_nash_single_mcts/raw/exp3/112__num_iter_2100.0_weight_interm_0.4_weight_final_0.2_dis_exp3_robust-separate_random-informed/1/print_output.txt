Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1910, 'sum_payoffs': 244.69421046105955, 'action': [1.0, 0]}, {'num_count': 190, 'sum_payoffs': 19.466999994808805, 'action': [0.0, 0]}])
Weights num count: [0.9095238095238095, 0.09047619047619047]
Actions to choose Agent 1: dict_values([{'num_count': 256, 'sum_payoffs': 27.72149999260755, 'action': [0.0, 0]}, {'num_count': 1844, 'sum_payoffs': 231.94421046445967, 'action': [1.0, 0]}])
Weights num count: [0.1219047619047619, 0.878095238095238]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 210, 'sum_payoffs': 23.88749999362996, 'action': [0.0, 0]}, {'num_count': 1890, 'sum_payoffs': 261.27749993033274, 'action': [1.0, 0]}])
Weights num count: [0.1, 0.9]
Actions to choose Agent 1: dict_values([{'num_count': 166, 'sum_payoffs': 18.082499995177972, 'action': [0.0, 0]}, {'num_count': 1934, 'sum_payoffs': 267.3524999287131, 'action': [1.0, 0]}])
Weights num count: [0.07904761904761905, 0.920952380952381]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.8444876670837402 s
