Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1687, 'sum_payoffs': 161.56542430575064, 'action': [1.0, 0]}, {'num_count': 413, 'sum_payoffs': 33.06149999256114, 'action': [0.0, 0]}])
Weights num count: [0.8033333333333333, 0.19666666666666666]
Actions to choose Agent 1: dict_values([{'num_count': 227, 'sum_payoffs': 20.039062495491176, 'action': [0.0, 0]}, {'num_count': 1873, 'sum_payoffs': 185.88736180027516, 'action': [1.0, 0]}])
Weights num count: [0.10809523809523809, 0.8919047619047619]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 208, 'sum_payoffs': 18.44437499585007, 'action': [0.0, 0]}, {'num_count': 1892, 'sum_payoffs': 198.6862499552986, 'action': [1.0, 0]}])
Weights num count: [0.09904761904761905, 0.900952380952381]
Actions to choose Agent 1: dict_values([{'num_count': 1780, 'sum_payoffs': 185.2199999583275, 'action': [1.0, 0]}, {'num_count': 320, 'sum_payoffs': 26.949374993936566, 'action': [0.0, 0]}])
Weights num count: [0.8476190476190476, 0.1523809523809524]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.7911903858184814 s
