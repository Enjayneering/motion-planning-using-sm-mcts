Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 201, 'sum_payoffs': 28.662749994745113, 'action': [0.0, 0]}, {'num_count': 1899, 'sum_payoffs': 353.92440782984966, 'action': [1.0, 0]}])
Weights num count: [0.09571428571428571, 0.9042857142857142]
Actions to choose Agent 1: dict_values([{'num_count': 147, 'sum_payoffs': 22.557374995864453, 'action': [0.0, 0]}, {'num_count': 1953, 'sum_payoffs': 373.15178282632473, 'action': [1.0, 0]}])
Weights num count: [0.07, 0.93]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1857, 'sum_payoffs': 383.5237499296804, 'action': [1.0, 0]}, {'num_count': 243, 'sum_payoffs': 41.15249999245537, 'action': [0.0, 0]}])
Weights num count: [0.8842857142857142, 0.11571428571428571]
Actions to choose Agent 1: dict_values([{'num_count': 199, 'sum_payoffs': 35.17874999355055, 'action': [0.0, 0]}, {'num_count': 1901, 'sum_payoffs': 393.34499992787926, 'action': [1.0, 0]}])
Weights num count: [0.09476190476190476, 0.9052380952380953]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.808175802230835 s
