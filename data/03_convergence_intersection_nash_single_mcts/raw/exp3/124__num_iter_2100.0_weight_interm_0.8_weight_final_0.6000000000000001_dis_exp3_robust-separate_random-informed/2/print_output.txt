Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 218, 'sum_payoffs': 29.859428566309877, 'action': [0.0, 0]}, {'num_count': 1882, 'sum_payoffs': 298.78003754275755, 'action': [1.0, 0]}])
Weights num count: [0.10380952380952381, 0.8961904761904762]
Actions to choose Agent 1: dict_values([{'num_count': 1942, 'sum_payoffs': 317.3238946824346, 'action': [1.0, 0]}, {'num_count': 158, 'sum_payoffs': 21.781928567694564, 'action': [0.0, 0]}])
Weights num count: [0.9247619047619048, 0.07523809523809524]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 216, 'sum_payoffs': 33.23249999430302, 'action': [0.0, 0]}, {'num_count': 1884, 'sum_payoffs': 333.76499994277265, 'action': [1.0, 0]}])
Weights num count: [0.10285714285714286, 0.8971428571428571]
Actions to choose Agent 1: dict_values([{'num_count': 1831, 'sum_payoffs': 323.61107137308534, 'action': [1.0, 0]}, {'num_count': 269, 'sum_payoffs': 41.47714285003241, 'action': [0.0, 0]}])
Weights num count: [0.871904761904762, 0.1280952380952381]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.845705509185791 s
