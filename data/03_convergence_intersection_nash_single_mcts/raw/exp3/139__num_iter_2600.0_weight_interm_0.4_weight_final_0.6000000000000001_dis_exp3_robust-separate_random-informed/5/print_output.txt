Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2405, 'sum_payoffs': 540.4193998919002, 'action': [1.0, 0]}, {'num_count': 195, 'sum_payoffs': 34.97447367721563, 'action': [0.0, 0]}])
Weights num count: [0.925, 0.075]
Actions to choose Agent 1: dict_values([{'num_count': 178, 'sum_payoffs': 26.995973678811342, 'action': [0.0, 0]}, {'num_count': 2422, 'sum_payoffs': 543.149099891354, 'action': [1.0, 0]}])
Weights num count: [0.06846153846153846, 0.9315384615384615]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 180, 'sum_payoffs': 33.77249999324555, 'action': [0.0, 0]}, {'num_count': 2420, 'sum_payoffs': 595.9484998807972, 'action': [1.0, 0]}])
Weights num count: [0.06923076923076923, 0.9307692307692308]
Actions to choose Agent 1: dict_values([{'num_count': 2366, 'sum_payoffs': 584.8919998830089, 'action': [1.0, 0]}, {'num_count': 234, 'sum_payoffs': 51.14699998977068, 'action': [0.0, 0]}])
Weights num count: [0.91, 0.09]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.977623462677002 s
