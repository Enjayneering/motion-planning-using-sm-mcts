Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 33, 'sum_payoffs': 7.228799998554245, 'action': [0.0, 0]}, {'num_count': 67, 'sum_payoffs': 17.726399996454745, 'action': [1.0, 0]}])
Weights num count: [0.33, 0.67]
Actions to choose Agent 1: dict_values([{'num_count': 66, 'sum_payoffs': 18.330276312123438, 'action': [1.0, 0]}, {'num_count': 34, 'sum_payoffs': 8.593223682491887, 'action': [0.0, 0]}])
Weights num count: [0.66, 0.34]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 26, 'sum_payoffs': 6.070499998785901, 'action': [0.0, 0]}, {'num_count': 74, 'sum_payoffs': 20.159999995967993, 'action': [1.0, 0]}])
Weights num count: [0.26, 0.74]
Actions to choose Agent 1: dict_values([{'num_count': 45, 'sum_payoffs': 9.715499998056897, 'action': [0.0, 0]}, {'num_count': 55, 'sum_payoffs': 14.570999997085782, 'action': [1.0, 0]}])
Weights num count: [0.45, 0.55]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.09273552894592285 s
