Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 221, 'sum_payoffs': 26.23221710100037, 'action': [0.0, 0]}, {'num_count': 2379, 'sum_payoffs': 447.78878282198735, 'action': [1.0, 0]}])
Weights num count: [0.085, 0.915]
Actions to choose Agent 1: dict_values([{'num_count': 2415, 'sum_payoffs': 456.18637492588664, 'action': [1.0, 0]}, {'num_count': 185, 'sum_payoffs': 26.7648749956507, 'action': [0.0, 0]}])
Weights num count: [0.9288461538461539, 0.07115384615384615]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 191, 'sum_payoffs': 31.837499994826537, 'action': [0.0, 0]}, {'num_count': 2409, 'sum_payoffs': 495.91124991939535, 'action': [1.0, 0]}])
Weights num count: [0.07346153846153847, 0.9265384615384615]
Actions to choose Agent 1: dict_values([{'num_count': 2375, 'sum_payoffs': 488.82374992054804, 'action': [1.0, 0]}, {'num_count': 225, 'sum_payoffs': 39.12749999364193, 'action': [0.0, 0]}])
Weights num count: [0.9134615384615384, 0.08653846153846154]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.0154125690460205 s
