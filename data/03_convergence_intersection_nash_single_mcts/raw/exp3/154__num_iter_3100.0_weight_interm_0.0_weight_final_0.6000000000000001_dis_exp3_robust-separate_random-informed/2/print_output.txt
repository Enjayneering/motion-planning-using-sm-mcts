Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2941, 'sum_payoffs': 1085.6632497105295, 'action': [1.0, 0]}, {'num_count': 159, 'sum_payoffs': 42.82874998857894, 'action': [0.0, 0]}])
Weights num count: [0.9487096774193549, 0.05129032258064516]
Actions to choose Agent 1: dict_values([{'num_count': 2901, 'sum_payoffs': 1074.728249713445, 'action': [1.0, 0]}, {'num_count': 199, 'sum_payoffs': 57.0442499847881, 'action': [0.0, 0]}])
Weights num count: [0.9358064516129032, 0.06419354838709677]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2931, 'sum_payoffs': 1193.939999681582, 'action': [1.0, 0]}, {'num_count': 169, 'sum_payoffs': 59.939999984015856, 'action': [0.0, 0]}])
Weights num count: [0.9454838709677419, 0.05451612903225807]
Actions to choose Agent 1: dict_values([{'num_count': 2922, 'sum_payoffs': 1192.52249968196, 'action': [1.0, 0]}, {'num_count': 178, 'sum_payoffs': 65.00249998266585, 'action': [0.0, 0]}])
Weights num count: [0.9425806451612904, 0.05741935483870968]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.2595100402832031 s
