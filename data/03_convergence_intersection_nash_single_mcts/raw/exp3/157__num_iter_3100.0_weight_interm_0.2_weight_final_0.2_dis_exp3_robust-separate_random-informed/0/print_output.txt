Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 2840, 'sum_payoffs': 531.0404998141537, 'action': [1.0, 0]}, {'num_count': 260, 'sum_payoffs': 37.27912498695217, 'action': [0.0, 0]}])
Weights num count: [0.9161290322580645, 0.08387096774193549]
Actions to choose Agent 1: dict_values([{'num_count': 2870, 'sum_payoffs': 538.5436577062624, 'action': [1.0, 0]}, {'num_count': 230, 'sum_payoffs': 34.87896709305538, 'action': [0.0, 0]}])
Weights num count: [0.9258064516129032, 0.07419354838709677]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 2844, 'sum_payoffs': 582.4799997961213, 'action': [1.0, 0]}, {'num_count': 256, 'sum_payoffs': 42.56999998510044, 'action': [0.0, 0]}])
Weights num count: [0.9174193548387096, 0.08258064516129032]
Actions to choose Agent 1: dict_values([{'num_count': 2859, 'sum_payoffs': 589.9724997935007, 'action': [1.0, 0]}, {'num_count': 241, 'sum_payoffs': 43.177499984887774, 'action': [0.0, 0]}])
Weights num count: [0.922258064516129, 0.07774193548387097]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.259047269821167 s
