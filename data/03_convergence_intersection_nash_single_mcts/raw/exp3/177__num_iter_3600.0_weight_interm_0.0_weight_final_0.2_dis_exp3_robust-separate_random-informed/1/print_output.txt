Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 205, 'sum_payoffs': 58.6844999647895, 'action': [0.0, 0]}, {'num_count': 3395, 'sum_payoffs': 1247.318999251642, 'action': [1.0, 0]}])
Weights num count: [0.05694444444444444, 0.9430555555555555]
Actions to choose Agent 1: dict_values([{'num_count': 3384, 'sum_payoffs': 1253.5154992479224, 'action': [1.0, 0]}, {'num_count': 216, 'sum_payoffs': 64.8809999610716, 'action': [0.0, 0]}])
Weights num count: [0.94, 0.06]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 243, 'sum_payoffs': 99.83249994010029, 'action': [1.0, 0]}, {'num_count': 3357, 'sum_payoffs': 1320.70499920755, 'action': [0.0, 0]}])
Weights num count: [0.0675, 0.9325]
Actions to choose Agent 1: dict_values([{'num_count': 203, 'sum_payoffs': 77.9624999532225, 'action': [0.0, 0]}, {'num_count': 3397, 'sum_payoffs': 1417.0949991497034, 'action': [1.0, 0]}])
Weights num count: [0.05638888888888889, 0.9436111111111111]
Selected final action: [0.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 1.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.4691157341003418 s
