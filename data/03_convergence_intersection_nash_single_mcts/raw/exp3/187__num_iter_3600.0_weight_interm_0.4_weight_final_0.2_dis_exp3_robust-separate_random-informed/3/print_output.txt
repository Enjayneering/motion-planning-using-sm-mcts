Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 3269, 'sum_payoffs': 411.69596041655564, 'action': [1.0, 0]}, {'num_count': 331, 'sum_payoffs': 33.31724999111525, 'action': [0.0, 0]}])
Weights num count: [0.9080555555555555, 0.09194444444444444]
Actions to choose Agent 1: dict_values([{'num_count': 313, 'sum_payoffs': 31.12349999170029, 'action': [0.0, 0]}, {'num_count': 3287, 'sum_payoffs': 412.43171041635975, 'action': [1.0, 0]}])
Weights num count: [0.08694444444444445, 0.9130555555555555]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 3286, 'sum_payoffs': 450.0074998800169, 'action': [1.0, 0]}, {'num_count': 314, 'sum_payoffs': 37.5224999899939, 'action': [0.0, 0]}])
Weights num count: [0.9127777777777778, 0.08722222222222223]
Actions to choose Agent 1: dict_values([{'num_count': 250, 'sum_payoffs': 28.612499992369905, 'action': [0.0, 0]}, {'num_count': 3350, 'sum_payoffs': 459.45749987749747, 'action': [1.0, 0]}])
Weights num count: [0.06944444444444445, 0.9305555555555556]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.431562900543213 s
