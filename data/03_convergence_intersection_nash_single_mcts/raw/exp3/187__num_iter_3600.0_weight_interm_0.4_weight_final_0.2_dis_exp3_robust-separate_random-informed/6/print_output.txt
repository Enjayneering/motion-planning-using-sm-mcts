Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 300, 'sum_payoffs': 33.11399999116949, 'action': [0.0, 0]}, {'num_count': 3300, 'sum_payoffs': 417.7904998886157, 'action': [1.0, 0]}])
Weights num count: [0.08333333333333333, 0.9166666666666666]
Actions to choose Agent 1: dict_values([{'num_count': 3242, 'sum_payoffs': 406.8359604178511, 'action': [1.0, 0]}, {'num_count': 358, 'sum_payoffs': 33.86253946465404, 'action': [0.0, 0]}])
Weights num count: [0.9005555555555556, 0.09944444444444445]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 3276, 'sum_payoffs': 448.92749988030477, 'action': [1.0, 0]}, {'num_count': 324, 'sum_payoffs': 38.39999998975995, 'action': [0.0, 0]}])
Weights num count: [0.91, 0.09]
Actions to choose Agent 1: dict_values([{'num_count': 263, 'sum_payoffs': 30.907499991757874, 'action': [0.0, 0]}, {'num_count': 3337, 'sum_payoffs': 457.36499987805536, 'action': [1.0, 0]}])
Weights num count: [0.07305555555555555, 0.9269444444444445]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.6113431453704834 s
