Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 243, 'sum_payoffs': 45.0306236752043, 'action': [0.0, 0]}, {'num_count': 3357, 'sum_payoffs': 747.006726166356, 'action': [1.0, 0]}])
Weights num count: [0.0675, 0.9325]
Actions to choose Agent 1: dict_values([{'num_count': 244, 'sum_payoffs': 42.37427367573559, 'action': [0.0, 0]}, {'num_count': 3356, 'sum_payoffs': 749.2256761659119, 'action': [1.0, 0]}])
Weights num count: [0.06777777777777778, 0.9322222222222222]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 3332, 'sum_payoffs': 814.8914998370032, 'action': [1.0, 0]}, {'num_count': 268, 'sum_payoffs': 56.857499988628575, 'action': [0.0, 0]}])
Weights num count: [0.9255555555555556, 0.07444444444444444]
Actions to choose Agent 1: dict_values([{'num_count': 3344, 'sum_payoffs': 823.1534998353508, 'action': [1.0, 0]}, {'num_count': 256, 'sum_payoffs': 57.100499988580005, 'action': [0.0, 0]}])
Weights num count: [0.9288888888888889, 0.07111111111111111]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.4679381847381592 s
