Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 321, 'sum_payoffs': 24.27637499453778, 'action': [0.0, 0]}, {'num_count': 3279, 'sum_payoffs': 313.4463749294697, 'action': [1.0, 0]}])
Weights num count: [0.08916666666666667, 0.9108333333333334]
Actions to choose Agent 1: dict_values([{'num_count': 338, 'sum_payoffs': 24.777562494425016, 'action': [0.0, 0]}, {'num_count': 3262, 'sum_payoffs': 306.01968743113963, 'action': [1.0, 0]}])
Weights num count: [0.09388888888888888, 0.9061111111111111]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 335, 'sum_payoffs': 27.708749993765718, 'action': [0.0, 0]}, {'num_count': 3265, 'sum_payoffs': 336.79124992421487, 'action': [1.0, 0]}])
Weights num count: [0.09305555555555556, 0.9069444444444444]
Actions to choose Agent 1: dict_values([{'num_count': 327, 'sum_payoffs': 29.429999993378463, 'action': [0.0, 0]}, {'num_count': 3273, 'sum_payoffs': 339.01874992371313, 'action': [1.0, 0]}])
Weights num count: [0.09083333333333334, 0.9091666666666667]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.749291181564331 s
