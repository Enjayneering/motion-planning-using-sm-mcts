Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 3351, 'sum_payoffs': 719.2582780721544, 'action': [1.0, 0]}, {'num_count': 249, 'sum_payoffs': 39.53815036916195, 'action': [0.0, 0]}])
Weights num count: [0.9308333333333333, 0.06916666666666667]
Actions to choose Agent 1: dict_values([{'num_count': 256, 'sum_payoffs': 40.57957894041199, 'action': [0.0, 0]}, {'num_count': 3344, 'sum_payoffs': 710.7185637879048, 'action': [1.0, 0]}])
Weights num count: [0.07111111111111111, 0.9288888888888889]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 256, 'sum_payoffs': 52.341428562455555, 'action': [0.0, 0]}, {'num_count': 3344, 'sum_payoffs': 782.5371427229442, 'action': [1.0, 0]}])
Weights num count: [0.07111111111111111, 0.9288888888888889]
Actions to choose Agent 1: dict_values([{'num_count': 253, 'sum_payoffs': 51.415714276900005, 'action': [0.0, 0]}, {'num_count': 3347, 'sum_payoffs': 782.537142722944, 'action': [1.0, 0]}])
Weights num count: [0.07027777777777777, 0.9297222222222222]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.3250229358673096 s
