Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 3832, 'sum_payoffs': 1411.1617496237466, 'action': [1.0, 0]}, {'num_count': 268, 'sum_payoffs': 72.71774998060852, 'action': [0.0, 0]}])
Weights num count: [0.9346341463414635, 0.06536585365853659]
Actions to choose Agent 1: dict_values([{'num_count': 3878, 'sum_payoffs': 1439.4104996162148, 'action': [1.0, 0]}, {'num_count': 222, 'sum_payoffs': 65.60999998250391, 'action': [0.0, 0]}])
Weights num count: [0.9458536585365853, 0.054146341463414634]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 3791, 'sum_payoffs': 1488.374999603044, 'action': [0.0, 0]}, {'num_count': 309, 'sum_payoffs': 128.99249996560167, 'action': [1.0, 0]}])
Weights num count: [0.9246341463414635, 0.07536585365853658]
Actions to choose Agent 1: dict_values([{'num_count': 3853, 'sum_payoffs': 1609.0649995708513, 'action': [1.0, 0]}, {'num_count': 247, 'sum_payoffs': 94.97249997467377, 'action': [0.0, 0]}])
Weights num count: [0.9397560975609756, 0.06024390243902439]
Selected final action: [0.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 1.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.8066282272338867 s
