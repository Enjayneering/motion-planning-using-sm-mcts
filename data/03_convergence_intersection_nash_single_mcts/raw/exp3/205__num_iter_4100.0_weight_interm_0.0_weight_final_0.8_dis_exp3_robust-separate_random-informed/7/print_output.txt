Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 268, 'sum_payoffs': 80.91899998179302, 'action': [0.0, 0]}, {'num_count': 3832, 'sum_payoffs': 1414.624499681717, 'action': [1.0, 0]}])
Weights num count: [0.06536585365853659, 0.9346341463414635]
Actions to choose Agent 1: dict_values([{'num_count': 3848, 'sum_payoffs': 1420.6387496803652, 'action': [1.0, 0]}, {'num_count': 252, 'sum_payoffs': 72.71774998363846, 'action': [0.0, 0]}])
Weights num count: [0.9385365853658536, 0.06146341463414634]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 272, 'sum_payoffs': 104.48999997649025, 'action': [0.0, 0]}, {'num_count': 3828, 'sum_payoffs': 1560.0599996489157, 'action': [1.0, 0]}])
Weights num count: [0.06634146341463415, 0.9336585365853659]
Actions to choose Agent 1: dict_values([{'num_count': 3874, 'sum_payoffs': 1575.6524996454039, 'action': [1.0, 0]}, {'num_count': 226, 'sum_payoffs': 80.79749998182075, 'action': [0.0, 0]}])
Weights num count: [0.9448780487804878, 0.055121951219512196]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.5654582977294922 s
