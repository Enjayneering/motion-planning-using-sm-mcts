Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 240, 'sum_payoffs': 39.838499989376395, 'action': [0.0, 0]}, {'num_count': 3860, 'sum_payoffs': 957.1466050079955, 'action': [1.0, 0]}])
Weights num count: [0.05853658536585366, 0.9414634146341463]
Actions to choose Agent 1: dict_values([{'num_count': 271, 'sum_payoffs': 51.28949998632273, 'action': [0.0, 0]}, {'num_count': 3829, 'sum_payoffs': 950.0696050098811, 'action': [1.0, 0]}])
Weights num count: [0.06609756097560976, 0.9339024390243903]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 3745, 'sum_payoffs': 1041.719999722244, 'action': [1.0, 0]}, {'num_count': 355, 'sum_payoffs': 90.61499997583599, 'action': [0.0, 0]}])
Weights num count: [0.9134146341463415, 0.08658536585365853]
Actions to choose Agent 1: dict_values([{'num_count': 3755, 'sum_payoffs': 985.6649997371946, 'action': [0.0, 0]}, {'num_count': 345, 'sum_payoffs': 98.06999997384808, 'action': [1.0, 0]}])
Weights num count: [0.9158536585365854, 0.08414634146341464]
Selected final action: [1.0, 0, 0.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 1.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 2.134718179702759 s
