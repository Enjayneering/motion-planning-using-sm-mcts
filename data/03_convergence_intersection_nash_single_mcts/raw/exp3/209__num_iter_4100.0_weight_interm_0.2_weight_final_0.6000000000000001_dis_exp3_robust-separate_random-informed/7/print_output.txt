Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 243, 'sum_payoffs': 54.474749987743216, 'action': [0.0, 0]}, {'num_count': 3857, 'sum_payoffs': 1071.5363287062708, 'action': [1.0, 0]}])
Weights num count: [0.059268292682926826, 0.9407317073170731]
Actions to choose Agent 1: dict_values([{'num_count': 290, 'sum_payoffs': 63.496124985713465, 'action': [0.0, 0]}, {'num_count': 3810, 'sum_payoffs': 1057.867578709339, 'action': [1.0, 0]}])
Weights num count: [0.07073170731707316, 0.9292682926829269]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 3700, 'sum_payoffs': 1132.0706247453504, 'action': [1.0, 0]}, {'num_count': 400, 'sum_payoffs': 113.67562497442233, 'action': [0.0, 0]}])
Weights num count: [0.9024390243902439, 0.0975609756097561]
Actions to choose Agent 1: dict_values([{'num_count': 255, 'sum_payoffs': 70.08749998423, 'action': [0.0, 0]}, {'num_count': 3845, 'sum_payoffs': 1176.266249735398, 'action': [1.0, 0]}])
Weights num count: [0.06219512195121951, 0.9378048780487804]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.7303643226623535 s
