Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 255, 'sum_payoffs': 50.887499990670634, 'action': [0.0, 0]}, {'num_count': 3845, 'sum_payoffs': 943.6601050901975, 'action': [1.0, 0]}])
Weights num count: [0.06219512195121951, 0.9378048780487804]
Actions to choose Agent 1: dict_values([{'num_count': 3846, 'sum_payoffs': 949.6136050891065, 'action': [1.0, 0]}, {'num_count': 254, 'sum_payoffs': 55.13999998989105, 'action': [0.0, 0]}])
Weights num count: [0.9380487804878048, 0.06195121951219512]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 291, 'sum_payoffs': 71.30999998692641, 'action': [0.0, 0]}, {'num_count': 3809, 'sum_payoffs': 1037.2649998099084, 'action': [1.0, 0]}])
Weights num count: [0.07097560975609755, 0.9290243902439025]
Actions to choose Agent 1: dict_values([{'num_count': 3823, 'sum_payoffs': 1040.7749998092645, 'action': [1.0, 0]}, {'num_count': 277, 'sum_payoffs': 66.71999998776792, 'action': [0.0, 0]}])
Weights num count: [0.932439024390244, 0.0675609756097561]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.564035177230835 s
