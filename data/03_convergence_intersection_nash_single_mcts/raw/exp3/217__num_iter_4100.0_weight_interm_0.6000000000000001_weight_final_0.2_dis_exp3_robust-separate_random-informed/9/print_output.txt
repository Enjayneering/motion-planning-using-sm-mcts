Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 414, 'sum_payoffs': 33.01593749257141, 'action': [0.0, 0]}, {'num_count': 3686, 'sum_payoffs': 353.967424262464, 'action': [1.0, 0]}])
Weights num count: [0.10097560975609757, 0.8990243902439025]
Actions to choose Agent 1: dict_values([{'num_count': 477, 'sum_payoffs': 38.02781249144386, 'action': [0.0, 0]}, {'num_count': 3623, 'sum_payoffs': 341.66554926523025, 'action': [1.0, 0]}])
Weights num count: [0.11634146341463415, 0.8836585365853659]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 3781, 'sum_payoffs': 391.97249991178853, 'action': [1.0, 0]}, {'num_count': 319, 'sum_payoffs': 27.15187499389101, 'action': [0.0, 0]}])
Weights num count: [0.9221951219512196, 0.07780487804878049]
Actions to choose Agent 1: dict_values([{'num_count': 3725, 'sum_payoffs': 384.2268749135327, 'action': [1.0, 0]}, {'num_count': 375, 'sum_payoffs': 30.94874999303677, 'action': [0.0, 0]}])
Weights num count: [0.9085365853658537, 0.09146341463414634]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.5164365768432617 s
