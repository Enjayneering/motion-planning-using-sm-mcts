Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 4327, 'sum_payoffs': 1598.3324996404167, 'action': [1.0, 0]}, {'num_count': 273, 'sum_payoffs': 89.30249997990663, 'action': [0.0, 0]}])
Weights num count: [0.9406521739130435, 0.059347826086956525]
Actions to choose Agent 1: dict_values([{'num_count': 264, 'sum_payoffs': 77.27399998261316, 'action': [0.0, 0]}, {'num_count': 4336, 'sum_payoffs': 1588.8554996425473, 'action': [1.0, 0]}])
Weights num count: [0.057391304347826085, 0.9426086956521739]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 272, 'sum_payoffs': 101.24999997721922, 'action': [0.0, 0]}, {'num_count': 4328, 'sum_payoffs': 1759.5224996039963, 'action': [1.0, 0]}])
Weights num count: [0.059130434782608696, 0.9408695652173913]
Actions to choose Agent 1: dict_values([{'num_count': 228, 'sum_payoffs': 85.45499998077287, 'action': [0.0, 0]}, {'num_count': 4372, 'sum_payoffs': 1779.7724995994365, 'action': [1.0, 0]}])
Weights num count: [0.049565217391304345, 0.9504347826086956]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.654479742050171 s
