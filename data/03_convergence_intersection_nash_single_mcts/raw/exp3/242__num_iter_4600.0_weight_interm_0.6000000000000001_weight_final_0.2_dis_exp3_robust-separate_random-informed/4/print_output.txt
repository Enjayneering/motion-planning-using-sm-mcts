Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 4218, 'sum_payoffs': 396.56161175288725, 'action': [1.0, 0]}, {'num_count': 382, 'sum_payoffs': 27.253124993868017, 'action': [0.0, 0]}])
Weights num count: [0.9169565217391304, 0.08304347826086957]
Actions to choose Agent 1: dict_values([{'num_count': 351, 'sum_payoffs': 25.23318749432249, 'action': [0.0, 0]}, {'num_count': 4249, 'sum_payoffs': 402.4087992515731, 'action': [1.0, 0]}])
Weights num count: [0.07630434782608696, 0.923695652173913]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 394, 'sum_payoffs': 36.112499991874955, 'action': [0.0, 0]}, {'num_count': 4206, 'sum_payoffs': 433.38374990246234, 'action': [1.0, 0]}])
Weights num count: [0.08565217391304347, 0.9143478260869565]
Actions to choose Agent 1: dict_values([{'num_count': 4140, 'sum_payoffs': 425.38499990426413, 'action': [1.0, 0]}, {'num_count': 460, 'sum_payoffs': 40.668749990849854, 'action': [0.0, 0]}])
Weights num count: [0.9, 0.1]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.6236352920532227 s
