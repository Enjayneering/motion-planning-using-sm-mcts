Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 4215, 'sum_payoffs': 395.3010492531709, 'action': [1.0, 0]}, {'num_count': 385, 'sum_payoffs': 27.48093749381673, 'action': [0.0, 0]}])
Weights num count: [0.9163043478260869, 0.08369565217391305]
Actions to choose Agent 1: dict_values([{'num_count': 4245, 'sum_payoffs': 404.99742425099043, 'action': [1.0, 0]}, {'num_count': 355, 'sum_payoffs': 24.710062494440194, 'action': [0.0, 0]}])
Weights num count: [0.9228260869565217, 0.07717391304347826]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 4234, 'sum_payoffs': 435.61124990196123, 'action': [1.0, 0]}, {'num_count': 366, 'sum_payoffs': 31.859999992831742, 'action': [0.0, 0]}])
Weights num count: [0.9204347826086956, 0.07956521739130434]
Actions to choose Agent 1: dict_values([{'num_count': 4194, 'sum_payoffs': 431.7131249028395, 'action': [1.0, 0]}, {'num_count': 406, 'sum_payoffs': 36.46687499179524, 'action': [0.0, 0]}])
Weights num count: [0.9117391304347826, 0.08826086956521739]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.6428730487823486 s
