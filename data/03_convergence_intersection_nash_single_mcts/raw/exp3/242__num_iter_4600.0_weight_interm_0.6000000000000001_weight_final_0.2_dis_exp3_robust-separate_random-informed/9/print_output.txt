Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 4226, 'sum_payoffs': 398.9376117523529, 'action': [1.0, 0]}, {'num_count': 374, 'sum_payoffs': 28.544062493577528, 'action': [0.0, 0]}])
Weights num count: [0.918695652173913, 0.08130434782608696]
Actions to choose Agent 1: dict_values([{'num_count': 4247, 'sum_payoffs': 401.2612992518305, 'action': [1.0, 0]}, {'num_count': 353, 'sum_payoffs': 26.311499994079895, 'action': [0.0, 0]}])
Weights num count: [0.9232608695652174, 0.07673913043478262]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 555, 'sum_payoffs': 50.64187498860598, 'action': [0.0, 0]}, {'num_count': 4045, 'sum_payoffs': 417.0824999061341, 'action': [1.0, 0]}])
Weights num count: [0.12065217391304348, 0.8793478260869565]
Actions to choose Agent 1: dict_values([{'num_count': 344, 'sum_payoffs': 28.72124999353792, 'action': [0.0, 0]}, {'num_count': 4256, 'sum_payoffs': 439.1043749011738, 'action': [1.0, 0]}])
Weights num count: [0.07478260869565218, 0.9252173913043479]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 1.6087143421173096 s
