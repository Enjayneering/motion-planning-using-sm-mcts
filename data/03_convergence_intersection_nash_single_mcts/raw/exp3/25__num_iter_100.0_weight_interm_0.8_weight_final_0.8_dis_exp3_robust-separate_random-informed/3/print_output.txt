Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 48, 'sum_payoffs': 9.7689671036757, 'action': [0.0, 0]}, {'num_count': 52, 'sum_payoffs': 14.93940789230919, 'action': [1.0, 0]}])
Weights num count: [0.48, 0.52]
Actions to choose Agent 1: dict_values([{'num_count': 50, 'sum_payoffs': 9.7689671036757, 'action': [0.0, 0]}, {'num_count': 50, 'sum_payoffs': 14.392657892398036, 'action': [1.0, 0]}])
Weights num count: [0.5, 0.5]
Selected final action: [1.0, 0, 0.0, 0]
Total payoff list: [0.49999999991875, 0.49999999991875]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 45, 'sum_payoffs': 12.19499999801831, 'action': [0.0, 0]}, {'num_count': 55, 'sum_payoffs': 16.59374999730352, 'action': [1.0, 0]}])
Weights num count: [0.45, 0.55]
Actions to choose Agent 1: dict_values([{'num_count': 60, 'sum_payoffs': 11.182499998182845, 'action': [1.0, 0]}, {'num_count': 40, 'sum_payoffs': 3.2287499994753266, 'action': [0.0, 0]}])
Weights num count: [0.6, 0.4]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.5263157893881579, 0.5263157893881579]
Terminal state: [1.0, 2.0, 1.5707963267948966, 1.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.08026671409606934 s
