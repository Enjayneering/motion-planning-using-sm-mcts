Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 93, 'sum_payoffs': 20.98631249527806, 'action': [0.0, 0]}, {'num_count': 507, 'sum_payoffs': 144.7067664148101, 'action': [1.0, 0]}])
Weights num count: [0.155, 0.845]
Actions to choose Agent 1: dict_values([{'num_count': 65, 'sum_payoffs': 12.83343749711247, 'action': [0.0, 0]}, {'num_count': 535, 'sum_payoffs': 154.7732664125448, 'action': [1.0, 0]}])
Weights num count: [0.10833333333333334, 0.8916666666666667]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 558, 'sum_payoffs': 176.01749996039496, 'action': [1.0, 0]}, {'num_count': 42, 'sum_payoffs': 9.793124997796546, 'action': [0.0, 0]}])
Weights num count: [0.93, 0.07]
Actions to choose Agent 1: dict_values([{'num_count': 90, 'sum_payoffs': 21.4874999951653, 'action': [0.0, 0]}, {'num_count': 510, 'sum_payoffs': 158.24812496439318, 'action': [1.0, 0]}])
Weights num count: [0.15, 0.85]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.26540231704711914 s
