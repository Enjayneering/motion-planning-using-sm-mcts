Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 498, 'sum_payoffs': 111.68884960491411, 'action': [1.0, 0]}, {'num_count': 102, 'sum_payoffs': 17.74285713981551, 'action': [0.0, 0]}])
Weights num count: [0.83, 0.17]
Actions to choose Agent 1: dict_values([{'num_count': 516, 'sum_payoffs': 115.85456388991426, 'action': [1.0, 0]}, {'num_count': 84, 'sum_payoffs': 13.993714283315354, 'action': [0.0, 0]}])
Weights num count: [0.86, 0.14]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 132, 'sum_payoffs': 27.925714280926965, 'action': [0.0, 0]}, {'num_count': 468, 'sum_payoffs': 113.8242856947738, 'action': [1.0, 0]}])
Weights num count: [0.22, 0.78]
Actions to choose Agent 1: dict_values([{'num_count': 462, 'sum_payoffs': 111.39428569519039, 'action': [1.0, 0]}, {'num_count': 138, 'sum_payoffs': 27.1157142810658, 'action': [0.0, 0]}])
Weights num count: [0.77, 0.23]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.23533105850219727 s
