Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 155, 'sum_payoffs': 30.41742856621414, 'action': [0.0, 0]}, {'num_count': 445, 'sum_payoffs': 109.53270674814068, 'action': [1.0, 0]}])
Weights num count: [0.25833333333333336, 0.7416666666666667]
Actions to choose Agent 1: dict_values([{'num_count': 364, 'sum_payoffs': 81.1749924672877, 'action': [1.0, 0]}, {'num_count': 236, 'sum_payoffs': 38.57142856481638, 'action': [0.0, 0]}])
Weights num count: [0.6066666666666667, 0.3933333333333333]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 472, 'sum_payoffs': 113.12999998060708, 'action': [1.0, 0]}, {'num_count': 128, 'sum_payoffs': 25.95857142412132, 'action': [0.0, 0]}])
Weights num count: [0.7866666666666666, 0.21333333333333335]
Actions to choose Agent 1: dict_values([{'num_count': 518, 'sum_payoffs': 124.46999997866342, 'action': [1.0, 0]}, {'num_count': 82, 'sum_payoffs': 16.46999999717656, 'action': [0.0, 0]}])
Weights num count: [0.8633333333333333, 0.13666666666666666]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.23926019668579102 s
