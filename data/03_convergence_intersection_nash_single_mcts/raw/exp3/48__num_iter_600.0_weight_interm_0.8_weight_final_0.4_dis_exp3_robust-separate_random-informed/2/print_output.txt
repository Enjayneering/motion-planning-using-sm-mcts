Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 154, 'sum_payoffs': 18.189039470349574, 'action': [0.0, 0]}, {'num_count': 446, 'sum_payoffs': 61.061210515120706, 'action': [1.0, 0]}])
Weights num count: [0.25666666666666665, 0.7433333333333333]
Actions to choose Agent 1: dict_values([{'num_count': 491, 'sum_payoffs': 68.33696051378695, 'action': [1.0, 0]}, {'num_count': 109, 'sum_payoffs': 12.735789471349335, 'action': [0.0, 0]}])
Weights num count: [0.8183333333333334, 0.18166666666666667]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 474, 'sum_payoffs': 67.61999998760292, 'action': [1.0, 0]}, {'num_count': 126, 'sum_payoffs': 14.572499997328359, 'action': [0.0, 0]}])
Weights num count: [0.79, 0.21]
Actions to choose Agent 1: dict_values([{'num_count': 126, 'sum_payoffs': 14.572499997328357, 'action': [0.0, 0]}, {'num_count': 474, 'sum_payoffs': 68.69999998740491, 'action': [1.0, 0]}])
Weights num count: [0.21, 0.79]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.255939245223999 s
