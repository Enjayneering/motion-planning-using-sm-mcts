Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 83, 'sum_payoffs': 13.483607140545677, 'action': [0.0, 0]}, {'num_count': 517, 'sum_payoffs': 91.79610900682047, 'action': [1.0, 0]}])
Weights num count: [0.13833333333333334, 0.8616666666666667]
Actions to choose Agent 1: dict_values([{'num_count': 407, 'sum_payoffs': 71.13018043893409, 'action': [1.0, 0]}, {'num_count': 193, 'sum_payoffs': 23.058321424618597, 'action': [0.0, 0]}])
Weights num count: [0.6783333333333333, 0.32166666666666666]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 241, 'sum_payoffs': 36.70392856513639, 'action': [0.0, 0]}, {'num_count': 359, 'sum_payoffs': 64.81607141745965, 'action': [1.0, 0]}])
Weights num count: [0.40166666666666667, 0.5983333333333334]
Actions to choose Agent 1: dict_values([{'num_count': 95, 'sum_payoffs': 15.007499997427308, 'action': [0.0, 0]}, {'num_count': 505, 'sum_payoffs': 94.67035712662823, 'action': [1.0, 0]}])
Weights num count: [0.15833333333333333, 0.8416666666666667]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.26456546783447266 s
