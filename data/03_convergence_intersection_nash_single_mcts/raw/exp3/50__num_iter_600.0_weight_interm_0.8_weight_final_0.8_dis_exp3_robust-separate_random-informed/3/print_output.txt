Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 512, 'sum_payoffs': 105.11265787765521, 'action': [1.0, 0]}, {'num_count': 88, 'sum_payoffs': 14.51759210290405, 'action': [0.0, 0]}])
Weights num count: [0.8533333333333334, 0.14666666666666667]
Actions to choose Agent 1: dict_values([{'num_count': 497, 'sum_payoffs': 94.58265787936638, 'action': [1.0, 0]}, {'num_count': 103, 'sum_payoffs': 14.47709210291063, 'action': [0.0, 0]}])
Weights num count: [0.8283333333333334, 0.17166666666666666]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 183, 'sum_payoffs': 32.849999994662, 'action': [0.0, 0]}, {'num_count': 417, 'sum_payoffs': 88.17749998567089, 'action': [1.0, 0]}])
Weights num count: [0.305, 0.695]
Actions to choose Agent 1: dict_values([{'num_count': 498, 'sum_payoffs': 106.30124998272521, 'action': [1.0, 0]}, {'num_count': 102, 'sum_payoffs': 18.371249997014697, 'action': [0.0, 0]}])
Weights num count: [0.83, 0.17]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.24076008796691895 s
