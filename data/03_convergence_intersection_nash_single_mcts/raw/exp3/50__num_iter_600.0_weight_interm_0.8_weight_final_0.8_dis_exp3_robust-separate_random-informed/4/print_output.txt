Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 524, 'sum_payoffs': 105.06203287766327, 'action': [1.0, 0]}, {'num_count': 76, 'sum_payoffs': 13.859999997747751, 'action': [0.0, 0]}])
Weights num count: [0.8733333333333333, 0.12666666666666668]
Actions to choose Agent 1: dict_values([{'num_count': 495, 'sum_payoffs': 95.49390787921811, 'action': [1.0, 0]}, {'num_count': 105, 'sum_payoffs': 16.502624997318325, 'action': [0.0, 0]}])
Weights num count: [0.825, 0.175]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 106, 'sum_payoffs': 18.67499999696534, 'action': [0.0, 0]}, {'num_count': 494, 'sum_payoffs': 104.07374998308725, 'action': [1.0, 0]}])
Weights num count: [0.17666666666666667, 0.8233333333333334]
Actions to choose Agent 1: dict_values([{'num_count': 491, 'sum_payoffs': 103.56749998316954, 'action': [1.0, 0]}, {'num_count': 109, 'sum_payoffs': 19.38374999685017, 'action': [0.0, 0]}])
Weights num count: [0.8183333333333334, 0.18166666666666667]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.252399206161499 s
