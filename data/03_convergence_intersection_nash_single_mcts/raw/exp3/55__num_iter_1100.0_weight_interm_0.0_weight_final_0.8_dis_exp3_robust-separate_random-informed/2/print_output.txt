Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 85, 'sum_payoffs': 21.140999995243284, 'action': [0.0, 0]}, {'num_count': 1015, 'sum_payoffs': 372.3367499162282, 'action': [1.0, 0]}])
Weights num count: [0.07727272727272727, 0.9227272727272727]
Actions to choose Agent 1: dict_values([{'num_count': 1027, 'sum_payoffs': 391.83749991184106, 'action': [1.0, 0]}, {'num_count': 73, 'sum_payoffs': 17.313749996104413, 'action': [0.0, 0]}])
Weights num count: [0.9336363636363636, 0.06636363636363636]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 997, 'sum_payoffs': 409.04999990795824, 'action': [1.0, 0]}, {'num_count': 103, 'sum_payoffs': 35.842499991935405, 'action': [0.0, 0]}])
Weights num count: [0.9063636363636364, 0.09363636363636364]
Actions to choose Agent 1: dict_values([{'num_count': 87, 'sum_payoffs': 29.767499993302287, 'action': [0.0, 0]}, {'num_count': 1013, 'sum_payoffs': 416.74499990622644, 'action': [1.0, 0]}])
Weights num count: [0.07909090909090909, 0.9209090909090909]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.46485090255737305 s
