Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 112, 'sum_payoffs': 24.659999995068034, 'action': [0.0, 0]}, {'num_count': 988, 'sum_payoffs': 298.0007999403972, 'action': [1.0, 0]}])
Weights num count: [0.10181818181818182, 0.8981818181818182]
Actions to choose Agent 1: dict_values([{'num_count': 97, 'sum_payoffs': 22.035599995592907, 'action': [0.0, 0]}, {'num_count': 1003, 'sum_payoffs': 302.0831999395808, 'action': [1.0, 0]}])
Weights num count: [0.08818181818181818, 0.9118181818181819]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 81, 'sum_payoffs': 22.373999995525196, 'action': [0.0, 0]}, {'num_count': 1019, 'sum_payoffs': 338.45399993231473, 'action': [1.0, 0]}])
Weights num count: [0.07363636363636364, 0.9263636363636364]
Actions to choose Agent 1: dict_values([{'num_count': 991, 'sum_payoffs': 325.8179999348418, 'action': [1.0, 0]}, {'num_count': 109, 'sum_payoffs': 27.23399999455317, 'action': [0.0, 0]}])
Weights num count: [0.9009090909090909, 0.09909090909090909]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.46730470657348633 s
