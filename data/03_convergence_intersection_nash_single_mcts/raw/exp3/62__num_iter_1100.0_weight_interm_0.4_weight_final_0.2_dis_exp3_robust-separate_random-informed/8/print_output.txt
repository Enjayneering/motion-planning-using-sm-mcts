Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 955, 'sum_payoffs': 125.86721049274901, 'action': [1.0, 0]}, {'num_count': 145, 'sum_payoffs': 16.118249995701817, 'action': [0.0, 0]}])
Weights num count: [0.8681818181818182, 0.1318181818181818]
Actions to choose Agent 1: dict_values([{'num_count': 941, 'sum_payoffs': 121.68296049386488, 'action': [1.0, 0]}, {'num_count': 159, 'sum_payoffs': 18.47999999507201, 'action': [0.0, 0]}])
Weights num count: [0.8554545454545455, 0.14454545454545453]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 881, 'sum_payoffs': 122.96999996720606, 'action': [1.0, 0]}, {'num_count': 219, 'sum_payoffs': 25.979999993071925, 'action': [0.0, 0]}])
Weights num count: [0.8009090909090909, 0.1990909090909091]
Actions to choose Agent 1: dict_values([{'num_count': 950, 'sum_payoffs': 134.4449999641463, 'action': [1.0, 0]}, {'num_count': 150, 'sum_payoffs': 17.204999995411978, 'action': [0.0, 0]}])
Weights num count: [0.8636363636363636, 0.13636363636363635]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.40277528762817383 s
