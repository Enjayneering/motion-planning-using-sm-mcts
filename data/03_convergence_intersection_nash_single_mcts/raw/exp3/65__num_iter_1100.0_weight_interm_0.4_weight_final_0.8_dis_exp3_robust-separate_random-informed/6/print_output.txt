Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 993, 'sum_payoffs': 251.1371052171185, 'action': [1.0, 0]}, {'num_count': 107, 'sum_payoffs': 19.540499996417598, 'action': [0.0, 0]}])
Weights num count: [0.9027272727272727, 0.09727272727272727]
Actions to choose Agent 1: dict_values([{'num_count': 994, 'sum_payoffs': 251.74460521700715, 'action': [1.0, 0]}, {'num_count': 106, 'sum_payoffs': 19.904999996350764, 'action': [0.0, 0]}])
Weights num count: [0.9036363636363637, 0.09636363636363636]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 105, 'sum_payoffs': 30.299999994444967, 'action': [1.0, 0]}, {'num_count': 995, 'sum_payoffs': 261.5249999520544, 'action': [0.0, 0]}])
Weights num count: [0.09545454545454546, 0.9045454545454545]
Actions to choose Agent 1: dict_values([{'num_count': 1007, 'sum_payoffs': 282.88499994814026, 'action': [1.0, 0]}, {'num_count': 93, 'sum_payoffs': 21.359999996083978, 'action': [0.0, 0]}])
Weights num count: [0.9154545454545454, 0.08454545454545455]
Selected final action: [0.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 1.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.41350436210632324 s
