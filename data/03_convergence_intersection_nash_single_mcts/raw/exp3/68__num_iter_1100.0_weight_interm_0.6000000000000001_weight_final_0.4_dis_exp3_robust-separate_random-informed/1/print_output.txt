Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 990, 'sum_payoffs': 153.3457894430138, 'action': [1.0, 0]}, {'num_count': 110, 'sum_payoffs': 15.732899996853451, 'action': [0.0, 0]}])
Weights num count: [0.9, 0.1]
Actions to choose Agent 1: dict_values([{'num_count': 940, 'sum_payoffs': 145.35648944461113, 'action': [1.0, 0]}, {'num_count': 160, 'sum_payoffs': 20.806199995838806, 'action': [0.0, 0]}])
Weights num count: [0.8545454545454545, 0.14545454545454545]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 948, 'sum_payoffs': 159.0299999681965, 'action': [1.0, 0]}, {'num_count': 152, 'sum_payoffs': 21.51899999569612, 'action': [0.0, 0]}])
Weights num count: [0.8618181818181818, 0.13818181818181818]
Actions to choose Agent 1: dict_values([{'num_count': 158, 'sum_payoffs': 21.518999995696124, 'action': [0.0, 0]}, {'num_count': 942, 'sum_payoffs': 157.40999996852048, 'action': [1.0, 0]}])
Weights num count: [0.14363636363636365, 0.8563636363636363]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6240155696868896 s
