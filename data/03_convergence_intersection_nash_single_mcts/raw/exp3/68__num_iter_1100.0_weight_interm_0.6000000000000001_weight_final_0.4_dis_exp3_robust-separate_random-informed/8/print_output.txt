Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 146, 'sum_payoffs': 18.891899996221664, 'action': [0.0, 0]}, {'num_count': 954, 'sum_payoffs': 149.47469997010367, 'action': [1.0, 0]}])
Weights num count: [0.13272727272727272, 0.8672727272727273]
Actions to choose Agent 1: dict_values([{'num_count': 945, 'sum_payoffs': 145.10069997097818, 'action': [1.0, 0]}, {'num_count': 155, 'sum_payoffs': 21.37049999572595, 'action': [0.0, 0]}])
Weights num count: [0.8590909090909091, 0.1409090909090909]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 962, 'sum_payoffs': 160.56899996788886, 'action': [1.0, 0]}, {'num_count': 138, 'sum_payoffs': 21.032999995793336, 'action': [0.0, 0]}])
Weights num count: [0.8745454545454545, 0.12545454545454546]
Actions to choose Agent 1: dict_values([{'num_count': 940, 'sum_payoffs': 155.8709999688283, 'action': [1.0, 0]}, {'num_count': 160, 'sum_payoffs': 22.166999995566517, 'action': [0.0, 0]}])
Weights num count: [0.8545454545454545, 0.14545454545454545]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5712659358978271 s
