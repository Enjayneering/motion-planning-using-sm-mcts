Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 179, 'sum_payoffs': 19.459499996432434, 'action': [0.0, 0]}, {'num_count': 921, 'sum_payoffs': 123.14021050374126, 'action': [1.0, 0]}])
Weights num count: [0.16272727272727272, 0.8372727272727273]
Actions to choose Agent 1: dict_values([{'num_count': 860, 'sum_payoffs': 111.71996050583448, 'action': [1.0, 0]}, {'num_count': 240, 'sum_payoffs': 26.748749995096027, 'action': [0.0, 0]}])
Weights num count: [0.7818181818181819, 0.21818181818181817]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 152, 'sum_payoffs': 17.33999999682098, 'action': [0.0, 0]}, {'num_count': 948, 'sum_payoffs': 132.95999997562433, 'action': [1.0, 0]}])
Weights num count: [0.13818181818181818, 0.8618181818181818]
Actions to choose Agent 1: dict_values([{'num_count': 157, 'sum_payoffs': 18.082499996684852, 'action': [0.0, 0]}, {'num_count': 943, 'sum_payoffs': 132.2174999757605, 'action': [1.0, 0]}])
Weights num count: [0.14272727272727273, 0.8572727272727273]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.5266711711883545 s
