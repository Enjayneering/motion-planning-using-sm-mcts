Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 110, 'sum_payoffs': 27.337499990431834, 'action': [0.0, 0]}, {'num_count': 1490, 'sum_payoffs': 555.6802498055081, 'action': [1.0, 0]}])
Weights num count: [0.06875, 0.93125]
Actions to choose Agent 1: dict_values([{'num_count': 98, 'sum_payoffs': 22.78124999202654, 'action': [0.0, 0]}, {'num_count': 1502, 'sum_payoffs': 560.6009998037861, 'action': [1.0, 0]}])
Weights num count: [0.06125, 0.93875]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1508, 'sum_payoffs': 617.4224997839012, 'action': [1.0, 0]}, {'num_count': 92, 'sum_payoffs': 28.957499989864885, 'action': [0.0, 0]}])
Weights num count: [0.9425, 0.0575]
Actions to choose Agent 1: dict_values([{'num_count': 105, 'sum_payoffs': 35.639999987526004, 'action': [0.0, 0]}, {'num_count': 1495, 'sum_payoffs': 613.9799997851063, 'action': [1.0, 0]}])
Weights num count: [0.065625, 0.934375]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6812331676483154 s
