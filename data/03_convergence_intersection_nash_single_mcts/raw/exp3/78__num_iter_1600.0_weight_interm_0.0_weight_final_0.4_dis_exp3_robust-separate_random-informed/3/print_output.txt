Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1494, 'sum_payoffs': 548.7547498079307, 'action': [1.0, 0]}, {'num_count': 106, 'sum_payoffs': 28.24874999011292, 'action': [0.0, 0]}])
Weights num count: [0.93375, 0.06625]
Actions to choose Agent 1: dict_values([{'num_count': 1490, 'sum_payoffs': 557.5027498048703, 'action': [1.0, 0]}, {'num_count': 110, 'sum_payoffs': 32.2582499887096, 'action': [0.0, 0]}])
Weights num count: [0.93125, 0.06875]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 88, 'sum_payoffs': 29.362499989723158, 'action': [0.0, 0]}, {'num_count': 1512, 'sum_payoffs': 621.8774997823413, 'action': [1.0, 0]}])
Weights num count: [0.055, 0.945]
Actions to choose Agent 1: dict_values([{'num_count': 117, 'sum_payoffs': 38.47499998653373, 'action': [0.0, 0]}, {'num_count': 1483, 'sum_payoffs': 606.6899997876587, 'action': [1.0, 0]}])
Weights num count: [0.073125, 0.926875]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6256628036499023 s
