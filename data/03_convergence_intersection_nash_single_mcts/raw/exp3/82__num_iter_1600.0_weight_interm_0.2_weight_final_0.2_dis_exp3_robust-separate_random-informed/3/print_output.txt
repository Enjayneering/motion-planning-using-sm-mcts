Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1459, 'sum_payoffs': 271.54740779969256, 'action': [1.0, 0]}, {'num_count': 141, 'sum_payoffs': 21.337874992531685, 'action': [0.0, 0]}])
Weights num count: [0.911875, 0.088125]
Actions to choose Agent 1: dict_values([{'num_count': 168, 'sum_payoffs': 26.258624990809405, 'action': [0.0, 0]}, {'num_count': 1432, 'sum_payoffs': 275.3746577983533, 'action': [1.0, 0]}])
Weights num count: [0.105, 0.895]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1480, 'sum_payoffs': 305.7637498929825, 'action': [1.0, 0]}, {'num_count': 120, 'sum_payoffs': 19.889999993038487, 'action': [0.0, 0]}])
Weights num count: [0.925, 0.075]
Actions to choose Agent 1: dict_values([{'num_count': 1466, 'sum_payoffs': 302.9287498939751, 'action': [1.0, 0]}, {'num_count': 134, 'sum_payoffs': 22.11749999225885, 'action': [0.0, 0]}])
Weights num count: [0.91625, 0.08375]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.7024936676025391 s
