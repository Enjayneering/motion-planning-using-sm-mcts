Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1450, 'sum_payoffs': 434.08326307108223, 'action': [1.0, 0]}, {'num_count': 150, 'sum_payoffs': 33.16139999336778, 'action': [0.0, 0]}])
Weights num count: [0.90625, 0.09375]
Actions to choose Agent 1: dict_values([{'num_count': 137, 'sum_payoffs': 32.15699999356867, 'action': [0.0, 0]}, {'num_count': 1463, 'sum_payoffs': 437.1288630704732, 'action': [1.0, 0]}])
Weights num count: [0.085625, 0.914375]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 121, 'sum_payoffs': 35.49599999290075, 'action': [0.0, 0]}, {'num_count': 1479, 'sum_payoffs': 487.33199990254394, 'action': [1.0, 0]}])
Weights num count: [0.075625, 0.924375]
Actions to choose Agent 1: dict_values([{'num_count': 137, 'sum_payoffs': 37.43999999251192, 'action': [0.0, 0]}, {'num_count': 1463, 'sum_payoffs': 477.61199990448796, 'action': [1.0, 0]}])
Weights num count: [0.085625, 0.914375]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.7448227405548096 s
