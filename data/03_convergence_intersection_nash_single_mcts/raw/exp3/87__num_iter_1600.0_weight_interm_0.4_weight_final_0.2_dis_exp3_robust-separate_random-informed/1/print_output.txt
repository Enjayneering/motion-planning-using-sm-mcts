Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 200, 'sum_payoffs': 20.060249994650565, 'action': [0.0, 0]}, {'num_count': 1400, 'sum_payoffs': 179.50946047844315, 'action': [1.0, 0]}])
Weights num count: [0.125, 0.875]
Actions to choose Agent 1: dict_values([{'num_count': 179, 'sum_payoffs': 19.391999994828794, 'action': [0.0, 0]}, {'num_count': 1421, 'sum_payoffs': 185.76671047677456, 'action': [1.0, 0]}])
Weights num count: [0.111875, 0.888125]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 170, 'sum_payoffs': 19.027499994925975, 'action': [0.0, 0]}, {'num_count': 1430, 'sum_payoffs': 199.51499994679867, 'action': [1.0, 0]}])
Weights num count: [0.10625, 0.89375]
Actions to choose Agent 1: dict_values([{'num_count': 240, 'sum_payoffs': 28.274999992459907, 'action': [0.0, 0]}, {'num_count': 1360, 'sum_payoffs': 188.78249994965992, 'action': [1.0, 0]}])
Weights num count: [0.15, 0.85]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6965172290802002 s
