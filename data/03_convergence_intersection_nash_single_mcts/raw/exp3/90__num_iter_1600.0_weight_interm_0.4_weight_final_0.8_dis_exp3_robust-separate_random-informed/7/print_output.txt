Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 112, 'sum_payoffs': 21.51789473289718, 'action': [0.0, 0]}, {'num_count': 1488, 'sum_payoffs': 371.5436051950351, 'action': [1.0, 0]}])
Weights num count: [0.07, 0.93]
Actions to choose Agent 1: dict_values([{'num_count': 1471, 'sum_payoffs': 366.56210519594885, 'action': [1.0, 0]}, {'num_count': 129, 'sum_payoffs': 26.256394732028472, 'action': [0.0, 0]}])
Weights num count: [0.919375, 0.080625]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1436, 'sum_payoffs': 371.00999993199355, 'action': [0.0, 0]}, {'num_count': 164, 'sum_payoffs': 47.17499999135119, 'action': [1.0, 0]}])
Weights num count: [0.8975, 0.1025]
Actions to choose Agent 1: dict_values([{'num_count': 177, 'sum_payoffs': 43.904999991950696, 'action': [0.0, 0]}, {'num_count': 1423, 'sum_payoffs': 403.9799999259509, 'action': [1.0, 0]}])
Weights num count: [0.110625, 0.889375]
Selected final action: [0.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 1.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6475269794464111 s
