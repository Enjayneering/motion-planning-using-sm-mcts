Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 316, 'sum_payoffs': 25.224749994324423, 'action': [0.0, 0]}, {'num_count': 1284, 'sum_payoffs': 125.42432562967588, 'action': [1.0, 0]}])
Weights num count: [0.1975, 0.8025]
Actions to choose Agent 1: dict_values([{'num_count': 1434, 'sum_payoffs': 143.33118746774988, 'action': [1.0, 0]}, {'num_count': 166, 'sum_payoffs': 15.701388154361904, 'action': [0.0, 0]}])
Weights num count: [0.89625, 0.10375]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 203, 'sum_payoffs': 17.938124995963953, 'action': [0.0, 0]}, {'num_count': 1397, 'sum_payoffs': 146.3906249670608, 'action': [1.0, 0]}])
Weights num count: [0.126875, 0.873125]
Actions to choose Agent 1: dict_values([{'num_count': 1417, 'sum_payoffs': 147.9093749667192, 'action': [1.0, 0]}, {'num_count': 183, 'sum_payoffs': 15.913124996419569, 'action': [0.0, 0]}])
Weights num count: [0.885625, 0.114375]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.6636977195739746 s
