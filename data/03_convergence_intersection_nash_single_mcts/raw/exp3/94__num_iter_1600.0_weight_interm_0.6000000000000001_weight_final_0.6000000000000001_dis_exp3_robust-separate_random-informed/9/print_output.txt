Searching game tree in timestep 0...
Max timehorizon: 2
Actions to choose Agent 0: dict_values([{'num_count': 1429, 'sum_payoffs': 270.8184078450858, 'action': [1.0, 0]}, {'num_count': 171, 'sum_payoffs': 24.709499995469898, 'action': [0.0, 0]}])
Weights num count: [0.893125, 0.106875]
Actions to choose Agent 1: dict_values([{'num_count': 1448, 'sum_payoffs': 275.8302828441669, 'action': [1.0, 0]}, {'num_count': 152, 'sum_payoffs': 22.97812499578732, 'action': [0.0, 0]}])
Weights num count: [0.905, 0.095]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Searching game tree in timestep 1...
Max timehorizon: 1
Actions to choose Agent 0: dict_values([{'num_count': 1456, 'sum_payoffs': 301.51124994471877, 'action': [1.0, 0]}, {'num_count': 144, 'sum_payoffs': 24.344999995536725, 'action': [0.0, 0]}])
Weights num count: [0.91, 0.09]
Actions to choose Agent 1: dict_values([{'num_count': 153, 'sum_payoffs': 25.762499995276844, 'action': [0.0, 0]}, {'num_count': 1447, 'sum_payoffs': 299.2837499451273, 'action': [1.0, 0]}])
Weights num count: [0.095625, 0.904375]
Selected final action: [1.0, 0, 1.0, 0]
Total payoff list: [0.0, 0.0]
Terminal state: [1.0, 2.0, 1.5707963267948966, 2.0, 1.0, 0.0, 2]
Timestep: 2
Runtime: 0.637934684753418 s
