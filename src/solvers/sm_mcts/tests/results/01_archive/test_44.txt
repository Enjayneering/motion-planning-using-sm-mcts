state_space: ['x0', 'y0', 'theta0', 'x1', 'y1', 'theta1', 'timestep']
delta_t: 1
agents: [0, 1]
interm_payoffs: {'penalty_distance_0': {'pos': 0, 'weight': -0.2, 'agent': 0}, 'penalty_distance_1': {'pos': 1, 'weight': -0.2, 'agent': 1}, 'reward_progress_0': {'pos': 2, 'weight': 0, 'agent': 0}, 'reward_progress_1': {'pos': 3, 'weight': 0, 'agent': 1}, 'penalty_agressor_0': {'pos': 4, 'weight': 0, 'agent': 0}, 'penalty_agressor_1': {'pos': 5, 'weight': 0, 'agent': 1}}
final_payoffs: {'penalty_timestep_0': {'pos': 0, 'weight': -0.2, 'agent': 0}, 'penalty_timestep_1': {'pos': 1, 'weight': -0.2, 'agent': 1}, 'reward_lead_0': {'pos': 2, 'weight': 1, 'agent': 0}, 'reward_lead_1': {'pos': 3, 'weight': 1, 'agent': 1}}
len_interm_payoffs: 6
len_final_payoffs: 4
num_iter: 400
c_param: 1.4142135623730951
action_set_0: {'velocity_0': [0.0, 1.0, 2.0], 'ang_velocity_0': [-1.5707963267948966, 0.0, 1.5707963267948966]}
action_set_1: {'velocity_1': [0.0, 1.0, 2.0], 'ang_velocity_1': [-1.5707963267948966, 0.0, 1.5707963267948966]}
Environment trigger: test
penalty_distance_0: [-0.002873919218087818, -0.0013475893998170934, -0.005434492234447113, -0.005434492234447113, -0.0009168169540213468, -0.0009168169540213468, -0.0013475893998170934, -0.003663127777746836, -0.0004957504353332717, -0.003663127777746836, -0.00995741367357279, -0.00995741367357279, -0.00995741367357279, -0.00995741367357279, -0.00995741367357279, -0.00995741367357279]
penalty_distance_1: [-0.002873919218087818, -0.0013475893998170934, -0.005434492234447113, -0.005434492234447113, -0.0009168169540213468, -0.0009168169540213468, -0.0013475893998170934, -0.003663127777746836, -0.0004957504353332717, -0.003663127777746836, -0.00995741367357279, -0.00995741367357279, -0.00995741367357279, -0.00995741367357279, -0.00995741367357279, -0.00995741367357279]
reward_progress_0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
reward_progress_1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
penalty_agressor_0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
penalty_agressor_1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
penalty_timestep_0: [-3.2]
penalty_timestep_1: [-3.2]
reward_lead_0: [3.0]
reward_lead_1: [-3.0]
payoff_total0: [-0.002873919218087818, -0.004221508617904912, -0.009656000852352024, -0.015090493086799137, -0.016007310040820483, -0.016924126994841828, -0.01827171639465892, -0.02193484417240576, -0.02243059460773903, -0.026093722385485865, -0.03605113605905866, -0.04600854973263145, -0.055965963406204244, -0.06592337707977704, -0.07588079075334983, -0.08583820442692262, -0.2858382044269228]
payoff_total1: [-0.002873919218087818, -0.004221508617904912, -0.009656000852352024, -0.015090493086799137, -0.016007310040820483, -0.016924126994841828, -0.01827171639465892, -0.02193484417240576, -0.02243059460773903, -0.026093722385485865, -0.03605113605905866, -0.04600854973263145, -0.055965963406204244, -0.06592337707977704, -0.07588079075334983, -0.08583820442692262, -6.2858382044269225]
Config: {'env_name': 'test', 'env_def': {0: '\n            ########################\n            #1.....................#\n            #####.....##############\n            ###.....################\n            #..0...#################\n            ########################'}, 'theta_0_init': 0, 'theta_1_init': 0, 'terminal_progress': 20, 'alpha_t': 1, 'num_sim': 1, 'num_iter': 400, 'delta_t': 1, 'c_param': 1.4142135623730951, 'penalty_distance_0': -0.2, 'penalty_distance_1': -0.2, 'reward_progress_0': 0, 'reward_progress_1': 0, 'penalty_agressor_0': 0, 'penalty_agressor_1': 0, 'penalty_timestep_0': -0.2, 'penalty_timestep_1': -0.2, 'reward_lead_0': 1, 'reward_lead_1': 1, 'velocity_0': [0.0, 1.0, 2.0], 'ang_velocity_0': [-1.5707963267948966, 0.0, 1.5707963267948966], 'velocity_1': [0.0, 1.0, 2.0], 'ang_velocity_1': [-1.5707963267948966, 0.0, 1.5707963267948966], 'feature_flags': {'final_move': {'robust': True, 'best': False}, 'collision_handling': {'punishing': True, 'pruning': False}, 'selection_policy': {'ucb': True, 'random': False}, 'rollout_policy': {'random': True, 'best': False}, 'payoff_weights': {'fixed': True, 'adaptive': False}}}
Duration: 83.76155209541321

Content of global_state.csv:
x0,y0,theta0,x1,y1,theta1,timestep
3,4,0,1,1,0,0
3,4,0,1,1,0,0
4.0,4.0,0.0,1.0,1.0,1.5707963267948966,1
5.0,4.0,4.71238898038469,1.0,1.0,0.0,2
5.0,3.0,4.71238898038469,2.0,1.0,4.71238898038469,3
5.0,3.0,0.0,2.0,1.0,3.141592653589793,4
7.0,3.0,0.0,2.0,1.0,3.141592653589793,5
7.0,3.0,4.71238898038469,2.0,1.0,1.5707963267948966,6
7.0,1.0,0.0,2.0,1.0,0.0,7
8.0,1.0,0.0,4.0,1.0,4.71238898038469,8
10.0,1.0,1.5707963267948966,4.0,1.0,0.0,9
10.0,1.0,0.0,6.0,1.0,0.0,10
11.0,1.0,0.0,8.0,1.0,0.0,11
13.0,1.0,0.0,10.0,1.0,0.0,12
15.0,1.0,0.0,12.0,1.0,0.0,13
17.0,1.0,0.0,14.0,1.0,0.0,14
19.0,1.0,0.0,16.0,1.0,0.0,15
21.0,1.0,0.0,18.0,1.0,0.0,16
