state_space: ['x0', 'y0', 'theta0', 'x1', 'y1', 'theta1', 'timestep']
delta_t: 1
agents: [0, 1]
interm_payoffs: {'penalty_distance_0': {'pos': 0, 'weight': -0.2, 'agent': 0}, 'penalty_distance_1': {'pos': 1, 'weight': -0.2, 'agent': 1}, 'reward_progress_0': {'pos': 2, 'weight': 0, 'agent': 0}, 'reward_progress_1': {'pos': 3, 'weight': 0, 'agent': 1}, 'penalty_agressor_0': {'pos': 4, 'weight': 0, 'agent': 0}, 'penalty_agressor_1': {'pos': 5, 'weight': 0, 'agent': 1}}
final_payoffs: {'penalty_timestep_0': {'pos': 0, 'weight': -0.2, 'agent': 0}, 'penalty_timestep_1': {'pos': 1, 'weight': -0.2, 'agent': 1}, 'reward_lead_0': {'pos': 2, 'weight': 1, 'agent': 0}, 'reward_lead_1': {'pos': 3, 'weight': 1, 'agent': 1}}
len_interm_payoffs: 6
len_final_payoffs: 4
num_iter: 400
c_param: 1.4142135623730951
action_set_0: {'velocity_0': [0.0, 1.0, 2.0], 'ang_velocity_0': [-1.5707963267948966, 0.0, 1.5707963267948966]}
action_set_1: {'velocity_1': [0.0, 1.0, 2.0], 'ang_velocity_1': [-1.5707963267948966, 0.0, 1.5707963267948966]}
Environment trigger: test
penalty_distance_0: [-0.005434492234447113, -0.07357588823428847, -0.02137558513207715, -0.0032388286638325124, -0.0012205454548348009, -0.0013475893998170934, -0.0013475893998170934, -0.0013475893998170934, -0.0013475893998170934, -0.0013475893998170934, -0.0013475893998170934]
penalty_distance_1: [-0.005434492234447113, -0.07357588823428847, -0.02137558513207715, -0.0032388286638325124, -0.0012205454548348009, -0.0013475893998170934, -0.0013475893998170934, -0.0013475893998170934, -0.0013475893998170934, -0.0013475893998170934, -0.0013475893998170934]
reward_progress_0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
reward_progress_1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
penalty_agressor_0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
penalty_agressor_1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
penalty_timestep_0: [-2.2]
penalty_timestep_1: [-2.2]
reward_lead_0: [-5.0]
reward_lead_1: [5.0]
payoff_total0: [-0.005434492234447113, -0.07901038046873558, -0.10038596560081273, -0.10362479426464524, -0.10484533971948004, -0.10619292911929713, -0.10754051851911423, -0.10888810791893132, -0.11023569731874841, -0.1115832867185655, -0.1129308761183826, -7.312930876118383]
payoff_total1: [-0.005434492234447113, -0.07901038046873558, -0.10038596560081273, -0.10362479426464524, -0.10484533971948004, -0.10619292911929713, -0.10754051851911423, -0.10888810791893132, -0.11023569731874841, -0.1115832867185655, -0.1129308761183826, 2.687069123881617]
Config: {'env_name': 'test', 'env_def': {0: '\n            ########################\n            #1.....................#\n            #####.....##############\n            ###.....################\n            #..0...#################\n            ########################'}, 'theta_0_init': 0, 'theta_1_init': 0, 'terminal_progress': 20, 'alpha_t': 1, 'num_sim': 1, 'num_iter': 400, 'delta_t': 1, 'c_param': 1.4142135623730951, 'penalty_distance_0': -0.2, 'penalty_distance_1': -0.2, 'reward_progress_0': 0, 'reward_progress_1': 0, 'penalty_agressor_0': 0, 'penalty_agressor_1': 0, 'penalty_timestep_0': -0.2, 'penalty_timestep_1': -0.2, 'reward_lead_0': 1, 'reward_lead_1': 1, 'velocity_0': [0.0, 1.0, 2.0], 'ang_velocity_0': [-1.5707963267948966, 0.0, 1.5707963267948966], 'velocity_1': [0.0, 1.0, 2.0], 'ang_velocity_1': [-1.5707963267948966, 0.0, 1.5707963267948966], 'feature_flags': {'final_move': {'robust': True, 'best': False}, 'collision_handling': {'punishing': True, 'pruning': False}, 'selection_policy': {'ucb': True, 'random': False}, 'rollout_policy': {'random': True, 'best': False}, 'payoff_weights': {'fixed': True, 'adaptive': False}, 'expansion_policy': {'full_child': True, 'random': False}}}
Duration: 67.81227493286133

Content of global_state.csv:
x0,y0,theta0,x1,y1,theta1,timestep
3,4,0,1,1,0,0
3,4,0,1,1,0,0
5.0,4.0,4.71238898038469,3.0,1.0,0.0,1
5.0,2.0,3.141592653589793,5.0,1.0,0.0,2
5.0,2.0,4.71238898038469,7.0,1.0,0.0,3
5.0,2.0,3.141592653589793,9.0,1.0,0.0,4
5.0,2.0,4.71238898038469,10.0,1.0,1.5707963267948966,5
5.0,1.0,0.0,10.0,1.0,0.0,6
7.0,1.0,0.0,12.0,1.0,0.0,7
9.0,1.0,0.0,14.0,1.0,0.0,8
11.0,1.0,0.0,16.0,1.0,0.0,9
13.0,1.0,0.0,18.0,1.0,0.0,10
15.0,1.0,0.0,20.0,1.0,4.71238898038469,11
