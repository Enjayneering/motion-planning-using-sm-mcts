state_space: ['x0', 'y0', 'theta0', 'x1', 'y1', 'theta1', 'timestep']
delta_t: 1
agents: [0, 1]
interm_payoffs: {'penalty_distance_0': {'pos': 0, 'weight': -0.2, 'agent': 0}, 'penalty_distance_1': {'pos': 1, 'weight': -0.2, 'agent': 1}, 'reward_progress_0': {'pos': 2, 'weight': 0, 'agent': 0}, 'reward_progress_1': {'pos': 3, 'weight': 0, 'agent': 1}, 'penalty_agressor_0': {'pos': 4, 'weight': 0, 'agent': 0}, 'penalty_agressor_1': {'pos': 5, 'weight': 0, 'agent': 1}}
final_payoffs: {'penalty_timestep_0': {'pos': 0, 'weight': -0.2, 'agent': 0}, 'penalty_timestep_1': {'pos': 1, 'weight': -0.2, 'agent': 1}, 'reward_lead_0': {'pos': 2, 'weight': 1, 'agent': 0}, 'reward_lead_1': {'pos': 3, 'weight': 1, 'agent': 1}}
len_interm_payoffs: 6
len_final_payoffs: 4
num_iter: 800
c_param: 1.4142135623730951
action_set_0: {'velocity_0': [0.0, 0.6666666666666666, 1.3333333333333333, 2.0], 'ang_velocity_0': [-1.5707963267948966, -0.5235987755982989, 0.5235987755982987, 1.5707963267948966]}
action_set_1: {'velocity_1': [0.0, 0.5, 1.0], 'ang_velocity_1': [-1.5707963267948966, -0.5235987755982989, 0.5235987755982987, 1.5707963267948966]}
Environment trigger: test
penalty_distance_0: [-0.006465243351458998, -0.005140209766961286]
penalty_distance_1: [-0.006465243351458998, -0.005140209766961286]
reward_progress_0: [0.0, 0.0]
reward_progress_1: [0.0, 0.0]
penalty_agressor_0: [0.0, 0.0]
penalty_agressor_1: [0.0, 0.0]
penalty_timestep_0: [-0.4]
penalty_timestep_1: [-0.4]
reward_lead_0: [2.8213672050459175]
reward_lead_1: [-2.8213672050459175]
payoff_total0: [-0.006465243351458998, -0.011605453118420284, 2.409761751927497]
payoff_total1: [-0.006465243351458998, -0.011605453118420284, -3.232972658164338]
Config: {'compute_n_actions': 1, 'env_name': 'test', 'env_def': {0: '\n            ######################\n            #1...................#\n            #####.....############\n            ###....###############\n            #..0.#################\n            ######################'}, 'theta_0_init': 0, 'theta_1_init': 0, 'terminal_progress': 18, 'alpha_t': 1, 'num_sim': 1, 'num_iter': 800, 'delta_t': 1, 'c_param': 1.4142135623730951, 'penalty_distance_0': -0.2, 'penalty_distance_1': -0.2, 'reward_progress_0': 0, 'reward_progress_1': 0, 'penalty_agressor_0': 0, 'penalty_agressor_1': 0, 'penalty_timestep_0': -0.2, 'penalty_timestep_1': -0.2, 'reward_lead_0': 1, 'reward_lead_1': 1, 'velocity_0': [0.0, 0.6666666666666666, 1.3333333333333333, 2.0], 'ang_velocity_0': [-1.5707963267948966, -0.5235987755982989, 0.5235987755982987, 1.5707963267948966], 'velocity_1': [0.0, 0.5, 1.0], 'ang_velocity_1': [-1.5707963267948966, -0.5235987755982989, 0.5235987755982987, 1.5707963267948966], 'feature_flags': {'final_move': {'robust': True, 'best': False}, 'collision_handling': {'punishing': True, 'pruning': False}, 'selection_policy': {'ucb': True, 'random': False}, 'rollout_policy': {'random': True, 'best': False}, 'payoff_weights': {'fixed': True, 'adaptive': False}}}
Duration: 44.8388614654541

Content of global_state.csv:
x0,y0,theta0,x1,y1,theta1,timestep
3,4,0,1,1,0,0
3,4,0,1,1,0,0
3.6666666666666665,4.0,5.759586531581287,2.0,1.0,1.5707963267948966,1
4.8213672050459175,3.333333333333333,5.235987755982988,2.0,1.0,1.0471975511965976,2
